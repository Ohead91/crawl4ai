---
date: 250113
source: aitimes
crawled_at: 2025-01-13T09:59:29.143211
---

## [2] 머스크 "AI 훈련 데이터 지난해 이미 고갈...합성 데이터가 보완책"

URL: https://www.aitimes.com/news/articleView.html?idxno=167004

![이미지](https://cdn.aitimes.com/news/photo/202501/167004_181663_721.png)

*(사진=셔터스톡)*

일론 머스크 CEO도 인공지능(AI) 훈련에 필요한 데이터가 이미 고갈됐다고 밝혔다. 지난해 말부터 이어진 '스케일링 법칙' 한계에 대해 동의한 것이다.

머스크 CEO는 8일(현지시간) X(트위터)에서 진행된 마크 펜 스태그웰 회장과의 라이브 스트리밍 인터뷰를 통해 "우리는 이제 AI 훈련에서 누적된 인간 지식의 총합을 고갈시켰다"라며 "이 문제는 지난해에 발생했다"라고 말했다.

또 합성 데이터를 해결책으로 들었다. "이를 보완하는 유일한 방법은 AI가 만드는 합성 데이터"라며 "합성 데이터를 사용하면 AI가 스스로를 평가하고 자체 학습 과정을 거칠 것"이라고 설명했다.

이번 발언은 사전 훈련을 통한 모델 성능 향상이 한계에 달했다는 지적과 일치한다. 오픈AI와 구글, 앤트로픽 등은 더 많은 컴퓨팅 인프라를 투입하고도 최신 모델이 기대만큼의 성능 향상을 보이지 않은 것으로 알려졌다. 그 이유로 더 이상 쓸만한 데이터가 없다는 점이 이유로 꼽혔다.

일리야 수츠케버 SSI 창립자도 지난달 열린 '뉴립스(NeurIPS)'에서 이 점을 강조했다. 그는 "컴퓨팅은 성장하고 있지만, 데이터는 성장하지 않는다. 왜냐하면 인터넷은 하나뿐이기 때문"이라며 "우리는 최고 데이터를 달성했고, 더 이상은 없을 것"이라고 밝혔다.

이번 발언은 xAI도 이런 점을 경험했다는 것으로 해석된다. xAI는 GPU 10만개를 투입한 세계 최대의 AI 컴퓨팅 인프라 '콜로서스'에서 지난 9월부터 '그록 3'를 훈련했지만, 2024년 출시에는 실패했다.

https://twitter.com/i/broadcasts/1yNxagNdkMlGj

지난 6일에는 머스크 CEO가 “곧 그록 3를 출시할 것"이라는 트윗을 게시했는데, 그록 3도 합성데이터로 학습했다고 볼 수 있다.

마이크로소프트가 이날 오픈 소스로 공개한 '파이-4'를 비롯해 오픈AI와 앤트로픽, 메타 등은 이미 합성 데이터를 활용 중인 것으로 알려졌다. 가트너는 2024년 AI 및 분석 프로젝트에 사용된 데이터의 60%가 합성물이라고 추정했다.

물론, 합성 데이터가 완전한 해결책은 아니다. 합성 데이터는 기존 모델의 편향을 반영, 결국 결과물이 동일해지는 '모델 붕괴' 현상을 일으키는 것으로 알려져 있다.

---

## [4] 실시간 지식 업데이트 가능한 '그래프RAG' 모델 출시..."데이터 학습보다 실시간 데이터가 중요"

URL: https://www.aitimes.com/news/articleView.html?idxno=167022

![이미지](https://cdn.aitimes.com/news/photo/202501/167022_181699_4529.png)

*(사진=디프봇)*

인공지능(AI) 모델의 정확도를 높이기 위해 사전 훈련 매개변수를 늘리는 것보다, 실시간 데이터베이스에 접속하는 것이 더 효과적이라는 것을 보여주는 모델이 등장했다. 이를 위해 '그래프 검색 증강 생성(GraphRAG)'이 동원됐다.

실리콘밸리 스타트업인 디프봇(DIFFBOT)은 9일(현지시간) 실시간 지식 업데이트가 가능한 '디프봇-LLM-추론(Diffbot-LLM-Inference)'를 오픈 소스로 깃허브에 공개했다.

디프봇은 이 모델을 설명하기 위해 'AI를 위한 웹 데이터'를 강조했다. "AI가 구조화된 데이터베이스처럼 웹에 접근할 수 있다고 상상해 보라"라고 설명했다.

실제로 이 회사는 세계에서 가장 큰 웹 지식 인덱스 중 하나를 유지 관리하는 것으로 유명하다. 디프봇 지식 그래프(Diffbot Knowledge Graph)라는 데이터베이스는 100억명 이상의 사람과 회사, 제품, 기사, 토론이 포함, 1조개가 넘는 상호 연결된 사실을 포함하며 지속 업데이트된다고 설명했다.

이처럼 지식그래프는 단순한 검색 결과가 아니라, 개체나 이벤트, 상황 등의 연관 관계를 유기적으로 연결하고 설명한 비즈니스용 데이터베이스다. 이미 시스코와 덕덕고, 스냅챗 등에 데이터를 제공하고 있다.

이번에 공개한 모델은 메타의 '라마 3.'3을 미세조정하고 그래프RAG와 연결한 최초의 오픈 소스 모델이다. 이를 통해 기존 AI 모델이 사전 훈련을 통한 방대한 양의 데이터에만 의존하는 것과 달리, 디브봇 LLM은 지식 그래프에서 실시간 정보를 활용한다. 이를 통해 모델의 정확도가 높아질 수 있다는 설명이다.

마이크 텅 디프봇 창립자 겸 CEO는 벤처비트와의 인터뷰에서 "모델에 필요한 것은 과다한 지식 학습이 아니라, 도구를 사용하는 데 능숙해져 외부에서 지식을 가져오는 것"이라며 "결국 범용 추론 모델은 10억개의 매개변수로 축소될 것"이라고 밝혔다.

이 회사의 지식 그래프는 2016년부터 공개 웹을 크롤링해 온 결과로, 4~5일마다 수백만개의 새로운 사실로 업데이트해 최신 상태를 유지한다. 모델은 데이터셋의 정적 지식에 의존하기보다는 그래프를 실시간으로 쿼리해 최신성을 유지한다는 설명이다.

예를 들어, 최근 뉴스에 대해 질문을 받으면 모델은 웹에서 업데이트를 검색하고 관련 사실을 추출하고 원래 출처를 인용할 수 있다. 최근 트렌드인 AI 검색과도 비슷한 원리다.

최신성을 테스트하는 벤치마크에서도 뛰어난 성적을 거뒀다. 실시간 지식을 테스트하기 위한 구글의 프레시QA(FreshQA)에서 81%의 정확도를 달성, '챗GPT'와 '제미나이'를 모두 능가했다. 또 전문 지식을 측정하는 MMLU-프로에서도 70.36%를 기록했다.

특히 사이즈는 8B와 70B 두가지로, 로컬 컴퓨터에 다운로드받아 사용할 수 있다는 것을 장점으로 들었다. 또 오픈 소스라 자유로운 미세조정과 상업적 활용이 가능하다고 강조했다.

텅 CEO는 "모두가 더 큰 모델만을 추구하는 것은 아니다"라며 "우리와 같은 접근 방식을 통해 큰 모델보다 더 많은 기능을 갖춘 모델을 가질 수 있다"라고 말했다.

---

## [7] MS, 수학 특화 추론 기술 공개..."sLM으로 o1 성능 능가"

URL: https://www.aitimes.com/news/articleView.html?idxno=167020

![이미지](https://cdn.aitimes.com/news/photo/202501/167020_181694_927.jpg)

*(사진=셔터스톡)*

마이크로소프트(MS)가 소형언어모델(sLM)의 수학적 추론 능력을 크게 향상하는 새로운 기술 ‘r스타-매스(rStar-Math)’를 발표했다. 이 기술은 sLM의 수학 문제 해결 능력을 획기적으로 개선, 오픈AI의 'o1-프리뷰'보다 우수한 성과를 보였다고 밝혔다.

MS와 베이징대, 칭화대 연구진은 9일(현지시간) sLM의 수학 추론 성능을 향상하는 ‘r스타-매스’ 기술 논문을 아카이브에 게재했다.

r스타-매스는 문제를 단계별로 해결하는 사고 사슬(CoT)에 '몬테카를로 트리 탐색(MCTS)'을 결합한 것이 핵심이다. MCTS는 모든 가능성을 탐색하는 대신 시뮬레이션을 통해 가장 유망한 경로를 선택하는 방법으로, 복잡한 수학 문제를 단계별로 단순화해 해결한다.

연구진은 공개된 74만7000개의 수학 단어 문제 데이터를 바탕으로 '정책 모델(Policy Model)'을 훈련해 문제 해결 단계를 생성했다. 이 정책 모델은 항상 자연어와 파이썬 코드로 문제 해결 과정을 설명하도록 설계됐으며, 생성 과정 중 최적의 단계를 선택하기 위해 '과정 선호 모델(PPM)'을 함께 사용됐다. 두 모델은 네차례의 자기 진화(Self-Evolution)를 통해 성능을 상호 개선했다는 설명이다.

이 방식은 MS의 '파이-3 미니', 알리바바의 '큐원-1.5B' 및 '큐원-7B' 등 sLM에 적용됐으며, 모든 모델에서 성능이 크게 향상했다.

특히 큐원-7B는 MATH 벤치마크에서 정확도가 58.8%에서 90.0%로 상승, o1-프리뷰 를 뛰어넘는 성과를 냈다. 또 미국 수학경시대회(AIME)에서는 문제의 53.3%를 해결, 고등학생 상위 20%에 해당하는 성적을 기록했다.

이 방식은 언어 모델의 크기를 키우는 방식으로 성능을 높이는 데 집중한 기존 개발 방식에 변화를 준 것이다. 효율성을 강조한 r스타-매스를 통해 sLM도 LLM에 맞먹거나 능가할 수 있다는 것을 보여줬다는 평이다.

연구진은 r스타-매스의 코드와 데이터를 깃허브를 통해 공개할 계획이며, 현재 내부 검토를 진행 중이라고 밝혔다.

---

## [8] MS, '이것이 세계 최고의 AI 슈퍼컴' 시즌 2 공개

URL: https://www.aitimes.com/news/articleView.html?idxno=167008

![이미지](https://cdn.aitimes.com/news/photo/202501/167008_181675_2653.jpg)

*NV링크를 소개 중인 젠슨 황 CEO (사진=엔비디아)*

젠슨 황 엔비디아 CEO가 CES 키노트에서 현존 세계 최고 사양의 '블랙웰' 인공지능(AI) 서버를 공개하자마자, 실물 사진이 소셜 미디어에 등장했다. 이번에도 마이크로소프트(MS)가 그 주인공이다.

사티아 나델라 MS CEO는 8일(현지시간) X(트위터)를 통해 엔비디아 'NV링크 (NVlink 72)' 클러스터의 사진을 공개하며 '애저' 서비스에 이를 적용했다고 발표했다. 이는 황 CEO가 키노트에서 이를 공개한 지 몇시간 뒤로, 나델라 CEO는 인도를 방문 중이었다.

그는 "테스트 타임 스케일링에 맞춰 애저에서 첫번째 NV링크 72 클러스터를 라이브로 출시했다"라며 "이 시스템을 기반으로 차세대 AI를 구축할 것"이라고 밝혔다.

https://twitter.com/satyanadella/status/1876669948912861497

NV링크는 블랙웰 기반 'GB200' 서버에 최신 네트워킹 기술을 도입, 처리 속도를 높인 AI 슈퍼컴퓨터다. 72개의 블랙웰 GPU와 36개의 그레이스 CPU를 연결, 이를 통해 72개의 GPU가 하나의 거대한 컴퓨팅 칩 역할을 한다. 특히 이전 세대보다 두배인 양방향 초당 1.8테라바이트 대역폭을 제공한다.

황 CEO는 CES 키노트에서 "1.5톤의 무게로 60만개의 부품으로 이뤄졌으며, 이는 자동차 20대와 맞먹는 규모"라고 소개했다. 또 120킬로와트(kW)의 전력이 소비되며, 3.2kg의 구리 케이블과 5000개의 케이블을 사용했다고 밝혔다. 특히 "제조 과정은 믿기 어려울 정도"라고 강조한 바 있다.

잘 알려진 대로 MS는 엔비디아의 최고 고객이다. 글로벌 시장조사기관 옴디아의 분석에 따르면, 지난해 엔비디아 주력 칩 '호퍼'를 48만5000개나 구입했다. 이는 전체 판매된 호퍼 GPU 중 20%에 해당하는 것으로, 다른 회사의 두배가 넘는 수치다. 따라서 신제품을 제품을 가장 먼저 받아본 것이다.

지난 10월에도 MS는 가장 먼저 블랙웰 서버를 구축했다고 자랑한 바 있다. 당시에는 애저 공식 X 계정을 통해 자체 구축한 엔비디아 'GB200' 서버를 공개했다.

이번 NV링크는 역시 오픈AI의 모델 구축에 투입된 것으로 볼 수 있다. 오픈AI는 최근 GPT-5, 일명 '오라이온'의 성능 향상에 어려움을 겪는 것으로 알려졌는데, 현존 최고의 슈퍼컴퓨터를 통해 어떤 결과를 낼지 주목된다.

---

## [9] 오픈AI, 로봇 개발 공식화..."하드웨어 전문가 모집"

URL: https://www.aitimes.com/news/articleView.html?idxno=167052

![이미지](https://cdn.aitimes.com/news/photo/202501/167052_181739_4056.png)

*오픈AI가 AI 개발을 담당한 '피규어 02' (사진=피규어 AI)*

오픈AI가 휴머노이드 로봇 개발을 공식화했다. 로봇팀을 소개하고 하드웨어 전문가 모집에 나섰다.

오픈AI는 10일(현지시간) 홈페이지를 통해 시스템 통합 전기 엔지니어와 로봇공학 전문가를 구인 공고를 게시했다. 이를 통해 로봇팀을 소개하고 역할도 설명했다.

"우리의 로보틱스 팀은 범용 로보틱스의 잠재력을 극대화하고 역동적이고 실제적인 환경에서 AGI 수준의 지능을 구축하는 데 주력하고 있다"라며 "고수준 AI 기능을 물리적 제약과 완벽하게 조화시키기 위해 노력한다"라고 밝혔다.

또 "팀에 합류해 로봇 시스템을 처음부터 설계하고 통합하는 일을 맡을 경험이 풍부한 로봇 시스템 통합 및 전기 엔지니어를 찾고 있다"라고 전했다. 이에 따라 전기 공학 분야에서 강력한 배경, 실무 문제 해결 능력, 실리콘 선택 및 PCB 관리에 대한 전문 지식을 갖추고 있어야 한다고 강조했다.

같은 날 오픈AI 기술 스태프이자 메타에서 AR 안경 책임자를 맡았던 케이틀린 칼리노프스키는 회사가 처음으로 하드웨어 로봇 인력을 채용한다는 소식을 알리는 메시지를 X(트위터)에 게시했다. 그는 2개월 전 오픈AI가 "로봇공학과 소비자 하드웨어를 이끌기 위해 채용했다"라고 발표했던 인물이다.

칼리노프스키는 "두명의 고위 기술 책임자 엔지니어링(IC) 역할과 TPM 관리자가 포함된다"라며, 로봇의 센서 제품군을 설계하는 데 도움이 되는 'EE 감지 엔지니어'와 로봇의 기어와 액추에이터, 모터 및 연결 장치를 설계한 경험이 있는 '로봇 기계 설계 엔지니어'가 포함된다고 설명했다.

이어 "이 작업을 시작하는 것이 너무 기대된다. 오픈AI에서 2개월을 지내며 이곳이 기술 작업을 하기에 정말 훌륭한 장소라는 것을 알았다. 우리와 함께하길 바란다"라는 글을 올렸다.

https://twitter.com/kalinowski007/status/1877809579154948223

앞서 지난해 6월에는 오픈AI가 4년 전 해체했던 로봇팀을 부활시켰다는 소식이 전해졌다. 당시 투자했던 로봇 스타트업 피규어 AI와 파트너십을 맺고 로봇 AI 구축에 나섰다는 내용이었다.

또 지난달 24일에는 디인포메이션이 내부 소식통을 인용, 오픈AI가 휴머노이드 로봇 개발을 검토 중이라고 보도했다. 따라서 이번 공고는 소프트웨어 개발을 넘어 하드웨어 개발까지 직접 나서기로 결정했다는 내용이다.

오픈AI는 제작할 로봇이 구체적으로 어떤 형태인지는 밝히지 않았다. 그러나 공고에 등장한 내용과 이제까지 피규어AI와 작업했던 경험 등을 종합하면 휴머노이드가 될 가능성이 높다. 휴머노이드는 인공지능(AI)을 탑재할 가장 부가가치가 높은 애플리케이션으로 꼽히기 때문이다.

이 분야에는 일론 머스크 CEO의 테슬라를 비롯해 아마존과 현대차그룹 계열사인 보스턴 다이내믹스는 물론, 마이크로소프트와 엔비디아 등의 지원을 받는 피규어AI와 아마존이 투자한 어질리티 로보틱스, 생츄어리 등 스타트업 등이 포진해 있다.

또 크런치베이스의 자료에 따르면, 로봇은 지난해 벤처 캐피털로부터 64억달러(약 9조4,330억원)의 투자가 이뤄지는 등 유망 분야로 꼽히고 있다. 국내에서도 삼성전자와 LG전자가 이번 CES에서 모두 로봇에 집중할 뜻을 밝힌 바 있다.

---

## [10] 챗GPT, 캐릭터 챗봇으로 확장하나...일부에 '성격' 설정 공개

URL: https://www.aitimes.com/news/articleView.html?idxno=167023

![이미지](https://cdn.aitimes.com/news/photo/202501/167023_181701_343.jpg)

*(사진=셔터스톡)*

오픈AI가 '챗GPT'의 성격을 설정할 수 있는 새로운 기능을 도입했다.

테크크런치는 9일(현지시간) 일부 사용자가 X(트위터)를 통해 웹 버전 챗GPT의 사용자 지정 메뉴가 개편됐다고 밝힌 내용을 소개했다.

이를 통해 사용자는 챗GPT에 이름과 별명, 직업 등을 지정할 수 있으며, 챗봇의 ‘특성’까지 설정할 수 있다. 오픈AI는 그 예로 ‘수다스러운’ ‘활기찬’ ‘Z세대 같은’ 등을 추천 리스트에 올렸다.

또 이 기능은 기존에 사용자와의 대화 내용을 기억하는 '메모리'와는 다른 것으로 알려졌다. 이보다는 모델의 정책을 결정하는 '시스템 프롬프트'에 가깝다.

다만, 이 기능은 현재 일부 사용자만 이용 가능한 것으로 보인다. 또 일부 사용자들은 새로운 메뉴가 일시적으로 나타났다가 사라졌다고 전했다.

오픈AI도 이 기능에 대해서는 언급이 없다. 즉, 일종의 테스트로 보인다.

https://twitter.com/testingcatalog/status/1877457357715750995

이번 개편은 기술 업그레이드라기보다 인터페이스를 개선한 것으로 보인다. 기존 사용자 지정 설정은 '프롬프트 엔지니어링'을 활용해 챗GPT의 응답 스타일과 톤을 사용자 요구에 맞게 조정했다. 새롭게 바뀐 메뉴 역시 동일한 기술을 사용하지만, 이를 보다 직관적이고 편리하게 사용할 수 있도록 디자인한 점이 특징이다.

즉, 지난해부터 오픈AI는 모델 기능 향상과 함께 사용성 확장에도 집중하고 있다.

얼마 전 '챗GPT를 잘 사용하는 5가지 방법'을 공개한 것도 이런 맥락이다. 새 기능을 추가하는 것만큼, 현재 있는 기능을 잘 사용하도록 유도하는 것이다.

실시간 웹 검색 기능과 글쓰기 및 코딩 프로젝트에 적합한 ‘캔버스(Canvas)’ 인터페이스를 도입한 것도 비슷한 예다. 검색 추가는 사람들이 챗봇을 검색 용도로 많이 활용한다는 데 집중한 것이며, 캔버스는 모델의 출력을 사용자가 직접 컨트롤할 수 있게 한 것이다.

챗GPT는 12월 기준 매주 3억명 이상이 사용하고 있다.

---


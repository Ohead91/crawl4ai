
---
title: ⚙️ Progress & Predictions 2025: Threats, harms and ethics
url: https://www.thedeepview.co/p/progress-predictions-2025-threats-harms-and-ethics
date: 250107
source: deepview
crawled_at: 2025-01-10T15:17:04.037351
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: Threats, harms and ethics 


# ⚙️ Progress & Predictions 2025: Threats, harms and ethics 
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) January 07, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37da8045-e9bd-49ba-bfc7-4bd07f1972be/Banner_Image-2.jpg?t=1735051388)
**Good morning.** In this second part of our special edition series, we’re breaking down the dark side of artificial intelligence, the moral and ethical challenges and questions posed by the increasing proliferation of the technology. 
The issues, as always, are manifold.
**Relatedly** , check out the [latest episode of our podcast](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/5-identity-hijacking-the-fight-against-ai-fraud-vijay-balasubramaniyan?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), an interview with Pindrop about battling audio deepfakes. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
# **The ethics of AI**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7c460004-90be-4203-b068-d895139ef432/4.jpg?t=1735051448)
Source: Created with AI by The Deep View
At the beginning of 2024, the ethics of generative artificial intelligence came into focus in a major way, centered in a dark spotlight around Taylor Swift; a series of sexually explicit, AI-generated deepfakes of the singer [went viral on social media](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), leading to a weeks-long period in late January and early February where it became hard to avoid a positive flood of explicit, AI-generated photos of a number of female celebrities. 
Eventually, accounts were banned and the photos were removed, but the problem didn’t go away. 
**Deepfake harassment** : This kind of deepfake harassment wasn’t a new phenomenon; it’s been [going on since at least 2017.](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) But, back in that pre-GenAI era, it took bad actors hours or even days to produce just one deepfake image; and even then, it wasn’t all too convincing. 
  * GenAI, on the other hand, allows anyone to very quickly produce highly realistic images, all resulting from short, simple English prompts — the days of having to understand coding languages in order to mess around with these kinds of algorithms are long gone. 
  * The issue quickly escalated beyond Taylor Swift, leading to a deepfake crisis in schools [around the world](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/crime/general/deepfake-crisis-at-schools-crimes-stoke-distrust-fear/ar-AA1v3u5M?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>). This began at the end of 2023 with [students at a New Jersey high school](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and has [since grown rampant](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-deepfake-revenge-porn-victim-aims-to-change-the-system?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>). In November, a [Pennsylvania private school was shut down over a deepfake nude scandal,](https://www.thedeepview.co/p/<https:/arstechnica.com/tech-policy/2024/11/school-failed-to-report-ai-nudes-of-kids-for-months-now-parents-are-suing/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) with parents filing lawsuits against the administration for not properly responding to the crisis. 


According to recent [research from the nonprofit Internet Matters](https://www.thedeepview.co/p/<https:/player.flipsnack.com/?hash=NjY1NkZDQkJEQzkrZGtsdmFzOGNqbA%3D%3D&p=2&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), some **13% of teenagers** say they have had experience with explicit deepfake image abuse. 
**A look back at related stories we’ve done in the past year:**
  * [AI cameras were quietly used to detect the emotions of UK passengers](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-cameras-quietly-used-detect-emotions-uk-train-passengers>)
  * [Department of Homeland Security: The ‘world needs to be aware of the inherent risk of deepfakes’ ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/department-homeland-security-world-needs-aware-inherent-risk-deepfakes>)
  * [ElevenLabs’ latest release highlights the issue of digital necromancy](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/elevenlabs-latest-release-highlights-the-issue-of-digital-necromancy>)


In the U.S., **there remains no federal legislation** regarding this kind of deepfake abuse. The [Defiance Act,](https://www.thedeepview.co/p/<https:/www.congress.gov/bill/118th-congress/senate-bill/3696/text?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) which would allow victims to sue over the spread of nonconsensual explicit deepfakes, passed the Senate over the summer, but has yet to pass the House. Legislation regarding the matter remains patchwork at best in the states; and while the policymakers debate regulatory approaches, the problem persists, with dozens of websites specifically marketed as AI-powered ‘nudify’ tools**remaining operational.**
The city of San Francisco in August [filed suit against 16 of those websites](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>). 
# The wider impacts
**But the ethical impacts of deepfakes** stretch far beyond image abuse and into weaponized identity hijacking that has enabled the spread of a truly concerning variety of misinformation. 
  * Even as AI-powered [vocal fraud has become something of a norm](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-tech-company-is-tackling-recent-proliferation-deepfake-fraud?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) — _phone calls from AI-generated relatives asking for money, for instance_ — political and election-related fraud and misinformation spread throughout much of last year; this began with a deepfaked robocall of [President Joe Biden that circulated in February,](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-the-company-that-traced-fake-biden-robocall-identifies-a-synthetic-voice?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>) encouraging New Hampshire voters to not participate in the primary. As the election drew nearer, Elon Musk took to [sharing AI-generated images and videos of Biden and Vice President Kamala Harris](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/news/politics/how-elon-musk-and-a-kamala-harris-deepfake-ad-sparked-a-debate-about-free-speech-and-parody/ar-BB1r2j6o?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>). 
  * Both [Meta](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and [OpenAI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/deepfakes-spiked-245-year>) have detailed their efforts to shut down covert influence operations that had been attempting to utilize the generative AI products operated by the two companies; looking back at the U.S. election last year, Meta said that it prevented nearly 600,000 requests to generate images of the candidates, [adding that the risks](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) of electoral interference from generative AI**“did not materialize in a significant way and that any such impact was modest and limited in scope.”**


**It’s not just election-related information;** AI-generated books, images and articles have spread across the internet, threatening widespread information pollution that has already had dangerous impacts. 
In August, we wrote about a British family who was [poisoned after using](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>) what turned out to be an AI-generated mushroom hunting guidebook; in the process, I discovered several AI-generated mushroom guidebooks listed on Amazon, [which the company removed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>) following my request for comment. 
And, pivoting away from the deepfake side of things, issues of generative AI leading to mass surveillance and algorithmic discrimination have proliferated: a November investigation uncovered [discrimination baked into Denmark’s digitized social welfare program](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-mass-surveillance-and-human-rights-violations-in-denmark>); the [steady adoption of AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cops-are-starting-to-use-ai-to-write-their-reports>) into already [discriminatory predictive policing efforts](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>) has continued; and the adoption of generative AI by [hospitals has](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>) continued, leading to many concerned nurses and patients alike. 
**A look back at related stories we’ve done in the past year:**
  * [I downloaded Character AI. It’s profoundly disturbing](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>)
  * [Researchers call for the abolishment of ‘carceral’ AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>)
  * [US Commission calls for ‘Manhattan Project’ for AGI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-commission-recommends-manhattan-project-for-ai>)


The psychological, sociological impacts of AI companionship, meanwhile, came into sharp focus when a [boy died by suicide after falling in love with a Character AI chatbot.](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>) To date, a [second lawsuit has been filed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/character-ai-sued-for-mental-health-decline-in-teenage-users-allegedly-encouraged-user-to-murder-his>) against the company by the mother of a teenage boy who, she argues, became mentally ill and unstable due to a close relationship with bots on Character. 
And the environmental impacts of increasing investments in generative AI, meanwhile, have steadily pushed much of the [Big Tech sector further from achieving their climate goals](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-grid-is-the-most-complicated-machine-ever-built-ai-is-stressing-it-out>), with the bulk of these giants — Meta, Google, Microsoft and Amazon — [pursuing nuclear power specifically to meet their AI energy requirements](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>) _._ But, before the nuclear comes online, AI data centers are taking advantage of fossil fuels, a situation that is leading to spiking emissions and a [burgeoning public health crisis](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-artificial-intelligence>) due to steadily worsening air quality. 
There’s also the general cybersecurity war that’s been taking place, with cybercriminals vastly [empowered by generative AI tools,](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/civais-latest-program-can-deepfake-5-seconds>) which have introduced specificity, speed and scale to their operations. Cybersecurity officials have, meanwhile, adopted [generative AI tools to fight back against ever-increasing attacks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-ai-and-cybersecurity-in-the-enterprise>), even as others work to educate companies and individuals about the [myriad security risks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-experts-say-artificial-intelligence-is-an-incredibly-vulnerable-technology#true-price-of-ai>) posed by AI, with AI and because of AI. 
On top of all this, there are ongoing legal battles regarding the legality of training generative AI models on copyrighted material, even as those models are beginning to be used to replace human workers, a challenging dynamic for the job market going forward. 
In sum, 2024 was a busy year of AI proliferation and integration, and the resulting moral and ethical impacts are vast, to say the least. 
The experts I spoke to expect 2025 to be worse. 
**Looking ahead:****Nell Watson, an author and leading AI ethicist,** told me that, with the rise of the increasingly autonomous agentic AI that we talked about yesterday, “ordinary members of the public will be tasked with teaching and managing these systems, something that**remains a major, uncertain challenge even for experts.”**
  * “Beyond alignment issues, agentic AI systems will certainly be employed to target systems and individuals for various kinds of attack, whether its creating designer synthetic data to poison another model (possibly even hijacking it in the process),” she said. “A friendly being must try to learn, model and accommodate the preferences of others. This is another strength of agentic systems, which could learn to surprise and delight us as a good friend might. However, these same capabilities can be used to observe human foibles, to strike at an exploitable weakness at a calculated moment of greatest impact.”
  * “The transition to agentic AI represents both unprecedented opportunity and risk, and this requires an investment in thoughtful governance to harness its potential while mitigating dangers. We must not only ensure that these powerful AI systems are used in an ethical manner, but we must now also work to ensure that these systems remain safe and loyal partners instead of impish and capricious minions.”


**Ajay Amlani, president of iProov, expects deepfake fraud** specifically to become fully weaponized in 2025: “a wave of account takeovers and fraudulent transactions will force banking regulators worldwide to take decisive action. Led by pioneers like Thailand and Vietnam, countries will mandate the implementation of biometric verification for payment authentication,” he said. 
Amlani added that he expects a “deepfake of a Fortune 500 CEO will cause significant disruption in the financial markets.” 
  * “The fabricated video, announcing a false merger, will trigger a temporary market dip and erode investor confidence before being exposed. This incident will highlight the growing need for robust identity verification solutions to ensure the authenticity of information and maintain trust in an increasingly digital world,” he said. 
  * “This incident will serve as a catalyst, accelerating the adoption of advanced identity verification solutions in the financial industry.”


**Typeform CPO Aleks Bass said that people will** “get scammed at a higher rate than what we are seeing now. 
“We might start asking ourselves, **‘is AI really worth it?’** We will see more companies investing money and time into locking down experiences and adding additional security, validation and verifications to prevent some of these abuses. But the challenge will be to create nearly invisible solutions, so as not to interrupt the customer experience.”
Aleks Bass 
**A look back at related stories we’ve done in the past year:**
  * [Amazon pulls AI-generated books after Deep View inquiry](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>)
  * [US hospital gets an AI assistant](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant>)
  * [The current harms and real-world impacts of algorithmic discrimination](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>)
  * [Meta and Big Tech’s nuclear revolution](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>)


**Cybersecurity firm Exabeam expects,** similar to much of what we’ve already discussed, highly enhanced and empowered cybercriminals, leading to new types of attacks and increasing exploitation. 
**Steve Povolny, one of Exabeam’s co-founder** s, said that, in 2025, “AI will democratize malware creation.”
  * “You won’t need to be a coder to create sophisticated malware in 2025 — AI will do it for you. Generative AI models trained specifically to generate malicious code will emerge in underground markets, making it possible for anyone with access to deploy ransomware, spyware and other types of malware with little effort,” he said. 
  * “Blindly trusting AI-generated outputs will become a major vulnerability for organizations. This will lead to the rise of a new cybersecurity mandate: **‘Zero Trust for AI.** ’ Unlike traditional Zero Trust principles, Zero Trust for AI is not a prediction for the future; it’s a concept ready for discussion now, bringing a nuanced approach to trusting AI. This framework will require organizations to verify, validate and fact-check AI outputs before allowing them to drive critical security decisions.”


Povolny thinks that video-based deepfakes will soon become “imperceptible from reality,” unleashing a “devastating new wave of social engineering attacks” that will allow “criminals to impersonate executives, forge high-stakes transactions, and extract massive payouts from unsuspecting victims. With AI making deepfakes accessible at the push of a button, the potential for financial fraud will explode, forcing organizations to rethink how they verify identity in an increasingly deceptive world.”
**Harry Muncey, Senior Director of Data Science** , and Responsible AI at Elsevier, expects the adoption of generative AI to continue, leading to improved confidence in “low-risk use cases” that “will lead to pressure for innovation and use in higher-risk environments, such as healthcare, where the need for robust guardrails is clearly critical.”
**And Vijay Balasubramaniyan** , the co-founder of CEO of Pindrop, expects deepfake attacks to “accelerate at an alarming rate” next year. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
I wholeheartedly expect — and I really hope I am wrong — that the ethical challenges related to artificial intelligence will become much more significant throughout 2025 as adoption continues, legislation lags and systems become more capable. 
A year ago, I saw no clear solution to the problem of deepfake abuse and harassment; I think we have made no progress on that front whatsoever. Instances will continue to occur at small and large scales. People will get hurt. And while I do worry about misinformation and its spread online, I am far more concerned about schools and this new, dangerous form of bullying and harassment that, without governance, oversight and regulation, will continue unabated. 
I also expect addictions to and obsessions with anthropomorphized GenAI chatbots to steadily spike as vulnerable people interact with these systems, leading to a heavy, noticeable increase in digital isolation, something that may start to become more clearly associated with mental health struggles. 
I expect we will additionally begin to see the problems of overreliance, specifically in high-risk environments. Hospitals, I think, will run into at least a few well-publicized instances regarding generative AI misuse.
As with any problem, things have to get worse before they get better — I think 2025 will be the year that these issues move off the fringe to become more mainstream; only then might action be taken against them. I do not expect that action to come soon, however. 
On the copyright front, I think we’ll see some significant movement from the big copyright infringement cases this year (Authors Guild and New York Times) that may — and that’s a very big ‘may’ — have implications for the future development of foundation models. I don’t expect mass job loss anytime soon — or at all, really — but I do think we’ll start to see a reduction in hiring due to internal reliance on AI tools. 
On the environmental front, the optimist in me hopes that the sheer cost of data center operation will drive massive innovations in energy efficiency, which will have positive impacts on sustainability. This, however, might very well be wishful thinking; the complexity and use of generative AI systems continues to grow, meaning energy efficiencies will simply free developers up to handle bigger workloads, rather than reducing their energy use. 
My areas of biggest concern involve algorithmic surveillance and discrimination, unsustainability, deepfake abuse and artificial companionship; as these issues continue to worsen — I expect them all to become hallmarks of this next year — global society will be pushed to the edge of truly radical transformation. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/61e53a7b-bfa9-4a5f-b63e-b5d84cb40b9f/Lodge_REAL-min.jpg?t=1735051636)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/108198e8-1f67-4a3c-b4ae-80e4a723306f/lodge_fAKE-min.png?t=1735051644)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/caaa1429-8a8d-4e34-b15e-eeff2bb13199/Real_or_Not_Template-3.jpg?t=1736213763)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The fake sled appears to be pulling the dogs.”


#### Selected Image 1 (Left): 
  * “Image 2 just looks fake.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Nvidia, chip stocks pop after Foxconn reports record revenue ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/06/global-chip-stocks-climb-on-foxconn-results-ai-server-demand.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Samsung claims its Ballie AI robot will actually be released this year ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/6/24337478/samsung-ballie-robot-release-date-features-2025?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * US crackdown leads Chinese firms to set their sights overseas ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/01/2025/us-crackdown-leads-chinese-firms-to-set-their-sights-overseas?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Google plays catch-up in video ad tech ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/google-plays-catch-up-in-video-ad-tech-as-streaming-ads-take-off?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Chip firms surge on hopes of strong AI-led demand ([Reuters](https://www.thedeepview.co/p/<https:/www.reuters.com/markets/us/chip-firms-surge-signs-strong-ai-led-demand-2025-01-06/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on agents in 2025: 
47% of you think 2025 will be the year of the AI agent. The rest … not so sure. 
**The year of the AI Agent:**
  * “And if that’s correct, he who holds the microphone will have a lot of sway over progressive adoption.”


**The year of the AI Agent:**
  * “Make Al more than trying to type and read my brain I want solutions and agents.”


### Thoughts on the ethical issues of AI next year?   
---  
  * [ Things are gonna get worse ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Things might start getting better - maybe there will be regulation ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No clue ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: ⚙️ Progress & Predictions 2025: Threats, harms and ethics
url: https://www.thedeepview.co/p/progress-predictions-2025-threats-harms-and-ethics
date: 250107
source: deepview
crawled_at: 2025-01-10T15:17:30.814218
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: Threats, harms and ethics 


# ⚙️ Progress & Predictions 2025: Threats, harms and ethics 
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) January 07, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37da8045-e9bd-49ba-bfc7-4bd07f1972be/Banner_Image-2.jpg?t=1735051388)
**Good morning.** In this second part of our special edition series, we’re breaking down the dark side of artificial intelligence, the moral and ethical challenges and questions posed by the increasing proliferation of the technology. 
The issues, as always, are manifold.
**Relatedly** , check out the [latest episode of our podcast](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/5-identity-hijacking-the-fight-against-ai-fraud-vijay-balasubramaniyan?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), an interview with Pindrop about battling audio deepfakes. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
# **The ethics of AI**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7c460004-90be-4203-b068-d895139ef432/4.jpg?t=1735051448)
Source: Created with AI by The Deep View
At the beginning of 2024, the ethics of generative artificial intelligence came into focus in a major way, centered in a dark spotlight around Taylor Swift; a series of sexually explicit, AI-generated deepfakes of the singer [went viral on social media](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), leading to a weeks-long period in late January and early February where it became hard to avoid a positive flood of explicit, AI-generated photos of a number of female celebrities. 
Eventually, accounts were banned and the photos were removed, but the problem didn’t go away. 
**Deepfake harassment** : This kind of deepfake harassment wasn’t a new phenomenon; it’s been [going on since at least 2017.](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) But, back in that pre-GenAI era, it took bad actors hours or even days to produce just one deepfake image; and even then, it wasn’t all too convincing. 
  * GenAI, on the other hand, allows anyone to very quickly produce highly realistic images, all resulting from short, simple English prompts — the days of having to understand coding languages in order to mess around with these kinds of algorithms are long gone. 
  * The issue quickly escalated beyond Taylor Swift, leading to a deepfake crisis in schools [around the world](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/crime/general/deepfake-crisis-at-schools-crimes-stoke-distrust-fear/ar-AA1v3u5M?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>). This began at the end of 2023 with [students at a New Jersey high school](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and has [since grown rampant](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-deepfake-revenge-porn-victim-aims-to-change-the-system?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>). In November, a [Pennsylvania private school was shut down over a deepfake nude scandal,](https://www.thedeepview.co/p/<https:/arstechnica.com/tech-policy/2024/11/school-failed-to-report-ai-nudes-of-kids-for-months-now-parents-are-suing/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) with parents filing lawsuits against the administration for not properly responding to the crisis. 


According to recent [research from the nonprofit Internet Matters](https://www.thedeepview.co/p/<https:/player.flipsnack.com/?hash=NjY1NkZDQkJEQzkrZGtsdmFzOGNqbA%3D%3D&p=2&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), some **13% of teenagers** say they have had experience with explicit deepfake image abuse. 
**A look back at related stories we’ve done in the past year:**
  * [AI cameras were quietly used to detect the emotions of UK passengers](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-cameras-quietly-used-detect-emotions-uk-train-passengers>)
  * [Department of Homeland Security: The ‘world needs to be aware of the inherent risk of deepfakes’ ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/department-homeland-security-world-needs-aware-inherent-risk-deepfakes>)
  * [ElevenLabs’ latest release highlights the issue of digital necromancy](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/elevenlabs-latest-release-highlights-the-issue-of-digital-necromancy>)


In the U.S., **there remains no federal legislation** regarding this kind of deepfake abuse. The [Defiance Act,](https://www.thedeepview.co/p/<https:/www.congress.gov/bill/118th-congress/senate-bill/3696/text?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) which would allow victims to sue over the spread of nonconsensual explicit deepfakes, passed the Senate over the summer, but has yet to pass the House. Legislation regarding the matter remains patchwork at best in the states; and while the policymakers debate regulatory approaches, the problem persists, with dozens of websites specifically marketed as AI-powered ‘nudify’ tools**remaining operational.**
The city of San Francisco in August [filed suit against 16 of those websites](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>). 
# The wider impacts
**But the ethical impacts of deepfakes** stretch far beyond image abuse and into weaponized identity hijacking that has enabled the spread of a truly concerning variety of misinformation. 
  * Even as AI-powered [vocal fraud has become something of a norm](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-tech-company-is-tackling-recent-proliferation-deepfake-fraud?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) — _phone calls from AI-generated relatives asking for money, for instance_ — political and election-related fraud and misinformation spread throughout much of last year; this began with a deepfaked robocall of [President Joe Biden that circulated in February,](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-the-company-that-traced-fake-biden-robocall-identifies-a-synthetic-voice?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>) encouraging New Hampshire voters to not participate in the primary. As the election drew nearer, Elon Musk took to [sharing AI-generated images and videos of Biden and Vice President Kamala Harris](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/news/politics/how-elon-musk-and-a-kamala-harris-deepfake-ad-sparked-a-debate-about-free-speech-and-parody/ar-BB1r2j6o?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>). 
  * Both [Meta](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and [OpenAI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/deepfakes-spiked-245-year>) have detailed their efforts to shut down covert influence operations that had been attempting to utilize the generative AI products operated by the two companies; looking back at the U.S. election last year, Meta said that it prevented nearly 600,000 requests to generate images of the candidates, [adding that the risks](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) of electoral interference from generative AI**“did not materialize in a significant way and that any such impact was modest and limited in scope.”**


**It’s not just election-related information;** AI-generated books, images and articles have spread across the internet, threatening widespread information pollution that has already had dangerous impacts. 
In August, we wrote about a British family who was [poisoned after using](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>) what turned out to be an AI-generated mushroom hunting guidebook; in the process, I discovered several AI-generated mushroom guidebooks listed on Amazon, [which the company removed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>) following my request for comment. 
And, pivoting away from the deepfake side of things, issues of generative AI leading to mass surveillance and algorithmic discrimination have proliferated: a November investigation uncovered [discrimination baked into Denmark’s digitized social welfare program](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-mass-surveillance-and-human-rights-violations-in-denmark>); the [steady adoption of AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cops-are-starting-to-use-ai-to-write-their-reports>) into already [discriminatory predictive policing efforts](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>) has continued; and the adoption of generative AI by [hospitals has](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>) continued, leading to many concerned nurses and patients alike. 
**A look back at related stories we’ve done in the past year:**
  * [I downloaded Character AI. It’s profoundly disturbing](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>)
  * [Researchers call for the abolishment of ‘carceral’ AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>)
  * [US Commission calls for ‘Manhattan Project’ for AGI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-commission-recommends-manhattan-project-for-ai>)


The psychological, sociological impacts of AI companionship, meanwhile, came into sharp focus when a [boy died by suicide after falling in love with a Character AI chatbot.](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>) To date, a [second lawsuit has been filed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/character-ai-sued-for-mental-health-decline-in-teenage-users-allegedly-encouraged-user-to-murder-his>) against the company by the mother of a teenage boy who, she argues, became mentally ill and unstable due to a close relationship with bots on Character. 
And the environmental impacts of increasing investments in generative AI, meanwhile, have steadily pushed much of the [Big Tech sector further from achieving their climate goals](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-grid-is-the-most-complicated-machine-ever-built-ai-is-stressing-it-out>), with the bulk of these giants — Meta, Google, Microsoft and Amazon — [pursuing nuclear power specifically to meet their AI energy requirements](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>) _._ But, before the nuclear comes online, AI data centers are taking advantage of fossil fuels, a situation that is leading to spiking emissions and a [burgeoning public health crisis](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-artificial-intelligence>) due to steadily worsening air quality. 
There’s also the general cybersecurity war that’s been taking place, with cybercriminals vastly [empowered by generative AI tools,](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/civais-latest-program-can-deepfake-5-seconds>) which have introduced specificity, speed and scale to their operations. Cybersecurity officials have, meanwhile, adopted [generative AI tools to fight back against ever-increasing attacks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-ai-and-cybersecurity-in-the-enterprise>), even as others work to educate companies and individuals about the [myriad security risks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-experts-say-artificial-intelligence-is-an-incredibly-vulnerable-technology#true-price-of-ai>) posed by AI, with AI and because of AI. 
On top of all this, there are ongoing legal battles regarding the legality of training generative AI models on copyrighted material, even as those models are beginning to be used to replace human workers, a challenging dynamic for the job market going forward. 
In sum, 2024 was a busy year of AI proliferation and integration, and the resulting moral and ethical impacts are vast, to say the least. 
The experts I spoke to expect 2025 to be worse. 
**Looking ahead:****Nell Watson, an author and leading AI ethicist,** told me that, with the rise of the increasingly autonomous agentic AI that we talked about yesterday, “ordinary members of the public will be tasked with teaching and managing these systems, something that**remains a major, uncertain challenge even for experts.”**
  * “Beyond alignment issues, agentic AI systems will certainly be employed to target systems and individuals for various kinds of attack, whether its creating designer synthetic data to poison another model (possibly even hijacking it in the process),” she said. “A friendly being must try to learn, model and accommodate the preferences of others. This is another strength of agentic systems, which could learn to surprise and delight us as a good friend might. However, these same capabilities can be used to observe human foibles, to strike at an exploitable weakness at a calculated moment of greatest impact.”
  * “The transition to agentic AI represents both unprecedented opportunity and risk, and this requires an investment in thoughtful governance to harness its potential while mitigating dangers. We must not only ensure that these powerful AI systems are used in an ethical manner, but we must now also work to ensure that these systems remain safe and loyal partners instead of impish and capricious minions.”


**Ajay Amlani, president of iProov, expects deepfake fraud** specifically to become fully weaponized in 2025: “a wave of account takeovers and fraudulent transactions will force banking regulators worldwide to take decisive action. Led by pioneers like Thailand and Vietnam, countries will mandate the implementation of biometric verification for payment authentication,” he said. 
Amlani added that he expects a “deepfake of a Fortune 500 CEO will cause significant disruption in the financial markets.” 
  * “The fabricated video, announcing a false merger, will trigger a temporary market dip and erode investor confidence before being exposed. This incident will highlight the growing need for robust identity verification solutions to ensure the authenticity of information and maintain trust in an increasingly digital world,” he said. 
  * “This incident will serve as a catalyst, accelerating the adoption of advanced identity verification solutions in the financial industry.”


**Typeform CPO Aleks Bass said that people will** “get scammed at a higher rate than what we are seeing now. 
“We might start asking ourselves, **‘is AI really worth it?’** We will see more companies investing money and time into locking down experiences and adding additional security, validation and verifications to prevent some of these abuses. But the challenge will be to create nearly invisible solutions, so as not to interrupt the customer experience.”
Aleks Bass 
**A look back at related stories we’ve done in the past year:**
  * [Amazon pulls AI-generated books after Deep View inquiry](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>)
  * [US hospital gets an AI assistant](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant>)
  * [The current harms and real-world impacts of algorithmic discrimination](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>)
  * [Meta and Big Tech’s nuclear revolution](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>)


**Cybersecurity firm Exabeam expects,** similar to much of what we’ve already discussed, highly enhanced and empowered cybercriminals, leading to new types of attacks and increasing exploitation. 
**Steve Povolny, one of Exabeam’s co-founder** s, said that, in 2025, “AI will democratize malware creation.”
  * “You won’t need to be a coder to create sophisticated malware in 2025 — AI will do it for you. Generative AI models trained specifically to generate malicious code will emerge in underground markets, making it possible for anyone with access to deploy ransomware, spyware and other types of malware with little effort,” he said. 
  * “Blindly trusting AI-generated outputs will become a major vulnerability for organizations. This will lead to the rise of a new cybersecurity mandate: **‘Zero Trust for AI.** ’ Unlike traditional Zero Trust principles, Zero Trust for AI is not a prediction for the future; it’s a concept ready for discussion now, bringing a nuanced approach to trusting AI. This framework will require organizations to verify, validate and fact-check AI outputs before allowing them to drive critical security decisions.”


Povolny thinks that video-based deepfakes will soon become “imperceptible from reality,” unleashing a “devastating new wave of social engineering attacks” that will allow “criminals to impersonate executives, forge high-stakes transactions, and extract massive payouts from unsuspecting victims. With AI making deepfakes accessible at the push of a button, the potential for financial fraud will explode, forcing organizations to rethink how they verify identity in an increasingly deceptive world.”
**Harry Muncey, Senior Director of Data Science** , and Responsible AI at Elsevier, expects the adoption of generative AI to continue, leading to improved confidence in “low-risk use cases” that “will lead to pressure for innovation and use in higher-risk environments, such as healthcare, where the need for robust guardrails is clearly critical.”
**And Vijay Balasubramaniyan** , the co-founder of CEO of Pindrop, expects deepfake attacks to “accelerate at an alarming rate” next year. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
I wholeheartedly expect — and I really hope I am wrong — that the ethical challenges related to artificial intelligence will become much more significant throughout 2025 as adoption continues, legislation lags and systems become more capable. 
A year ago, I saw no clear solution to the problem of deepfake abuse and harassment; I think we have made no progress on that front whatsoever. Instances will continue to occur at small and large scales. People will get hurt. And while I do worry about misinformation and its spread online, I am far more concerned about schools and this new, dangerous form of bullying and harassment that, without governance, oversight and regulation, will continue unabated. 
I also expect addictions to and obsessions with anthropomorphized GenAI chatbots to steadily spike as vulnerable people interact with these systems, leading to a heavy, noticeable increase in digital isolation, something that may start to become more clearly associated with mental health struggles. 
I expect we will additionally begin to see the problems of overreliance, specifically in high-risk environments. Hospitals, I think, will run into at least a few well-publicized instances regarding generative AI misuse.
As with any problem, things have to get worse before they get better — I think 2025 will be the year that these issues move off the fringe to become more mainstream; only then might action be taken against them. I do not expect that action to come soon, however. 
On the copyright front, I think we’ll see some significant movement from the big copyright infringement cases this year (Authors Guild and New York Times) that may — and that’s a very big ‘may’ — have implications for the future development of foundation models. I don’t expect mass job loss anytime soon — or at all, really — but I do think we’ll start to see a reduction in hiring due to internal reliance on AI tools. 
On the environmental front, the optimist in me hopes that the sheer cost of data center operation will drive massive innovations in energy efficiency, which will have positive impacts on sustainability. This, however, might very well be wishful thinking; the complexity and use of generative AI systems continues to grow, meaning energy efficiencies will simply free developers up to handle bigger workloads, rather than reducing their energy use. 
My areas of biggest concern involve algorithmic surveillance and discrimination, unsustainability, deepfake abuse and artificial companionship; as these issues continue to worsen — I expect them all to become hallmarks of this next year — global society will be pushed to the edge of truly radical transformation. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/61e53a7b-bfa9-4a5f-b63e-b5d84cb40b9f/Lodge_REAL-min.jpg?t=1735051636)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/108198e8-1f67-4a3c-b4ae-80e4a723306f/lodge_fAKE-min.png?t=1735051644)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/caaa1429-8a8d-4e34-b15e-eeff2bb13199/Real_or_Not_Template-3.jpg?t=1736213763)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The fake sled appears to be pulling the dogs.”


#### Selected Image 1 (Left): 
  * “Image 2 just looks fake.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Nvidia, chip stocks pop after Foxconn reports record revenue ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/06/global-chip-stocks-climb-on-foxconn-results-ai-server-demand.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Samsung claims its Ballie AI robot will actually be released this year ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/6/24337478/samsung-ballie-robot-release-date-features-2025?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * US crackdown leads Chinese firms to set their sights overseas ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/01/2025/us-crackdown-leads-chinese-firms-to-set-their-sights-overseas?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Google plays catch-up in video ad tech ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/google-plays-catch-up-in-video-ad-tech-as-streaming-ads-take-off?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Chip firms surge on hopes of strong AI-led demand ([Reuters](https://www.thedeepview.co/p/<https:/www.reuters.com/markets/us/chip-firms-surge-signs-strong-ai-led-demand-2025-01-06/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on agents in 2025: 
47% of you think 2025 will be the year of the AI agent. The rest … not so sure. 
**The year of the AI Agent:**
  * “And if that’s correct, he who holds the microphone will have a lot of sway over progressive adoption.”


**The year of the AI Agent:**
  * “Make Al more than trying to type and read my brain I want solutions and agents.”


### Thoughts on the ethical issues of AI next year?   
---  
  * [ Things are gonna get worse ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Things might start getting better - maybe there will be regulation ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No clue ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



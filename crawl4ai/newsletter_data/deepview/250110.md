
---
title: No Title
url: https://www.thedeepview.co/p/progress-predictions-2025-investing-trends
date: 250110
source: deepview
crawled_at: 2025-01-10T15:38:50.659655
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: Investing trends


# ⚙️ Progress & Predictions 2025: Investing trends
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>) January 09, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-investing-trends>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-investing-trends&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-investing-trends>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-investing-trends>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9321c342-378e-49e3-983a-170a2f1b85e7/Banner_Image-4.jpg?t=1735052567)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/35021972-5cf0-486f-9126-d3679f5d81e5/Together_W_Tines.png?t=1736282535)](https://www.thedeepview.co/p/<https:/www.tines.com/access/guide/securing-ai-in-the-enterprise?utm_source=paid&utm_medium=media&utm_campaign=thedeepview-primary-0901>)
**Good morning.**
Before we get into it, if you’re out in LA right now, I hope you and your families are staying safe. You can find some fire department resources [here](https://www.thedeepview.co/p/<https:/lafd.org/news/palisades-fire-0?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>). 
Today, we’re getting into the money behind AI. The numbers for 2024 are astronomical, whether you’re looking at capital expenditures, stock surges or VC investments. 
And all the trends are seemingly angled up for 2025.
— Ian Krietzberg, Editor-in-Chief, The Deep View 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Overcoming Challenges in AI Adoption for IT and Security Leaders**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/91098a82-c089-453f-8b20-965844b0aed9/Ad_600x400.png?t=1736282620)](https://www.thedeepview.co/p/<https:/www.tines.com/access/guide/securing-ai-in-the-enterprise?utm_source=paid&utm_medium=media&utm_campaign=thedeepview-primary-0901>)
AI adoption in the enterprise can feel like an uphill battle, as conflicting priorities, unclear ROI, evolving regulations, and security risks add layers of complexity.
That’s why Tines wrote [Securing AI in the Enterprise: A step-by-step guide for IT and security leaders.](https://www.thedeepview.co/p/<https:/www.tines.com/access/guide/securing-ai-in-the-enterprise?utm_source=paid&utm_medium=media&utm_campaign=thedeepview-primary-0901>) This guide is designed to help IT and security leaders take a proactive, security-first approach to AI adoption, with practical strategies to address some of the biggest challenges.
From AI skeptics to believers to enthusiasts, you’ll get tactical advice on what safe and successful AI adoption looks like – and how your security team can accomplish it.
Get the [Securing AI in the Enterprise guide](https://www.thedeepview.co/p/<https:/www.tines.com/access/guide/securing-ai-in-the-enterprise?utm_source=paid&utm_medium=media&utm_campaign=thedeepview-primary-0901>) today to start making real progress toward achieving your AI adoption goals.
# **The 2024 tech surge**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/60c97193-4939-49a2-962d-1f331e725e51/3.jpg?t=1735052665)
Source: Created with AI by The Deep View
A consistent undercurrent to the AI story — riding somewhere beneath regular announcements of new models and new capabilities and sci-fi visions of a fully autonomous future — involves a vast investment landscape. 
These models are costly to the point of being cost-prohibitive, for almost anyone who lacks pockets the size of those wielded by Big Tech and venture capitalists around the world. 
And surrounding that landscape is a combination of blind excitement, tempered excitement, caution and blistering criticism. 
There are two sides to this story. The first involves the public market and Wall Street — the ways in which AI-exposed stocks have performed, and the impression of the analysts that study them. 
And despite rising costs, surging capital expenditures and little revenue to show for it, the AI names have spent the past year riding a wave of investor excitement to truly record-breaking heights. 
## **The AI Boom**
In 2024, as with 2023, powerful, ceaseless stock surges from the tech sector continued to lift markets ever higher. The tech-heavy **Nasdaq finished the year up 29%** ; the **S &P 500 was up 23%** (_after a 24% surge the year before_) and the **Dow Jones Industrial Average was up around 13%**. This push was led by a handful of tech stocks, most of which have clear exposure to artificial intelligence. 
Here, I’m talking about Nvidia, Microsoft, Meta, Google, Amazon, TSMC and Tesla.
(Tesla is a bit of a weird case — its late-year surge seems tied to President-elect Donald Trump’s win in November, more than the company’s AI or electric vehicle business, but still, the **stock spiked more than 60% in ‘24,** following a year in which it _spiked more than 100%)._
**A look back at related stories we’ve done in the past year:**
  * [Interview: The mismatch of the AI bubble](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-the-mismatch-of-the-ai-bubble>)
  * [The math behind the AI bubble](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-math-behind-the-ai-bubble>)
  * [Goldman Sachs publishes blistering report on the AI bubble](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/goldman-sachs-publishes-blistering-report-on-ai-bubble#true-price-of-ai>)


## **How high did they fly?**
Nvidia, the maker of those (insanely) expensive “picks and shovels” for the AI race — the GPU chips vital to the training and operation of AI models — **surged some 171% in 2024** (_following a 240% spike the year before_). On Dec. 30, 2023, Nvidia’s market cap was $1.22 trillion; a year later, the company was valued at around $3.5 trillion. 
  * Shares of Microsoft, following a late-December retreat, spiked some 13% as its **valuation soared from $2.79 trillion last year to $3.1 trillion this year**. **Shares of Amazon spiked 50%** ; its market cap jumped from **$1.5 trillion at the end of 2023 to $2.4 trillion by the end of 2024**. Shares of **Google spiked roughly 37%** ; its **market cap jumped from around $1.6 trillion to $2.3 trillion**. 
  * **Meta, meanwhile, jumped around 70% in 2024;** at the end of 2023, it was valued at around $900 billion. **It is now valued at $1.5 trillion.** And in the span of a year, TSMC went from a $500 billion stock to **a trillion-dollar stock, surging nearly 100%**. 


Though this isn’t comprehensive, just this small handful of companies added hundreds of billions of dollars to their market caps in the past 12 months. 
But the stock surge is almost nothing compared to the capital expenditures this handful of companies has notched. 
## **But at what cost?**
Just Microsoft, Amazon, Meta and Google were [expected to collectively spend](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/business-spending-on-ai-jumps-500-to-13-8-billion-on-200-billion-in-capex>)**around $240 billion in capex** — all largely going to AI — by the end of 2024, a significant increase over last year’s numbers, according to Forbes. All of these firms have spent the past year assuring investors that their [capital expenditures ](https://www.thedeepview.co/p/<https:/www.fool.com/investing/2024/11/08/big-tech-capex-spending-is-set-to-soar-once-again/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)_[will increase in 2025](https://www.thedeepview.co/p/<https:/www.fool.com/investing/2024/11/08/big-tech-capex-spending-is-set-to-soar-once-again/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)_ as they work to build out AI infrastructure. 
And, while some have been quick to suggest that they are starting to see a bit of revenue from all of these massive expenditures, many of the big players here have made clear that **the AI game is a long one.**
Microsoft CFO Amy Hood said in August that its current investments in AI infrastructure will support the monetization of AI **“over the next 15 years and beyond.”** _Microsoft_ _[plans](https://www.thedeepview.co/p/<https:/blogs.microsoft.com/on-the-issues/2025/01/03/the-golden-opportunity-for-american-ai/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)_ _to spend some $80 billion on AI infrastructure in 2025 alone._
Meta CFO Susan Li similarly expects “returns from generative AI to come in over a longer period of time,” adding: “we don’t expect our GenAI products to be a **meaningful driver of revenue in ’24.** But we do expect that they’re going to open up new revenue opportunities over time that will enable us to generate a solid return off of our investment.”
And in the midst of this, some sectors of Wall Street have been losing patience.
D.A. Davidson analyst Gil Luria told [CNN](https://www.thedeepview.co/p/<https:/www.cnn.com/2024/08/02/tech/wall-street-asks-big-tech-will-ai-ever-make-money/index.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>) in August: “if you’re going to invest now and get returns in 10 to 15 years, that’s a venture investment, that’s not a public company investment. For public companies, we expect to get return on investment in much shorter time frames. So that’s causing discomfort, because we’re not seeing the types of applications and revenue from applications that we would need to justify anywhere near these investments right now.”
**A look back at related stories we’ve done in the past year:**
  * [AI companies need a lot of money. Investors are still forking it over](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-companies-need-a-lot-of-money-investors-are-still-forking-it-over>)
  * [OpenAI, others dealing with ‘diminishing returns’ in current architecture](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-others-dealing-with-diminishing-returns-in-current-architecture>)
  * [Competition and power consolidation in AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/competition-and-power-consolidation-in-ai>)


At around the same time, Goldman Sachs released a report titled: “[GenAI: Too much spend, too little benefit?](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/goldman-sachs-publishes-blistering-report-on-ai-bubble>)” In the report, Jim Covello, Goldman’s head of Global Equity Research, said that, considering the $1 trillion _(+)_ the industry is expected to spend on AI in the next few years, it remains unclear **what trillion-dollar problem AI will solve.**
“Replacing low-wage jobs with tremendously costly technology is basically the polar opposite of the prior technology transitions I’ve witnessed in my thirty years of closely following the tech industry,” he said, adding that, where the internet provided a low-cost solution to a high-cost problem, GenAI offers a high-cost solution to a low-cost problem. 
That high cost has thus far been eaten by the developers as a means of bringing people on board. And that brings us to the startups.
  * OpenAI, still the dominant developer in the generative AI race, **reportedly**[**lost**](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-this-year-on-3point7-billion-in-revenue.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)**$5 billion in 2024**. And that’s after it raked in $3.7 billion in revenue. And it expects these losses to keep on mounting. 
  * The Information reported in October that, according to internal documents, OpenAI [expects to spend some ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-s-long-costly-road-to-profitability>)[$200 billion between 2023 and 2030](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-s-long-costly-road-to-profitability>)[;](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-s-long-costly-road-to-profitability>) more than two-thirds of that amount is expected to go toward the training and deployment of its generative AI models. The startup expects to**lose $44 billion between 2023 and 2028,** saying that it expects to turn a $14 billion profit in 2029. 


Last year, it [raised $6.6 billion in funding](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-companies-need-a-lot-of-money-investors-are-still-forking-it-over>) at a $157 billion valuation; at the same time, it secured a $4 billion revolving line of credit. [It’s not just OpenAI, either](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>); xAI, through a Series B and C funding round both conducted in 2024, **raised a total of around $12 billion** for the year and **Anthropic raked in an additional $4 billion from Amazon**. The costs are almost incomprehensible, but a combination of Big Tech backers and venture capitalists are still interested in footing the bill. 
**And that brings us to** the private markets and the venture capitalists, and it tells a story that is both different and the same from the trends on Wall Street. 
In 2023, according to Crunchbase data, the AI sector raised $55.5 billion.
**In 2024, the sector raised $99.6 billion** , an 80% year-over-year increase. Around a third of that amount went to foundation model companies (largely, in billion-dollar raises). The remaining amount went to sectors seeking to drive an AI impact.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/25d5cea2-c012-4f1c-b768-92f791203003/Screenshot_2025-01-03_at_11.10.46_AM.png?t=1735920717)
The data here is pretty clear; VCs don’t care about high expenditures, low revenue and uncertain time horizons. They — even the skeptical ones — believe in artificial intelligence. 
Sequoia’s David Cahn [wrote last year](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-math-behind-the-ai-bubble>) that there was — at the time — a $600 billion gap in the AI industry, meaning simply that, considering the magnitude of the cost of development, the sector would need to bring in $600 billion in revenue — annually — to _just meet the scope of cost._
**Still, he believes in the potential of AI**. “In reality, the road ahead is going to be a long one. It will have ups and downs. But almost certainly it will be worthwhile.”
**As Pitchbook wrote in an August report** : “Valuations have ramped up, and despite high prices, VCs have consistently been willing to invest.”
So, Despite Goldman’s skepticism — and despite Wall Street’s feelings toward the high costs and long time horizon of generative AI — the stocks have inched ever higher, enterprise adoption of the technology is certainly growing, the costs of development are spiking, the private valuations are increasing and the VCs remain undeterred, all of which makes for a rather complicated picture.
**But, with adoption rates starting to increase, some investors are feeling good about 2025.**
**Wedbush’s Dan Ives, for one** , is super excited about what 2025 might hold for tech and AI. He expects tech stocks to soar another 25% in 2025 “based on underlying strength from the AI Revolution and the 2nd/3rd derivatives of this tidal wave of tech spending and AI cap-ex.”
  * Ives wrote that the $4 trillion market cap club will get “its first three members. We believe the first member of the $4 trillion market cap club will be Apple as the iPhone 16 brings the AI Revolution to Cupertino. In 2025 we also firmly expect both Nvidia and Microsoft to follow Apple in joining the exclusive $4 trillion market cap club as the AI Revolution takes hold into its next gear of growth.”
  * “We expect many enterprises and governments to aggressively head down the AI path with our view that **AI cap-ex budgets will exceed $1 trillion** and catalyze the next wave of use case and software buildouts across the consumer and enterprise landscape.”


**JPMorgan**[**wrote**](https://www.thedeepview.co/p/<https:/am.jpmorgan.com/gb/en/asset-management/institutional/insights/market-insights/investment-outlook/ai-investment/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)**in November** that it expects 2025 to see a broadening out of the market, rather than a bursting of the bubble. 
  * “The valuation gap between the biggest stocks (the megacaps) and the rest is unlikely to persist indefinitely. If the broad AI ecosystem generates sufficient revenues to justify the earnings expectations _already assumed for a handful of companies_ , **the ‘rest’ should catch up over time,”** according to JPM. “If instead, the broader corporate universe does not see the clear use case of these technologies and are unwilling to pay for them, **then a ‘catch down’ scenario is more likely.”**
  * “The strong fundamentals of the megacaps, both relative to other parts of the S&P 500 today, as well as relative to the 2000 tech bubble, provide some comfort that **a major ‘catch down’ is unlikely,”** according to JMP.


Still, the firm noted that the gap between revenue expectations, capital expenditures and actual revenue growth **will come into sharper focus next year, with investors saying:****“show me the money.”**
“If the developers and the integrators can’t generate sufficient profit,**this weakness will eventually spread up the value chain,”** JPM wrote. “In our view the gap between the valuation of mega-cap tech and the broader S&P 500 is unsustainable. However, unlike 2000, **we see a ‘catch up’ scenario as more likely** than a ‘catch down’ scenario.”
**[Sequoia expects](https://www.thedeepview.co/p/<https:/www.sequoiacap.com/article/ai-in-2025/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)****the question of investment returns** on AI spend to remain a problem in 2025, but also expects Big Tech capital expenditures to begin to stabilize. 
  * “Going into 2024, the Big Tech companies were nervous about AI being a threat to their oligopoly in the cloud business. Entering 2025, the picture has changed dramatically,” Sequoia wrote. “**Big Tech companies have their arms locked firmly around the AI revolution.** Not only do they control the vast majority of the data centers that power AI, but they own significant equity stakes in the big model companies, and they are among the largest backers of new AI startups.”
  * “With Big Tech feeling more confident, we think 2025 will be a stabilization year for AI CapEx. If 2024 was a scramble to sign deals for land and power,**2025 will be an execution year.** Shovels are in the ground, and these companies will be focused on completing their new projects on-time and on-budget. They will then need to sell this installed capacity to customers and work with enterprises to help them achieve success with their new AI capabilities.”


**A look back at related stories we’ve done in the past year:**
  * [2 years after ChatGPT, how VCs are approaching investing in](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/2-years-after-chatgpt-how-vcs-are-approaching-investing-in-ai>)
  * [OpenAI’s long, costly road to profitability](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-s-long-costly-road-to-profitability>)
  * [Health tech VC talks AI: If you buy into the hype, you’ll lose](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/health-tech-vc-talks-ai-if-you-buy-into-the-hype-you-ll-lose>)


**Deepwater Asset Management**[**believes**](https://www.thedeepview.co/p/<https:/deepwatermgmt.com/deepwaters-2025-predictions/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)**,** as it has said in the past, that we are in the second year of a 3-5 year AI-driven bull market **“that will end in the bursting of a bubble.”** Deepwater expects the Nasdaq to experience two 10% pullbacks in 2025, though it will still finish the year higher than it started. 
**Gené Teare, a senior data editor at Crunchbase** , expects “funding proportions to AI to **increase in 2025.** While foundation model companies might not raise as much as they did in 2024, AI infrastructure and applications will continue to see funding increase across multiple sectors."
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
OK, let’s talk about [reversion to the mean](https://www.thedeepview.co/p/<https:/www.investopedia.com/terms/m/meanreversion.asp?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>). 
It’s a financial theory that the price of an asset will eventually revert to its long-term average value; nothing rises forever, nothing falls forever. The hard part here is obviously figuring out the timing of such reversions. 
If you look at **historical sector weightings of the S &P 500,** tech has been on the rise in recent years. In 2024 it[**came in at 32.9%**](https://www.thedeepview.co/p/<https:/www.investopedia.com/best-25-sp500-stocks-8550793?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>) and in 2023 it was roughly 28.1%; things have been high and climbing since 2020 or so. 
Before the 2020 cycle, **the last time the weighting of the tech sector exceeded 28% was in 1999** , _during the peak of the dot-com bubble._
The average weighting of the tech sector of the S&P 500 — according to [data from Bespoke Investing Group](https://www.thedeepview.co/p/<https:/media.bespokepremium.com/uploads/2023/07/070323-Sector-Weights-5037189urijef.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>) — between **1990 and 2023 is 17.5%.** According to a [slightly different dataset,](https://www.thedeepview.co/p/<https:/einvestingforbeginners.com/historical-sp-500-industry-weights-20-years/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends#historical>) between 2002 and 2023, the average **weighting is 16.68%**. 
So, let’s split the difference and say that the average weighting of the S&P’s tech sector is 17%. **It is currently nearly double that average**. I see no reason why mean reversion will not kick in at some point here — this is what JPMorgan was talking about with their catch-up or catch-down scenarios. One of two things will happen; either the rest of the stocks will catch up and things will level out, or the tech stocks will fall to meet their non-tech peers. I think we’ll see a bit of both, and I think the catch-down might well begin in 2025 as investor impatience persists. 
At the same time, AI has been consuming an enormous amount of venture funding, a reality that just won’t continue forever. And, according to the VCs I’ve connected with, investing in AI has grown more challenging. Excitement might be far from dampened, but the landscape is becoming more expensive and more complex to invest in; I think the VC trends will start to falter next year, as well. 
We are pretty clearly in a bubble. Bubbles do two things; they expand, and they expand, and they expand … and then they burst. Again, nothing goes up forever. If the bubble swells another 20% next year, it would be approaching a danger point. 
I don’t know what the burst will look like — _the dot-com burst didn’t kill the internet, it just killed off a bunch of internet companies_ — but I am sure that it is coming, and probably coming soon. 
To make this trackable, I’ll say we’ll see the beginnings of a burst by the end of 2025, marking 2026 as the year the AI bubble comes apart. A lot of companies will fall, leaving the Big Tech giants in a clear field. When this happens, Nvidia will have a very tough go of things. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6b09a44a-72d3-40f9-bffc-c6991fc0e85f/Snowboard_REAL-min.jpg?t=1735052802)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/348c7500-5e8e-4f94-b1ba-4b31667f6ec0/Snowboard_FAKE-min.png?t=1735052806)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1fcc6bed-bf9f-4347-90c0-380a6a4c685a/Real_or_Not_Template-5.jpg?t=1736384789)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The fake one doesn't have supports/wires for the lifts and has a building with a tree growing on top of it.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/304c3211-9b4e-4f1b-b635-cc7a3c2f398e/Shrt_Stories_Blue_.png?t=1735051104)
  * **Sam Altman’s younger sister Annie****[has filed a lawsuit](https://www.thedeepview.co/p/<https:/www.nytimes.com/2025/01/08/technology/sam-altman-sister-lawsuit.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)** against her tech magnate brother, claiming that he sexually abused her for years. Sam denied the allegations in a statement shared on social media. 
  * **Apple Intelligence, Bloomberg’s Dave Lee****[argues](https://www.thedeepview.co/p/<https:/www.bloomberg.com/opinion/articles/2025-01-07/apple-intelligence-errors-dumb-mistakes-make-a-mockery-of-hyped-ai?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)****,** isn’t that intelligent. This comes in the wake of mounting instances of hallucinations combined with excessive storage requirements. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * What’s next for our privacy? ([MIT Tech Review](https://www.thedeepview.co/p/<https:/www.technologyreview.com/2025/01/07/1109301/privacy-protection-data-brokers-personal-information/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)). 
  * It is now illegal to use AI to deny a medically necessary health insurance claim in CA ([Latin Times](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/technology/artificial-intelligence/it-is-now-illegal-to-use-ai-to-deny-a-medically-necessary-health-insurance-claim-in-california/ar-AA1x3bVB?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)). 
  * Microsoft confirms performance-based job cuts across departments ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/08/microsoft-confirms-performance-based-job-cuts-across-departments.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)). 
  * Los Angeles wildfires come on heels of hottest year on record: Images reveal global devastation ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/08/2025/devastating-wildfires-los-angeles-palisades-california-hottest-year?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)).
  * Microsoft is reverting its Bing AI image generator because of quality complaints ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/8/24339450/microsoft-reverting-bing-image-creator-quality-complaints-dall-e-3-pr16-pr13?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-investing-trends>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on AI progress: 
45% are in the middle; 16% think robotaxis will become normal in 2025 and 18% think OpenAI will achieve a (meaningless) AGI in 2025.
**Middle:**
  * “If you follow or look into cognition-based science, you can see there is an extreme gulf between human and machine. LLMs and the present range of AI are nowhere near approaching the capabilities of the human mind. If you remember back to the AI shown in 2001: A Space Odyssey, you would have seen/heard the good doctor teaching the computer. Until we are at a point we can teach the AI, like we teach children, I suspect we have little to fear.”


### What do you think, a bubble burst in 2025?   
---  
  * [ Yep ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Nope, it'll keep going higher ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No idea ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/progress-predictions-2025-robots-avs-and-technical-advancements
date: 250110
source: deepview
crawled_at: 2025-01-10T15:38:55.775789
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: Robots, AVs and technical advancements


# ⚙️ Progress & Predictions 2025: Robots, AVs and technical advancements
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) January 08, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-robots-avs-and-technical-advancements>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-robots-avs-and-technical-advancements&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-robots-avs-and-technical-advancements>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-robots-avs-and-technical-advancements>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/870aa7c5-bf23-4507-91f3-9e4cf029279c/Banner_Image-3.jpg?t=1735051945)
**Good morning, and welcome to part 3 of our special edition series.**
In 2023, Waymo [delivered](https://www.thedeepview.co/p/<https:/waymo.com/blog/2023/12/dear-waymo-community-reflections-from-this-year-together?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) more than 700,000 trips. 
In 2024, the self-driving firm delivered more than four million rides. 
The past 12 months saw a lot of improvements in autonomous vehicles, robotics and the AI models that make them possible. But it also affirmed certain limitations, which grounds the technology in a rather interesting way. 
Let’s get into it. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
# **The rise of Waymo**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6d8b2e49-53c7-4340-b06d-418f69a7b6dc/2.jpg?t=1734452638)
Source: Waymo
By the end of 2024, [Waymo had expanded its operations](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-ai>) to serve a total of 500 square kilometers across its three major hubs: San Francisco, Los Angeles and Phoenix. And with those arenas on lock, the self-driving firm spent the year laying the foundation for an expansion into Austin, Atlanta, Miami and Tokyo set to take place in 2025. 
If you measure the rate of self-driving progress by Waymo alone, the company, at this point, has arguably established an operable robotaxi business. 
But scale, even for Waymo, remains a challenge at two different levels.
The first, of course, is cost. Waymo’s financials aren’t clear — parent company Google records Waymo’s numbers beneath its “Other Bets” umbrella, which disguises the full scope of Waymo’s revenue and losses. But, going just by the unit itself, the [loss seems to be narrowing](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-ai>); in the third quarter of 2024, the “Other Bets” unit reported $388 million in revenue and a $1.12 billion loss, a far smaller loss than the $1.98 billion reported the year before. 
The cost of each vehicle, meanwhile, is rumored to be somewhere in the region of $200,000.
All in, you certainly have a loss-making business. But the days of robotaxi revenues being perpetually on the horizon are over, at least for Waymo; the firm might well continue losing money for years, but it is finally generating a return. And investors seem sold on its potential; Waymo in 2024 closed a $5.6 billion funding round, led, unsurprisingly, by Google. 
You might call 2024 the year that Waymo pulled ahead. 
The other challenge of scale relates to safety. Thus far, Waymo has avoided any severe accidents and lawsuits, though it _is_[being investigated](https://www.thedeepview.co/p/<https:/www.cnn.com/2024/05/14/business/self-driving-cars-waymo-zoox-regulators-investigating/index.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) by the National Highway Traffic Safety Administration (NHTSA). It remains unclear how many miles are clocked by each vehicle in its fleet, the average distance of each ride and the [role and scope of its remote operators](https://www.thedeepview.co/p/<https:/arstechnica.com/cars/2024/05/on-self-driving-waymo-is-playing-chess-while-tesla-plays-checkers/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>); the [numbers have yet to scale to a point](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-complicated-statistics-behind-safe-self-driving-cars>) where they can support sweeping safety comparison against humans, and self-driving researchers remain skeptical that Waymo’s safety record will scale in kind with its expansion. 
# Sinking the competition
Now, those two issues of cost and safety have proved too much to overcome for other players in the robotaxi race. Cruise — until the end of 2023, Waymo’s most prominent competitor — was forced in 2023 to shutter its operations after a Cruise robotaxi struck and dragged a pedestrian. The self-driving unit spent 2024 very slowly, very cautiously, making its way back to the road, [only to be dissolved by parent General Motors](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/google-s-gemini-2-0-era-is-here>) due to issues of cost and too much competition. 
GM will be merging Cruise with its internal teams next year to pursue advanced driver-assist tech, rather than straight-up robotaxis. 
Amazon-owned Zoox, meanwhile — the only one making a robotaxi without traditional car controls — is [rolling slowly and](https://www.thedeepview.co/p/<https:/zoox.com/journal/zoox-robotaxi-in-san-francisco?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) steadily. In 2024, the firm began testing its services in San Francisco and expanded its Las Vegas test, with plans to begin welcoming public riders sometime in 2025. 
And that brings us to Tesla, the Elon Musk-owned company that has been steadily rolling out software updates to its misnamed Full-Self Driving software for months. See, Tesla is a bit of a weird case here, especially against a backdrop of robotaxi firms. The company, for years, now, has offered two different driver-assist softwares: Autopilot and Full-Self Driving (FSD). Despite the implications of their names, neither of these offers legitimate self-driving; both require the hands-on, eyes-on attention of the driver. 
This conflict between Tesla’s marketing and the realities of its software is at the root of more than a dozen lawsuits — not counting the multiple federal and state investigations — [that are ongoing against Tesla and Musk](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/character-ai-sued-for-mental-health-decline-in-teenage-users-allegedly-encouraged-user-to-murder-his>). 
NHTSA [warned Tesla](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/character-ai-sued-for-mental-health-decline-in-teenage-users-allegedly-encouraged-user-to-murder-his>) in November to ease up on the self-driving hype in its marketing materials online. 
Musk in [October unveiled Tesla’s own stab at a robotaxi](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/tesla-stock-plummets-following-robotaxi-unveil>), the flashy, two-seater Cybercab, which he said will enter production in 2026. In the meantime, he said that the Model 3 and Y will go fully autonomous in Texas and California next year, though how he’ll conquer the regulatory (and technical) burdens there remains unclear. 
## **Robocars and robo-workers**
But Musk, to his credit, has more than one autonomous basket to draw from. I’m talking about Optimus, his humanoid robot. 
While progress is hard to measure, externally — all we’ve really seen this year is a few videos of the robot walking around — those videos show a big leap in progress compared to 2021, when Musk revealed the Optimus robot, which, at the time, was a man in a suit … 
As of October, the [robot was capable](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/competition-and-power-consolidation-in-ai>) of exploring unseen spaces autonomously, climbing stairs and carrying heavy objects without overheating, according to Tesla. 
But Figure, Tesla’s big humanoid robotics competition, [spent the year demonstrating](https://www.thedeepview.co/p/<https:/x.com/figure_robot?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) its humanoid robots in use at a BMW factory, a step Optimus has yet to take. Earlier in the year, Figure partnered with OpenAI to bring ChatGPT to its robotic interfaces, and in February, closed a $675 million funding round at a $2.6 billion valuation. 
Figure plans to develop and deploy [billions of humanoid](https://www.thedeepview.co/p/<https:/www.figure.ai/master-plan?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) robots to take care of the jobs humans don’t like doing, and, eventually, to explore space. 
Researchers, meanwhile, spent the year working to combine advancements in generative AI and 3D mapping with advanced robotics; the early results, [according to a Johns Hopkins team](https://www.thedeepview.co/p/<https:/www.jhuapl.edu/news/news-releases/240822-human-robot-teaming?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>), are promising. The development of a generative AI “agent” in August enabled a dog-shaped robot to respond to natural language commands and navigate its surroundings. A possible result is a robotic assistant for battlefield medics.
And that brings us right around to the underlying software, the Large Language Models (LLMs) that are making all this possible. 
## **The wall**
We talked earlier this week about agents, which essentially marks a push away from single models and toward model systems. This has been the industry’s attempt to overcome the fundamental limitations of language models, because, for all the releases this year — OpenAI o1/o3, Google’s Gemini 2.0, Llama 3.3, etc. — hallucination (or confabulation) and bias remains a part of the architecture. 
Attempts to achieve reliability in 2024 got more creative. IBM, for instance, is [pushing advances in small language models](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ibm-and-the-road-to-achieving-ai-efficiency>) intended to be combined with enterprise data, alongside literal “guardian” models to ensure safety and reliability. Contextual AI, which has always been focused on systems, [developed a new observability model.](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-a-new-approach-to-ai-evaluation>) Enterprise startup Writer is [working on two paradigms](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/smaller-but-deeper-writers-secret-weapon-to-more-powerful-ai>); wider, more general-purpose models, and smaller (but deeper) “reasoning” models. 
And indeed, “reasoning” models have become all the buzz. 
OpenAI’s got o1 (and now, o3, but it’s not clear when it’ll actually be open for use) and Google’s got Gemini 2.0 Flash Thinking, both of which take advantage of chain-of-thought ‘reasoning’ to better answer queries. 
Still, the end of 2024 marked a point where the industry seemed to accept that scale — i.e., increasing the quantity of compute and training data — [is not enough to somehow morph a language model into a more powerful,](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-others-dealing-with-diminishing-returns-in-current-architecture>) less-flawed system. Companies increasingly turned to combinations of synthetic and organic data, focusing on data that is better organized and of higher quality, while others — specifically in the enterprise — went all-in on hyper-specific models, trained on company data and designed to accomplish specific tasks, something that reduces the risk of hallucination. 
[Even the unveiling of OpenAI’s o3 model](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-unveils-powerful-new-model>) acknowledges the fact that scale alone is not enough; though we know little about the system, we do know that the real boost in performance has to do more with its internal Chains of Thought rather than pure scale. 
And even with o3, GPT-5 isn’t here, yet, and doesn’t seem to be on its way. 
A new paradigm remains out of reach; the work, instead, has turned into optimizing the current paradigm. 
And there is likely a long way they can take it. 
But, looking at the benchmarks, the rate of progress has slowed down. The kind of exponential growth notched in early 2023 didn’t really appear in 2024 (o3 might mark a difference here, but nothing about the model has been independently verified by external researchers). Growth has become incremental, but that doesn’t mean growth hasn’t occurred. 
**Dr. John Licato, an associate professor of computer science** at the University of South Florida, told me that “the danger of hallucination is still there. I don’t really feel it’s gotten much better in the past year.”
  * “The fundamental arguments for why hallucination is inevitable are still there … I’m on the side where I’m less and less interested even in the thought of AGI (artificial general intelligence). The definitions are never consistent, even within the people who talk about it. It’s just too inconsistent, not rigorous.”
  * “The way that I’ve seen progress in this space has kind of been … you know when you’re in high school your sports ability doubles, and then you get to Olympic level stuff and their differences are measured in a quarter of a second. It seems that that’s what’s happening. In terms of absolute numbers, the improvements of the past 6 months are lower than the 6 months preceding it, because**that gets it close to the theoretical maximum** … I still see that as a significant increase.”


“I think we also want to be careful to disparage incremental improvements. That’s how science works. Incremental improvements. If you keep trying to pursue the kind of progress where you reinvent the wheel every time, you’re not going to make any progress. When you actually pursue incremental improvements, it’ll look like something dramatic when you reach a checkpoint. Transformers, the rest of the world saw that as a huge leap forward, but it really was an incremental improvement.”
John Licato 
**A look back at related stories we’ve done in the past year:**
  * [Gary Marcus on fighting for a positive AI future](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/gary-marcus-on-fighting-for-a-positive-ai-future>)
  * [Eric Xing and the age of AI empowerment](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/eric-xing-and-the-age-of-ai-empowerment>)
  * [MIT professor on achieving fair AI ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/mit-professor-on-achieving-fair-ai>)


**Johns Hopkins’ Dr. Bart Paulhamus** said in a recent media briefing that human-robot teaming will have a significant “impact” in 2025, due to the convergence of two technologies: generative AI and robotics. 
  * “The next wave is AI agents, powered by generative AI. And those … will be able to make decisions and take action, and that’s exactly what we want robots to do,” Paulhamus said. 
  * “This agentic AI, and the ability to tap into perception tools and movement tools and grasping tools, but also its ability to understand its environment and take action with that. So I think this is really exciting.” The Johns Hopkins team, plus a number of other research institutions, is focused on embodied AI, bringing the best advancements in generative tech to the physical world. 


**Dr. John Bates, the CEO of SER,** expects new developments — architectures beyond deep learning — to appear in 2025. 
  * "We've been pursuing AI or the concept of it since the 1950s, but what we truly mean by the term today refers to intelligent programs that can reason. We’re not there yet, and philosophers and neuroscientists might argue that we never will be. Currently, everything we're doing revolves around Deep Learning. This involves using artificial neural networks to identify patterns and apply learned rules to navigate specific domains.”
  * “We will almost certainly see new developments emerging — perhaps genetic models, for instance, which operate differently from neural networks or Deep Learning approaches. The key point is that what we currently have is not truly reasoning in any sense; it’s AI trained on data. We’ve defined what good reasoning looks like, and as a result, the AI replicates that behavior.”


“In a sense, none of this is the main concern — what truly matters is whether these technologies help us and prove to be useful. **I believe 2025 will be a pivotal year for a quantum leap in AI, potentially offering humanity not just one or two useful advancements, but a genuine game-changer — perhaps in** fields like medicine or transportation, though we can't say for certain yet,” he said. 
“For me — and perhaps for many others — it would be genuine home robots that can handle tasks like ironing and cleaning the apartment that would be genuinely beneficial,” Bates added. “Achieving this is quite challenging, but perhaps 2025 will be the year we finally see it come to fruition.”
**Dr. Gary Marcus**[wrote](https://www.thedeepview.co/p/<https:/garymarcus.substack.com/p/o3-agi-the-art-of-the-demo-and-what?utm_source=post-email-title&publication_id=888615&post_id=153450669&utm_campaign=email-post-title&isFreemail=true&r=3raqcm&triedRedirect=true&utm_medium=email>)**that, in 2025** , “a lot of AI influencers and maybe some companies are going to claim we have reached AGI. Almost nobody will give you their definition.”
“I am not saying we will never get AGI,” he added. “I am saying that many basic problems haven’t been solved. And I am saying, as every roboticist on the planet knows, that we shouldn’t take demos seriously, until purported products are actually released and subjected to outside scrutiny.”
In April, he wrote a list of things that ordinary people do that he doubts AI will be able to do by the end of 2025. Here are a few of them:
  * Watch a previously unseen mainstream movie and be able to follow plot twists, know when to laugh and be able to summarize it without giving away any spoilers or making up anything that didn’t actually happen.
  * Drive off-road vehicles, without maps, across streams, around obstacles such as fallen trees, and so on.
  * Write engaging biographies and obituaries without obvious hallucinations that aren’t grounded in reliable sources.


**A look back at related stories we’ve done in the past year:**
  * [Language and thought are not the same thing](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/language-and-thought-are-not-the-same-thing>)
  * [The dark side of scaling generative AI scaling datasets](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-dark-side-of-scaling-generative-ai-datasets>)
  * [The complicated statistics behind self-driving cars](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-complicated-statistics-behind-safe-self-driving-cars>)


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
Here’s the thing about AGI. I’m coming around to the idea most recently espoused by Sam Altman that we’ll achieve AGI sooner than we expect, and it’ll mean much less than anyone thinks. 
I think this will happen, not because we will crack a hitherto unachievable breakthrough, but because the definition of AGI will become steadily cheapened until it becomes in-reach. 
I take AGI to mean a general intelligence, a system capable of dynamic, flexible reasoning. It doesn’t have to be human-like at all, but it needs to possess a few characteristics that humans possess: flexibility, adaptability and generalization. 
Essentially, my big AGI marker is simple; if someone can develop a — transparent — system, with _very little training data_ , that is able to apply its “knowledge” reliably across novel situations, then I would say we might have a general intelligence on our hands. Because machine learning is machine learning, I do not expect this to happen. In fact, I would be shocked if we see something like this at any point soon; the latest innovations, o3 included, are all focused on leveraging massive quantities of training data. Smaller models tend to perform significantly worse across the so-called reasoning benchmarks that have become so important to the developers, which is an unsurprising result of the probabilistic architecture of machine learning algorithms (more data equals better probabilities). 
Something like this would seem to require models to actually understand their output, which would raise a lot of questions and today seems massively inaccessible. 
So that won’t happen in 2025. 
But through more training data, more compute and Chain of Thought explorations, large-scale models, albeit inefficiently and without consistent reliability, will become increasingly capable of mimicking that understanding, meaning their corpus of training data that enables it will become less and less important to some of the people using these products. 
Brute force is good enough for a lot of folks, and we’ll see a refining of brute force intelligence mimicry next year. Because of that, we won’t be anywhere close to an actual AGI, but if companies begin to measure “AGI” by a definition that looks only at what it is sometimes able to do and ignores _how_ it is able to do so, I wouldn’t be surprised if some actors declare that AGI has been achieved next year. 
This will create an interesting dynamic because research into the tech won’t stop; this is, after all, what the entire field has been pushing toward for decades. 
I do expect to see more grounded advancements in the models that make robotics possible, and I do think that different iterations of AI-enabled robots will become quite popular next year. They will be grounded by frustrating limitations — high cost, high energy use, short battery life, slow motion — but we’ll start to see them deployed in more arenas that remain high-risk or otherwise undesirable to humans. 
And on the self-driving front, Tesla will do what it has always done; sell hype, and fail to deliver. Waymo, meanwhile, will continue its expansion, although I expect that this expansion will falter sometime next year due to an incident (hopefully, a minor one) that seems unavoidable given the scope and speed of the company’s growth, crossed with the ongoing limitations of the architecture. 
I don’t think the hype will thin out next year. I think it will grow. But I expect the architectural limitations — bias, hallucination and compute cost/energy consumption — to persist, something that, in some sectors, might well blunt the excitement around adoption. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1be584c2-6f15-4139-be8c-b9796a499692/Ski_REAL-min.jpg?t=1735052243)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a333696d-5637-4014-831b-76f53e13fc2e/Ski_FAKE-min.png?t=1735052249)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f0e50f88-8a87-47cb-bfbc-e6c32cffe818/Real_or_Not_Template-4.jpg?t=1736303203)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The snow on the other one was smooth, even though people were walking on it.”


#### Selected Image 2 (Right): 
  * “Amount of snow on mountains doesn't match amount of snow in the foreground.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/304c3211-9b4e-4f1b-b635-cc7a3c2f398e/Shrt_Stories_Blue_.png?t=1735051104)
  * **We’re well past the Turing Test** ; we need a Weizenbaum test for AI, Jack Stilgoe, a researcher at the University College London, [argues](https://www.thedeepview.co/p/<https:/www.science.org/doi/10.1126/science.adk0176?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>); we should be more concerned if something is needed, and if it is useful, than if it is a true artificial intelligence. 
  * **Ethicists at the University of Cambridge**[warn](https://www.thedeepview.co/p/<https:/www.cam.ac.uk/research/news/coming-ai-driven-economy-will-sell-your-decisions-before-you-take-them-researchers-warn?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>) that, in the coming AI economy, AI agents will “sell your decisions before you take them,” through a thorough environment of influence and forecasting. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * CES 2025: All the news, gadgets and surprises ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/4/24307731/ces-2025-tvs-gaming-smart-home-wearables-news?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>)). 
  * Artificial intelligence advancing at ‘incredible pace,’ says Nvidia CEO ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/07/2025/artificial-intelligence-advancing-at-incredible-pace?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>)). 
  * Dow falls more than 170 points, Nasdaq loses nearly 2% as Nvidia leads tech sell-off ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/06/stock-market-today-live-updates.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>)). 
  * Research turns insecure license plate cameras into open source surveillance tool ([404 Media](https://www.thedeepview.co/p/<https:/www.404media.co/researcher-turns-insecure-license-plate-cameras-into-open-source-surveillance-tool/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>)). 
  * Meta’s seismic shift ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/metas-seismic-shift?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-robots-avs-and-technical-advancements>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on the ethics of AI: 
45% of you think the ethical issues related to AI will get worse next year; 21% think, as regulation comes into force, they might start to get better. The rest aren’t sure. 
**Gonna get worse:**
  * _“Even with one party holding the reins in all three branches of government, polarization will make mitigation all but improbable.”_


**Gonna get worse:**
  * _“Ethical companies will behave ethically... however, there are MANY, MANY entities that don't care about ethics and will generate a lot of chaos, so I believe things will get worse, much worse.”_


### What do you think? Will AI advance like crazy in 2025, or will it falter?   
---  
  * [ Somewhere in the middle ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Robotaxis will become normal ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ OpenAI will have AGI, but it won't mean anything ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No idea ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/progress-predictions-2025-threats-harms-and-ethics
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:00.520108
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: Threats, harms and ethics 


# ⚙️ Progress & Predictions 2025: Threats, harms and ethics 
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) January 07, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprogress-predictions-2025-threats-harms-and-ethics>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37da8045-e9bd-49ba-bfc7-4bd07f1972be/Banner_Image-2.jpg?t=1735051388)
**Good morning.** In this second part of our special edition series, we’re breaking down the dark side of artificial intelligence, the moral and ethical challenges and questions posed by the increasing proliferation of the technology. 
The issues, as always, are manifold.
**Relatedly** , check out the [latest episode of our podcast](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/5-identity-hijacking-the-fight-against-ai-fraud-vijay-balasubramaniyan?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), an interview with Pindrop about battling audio deepfakes. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
# **The ethics of AI**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7c460004-90be-4203-b068-d895139ef432/4.jpg?t=1735051448)
Source: Created with AI by The Deep View
At the beginning of 2024, the ethics of generative artificial intelligence came into focus in a major way, centered in a dark spotlight around Taylor Swift; a series of sexually explicit, AI-generated deepfakes of the singer [went viral on social media](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), leading to a weeks-long period in late January and early February where it became hard to avoid a positive flood of explicit, AI-generated photos of a number of female celebrities. 
Eventually, accounts were banned and the photos were removed, but the problem didn’t go away. 
**Deepfake harassment** : This kind of deepfake harassment wasn’t a new phenomenon; it’s been [going on since at least 2017.](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) But, back in that pre-GenAI era, it took bad actors hours or even days to produce just one deepfake image; and even then, it wasn’t all too convincing. 
  * GenAI, on the other hand, allows anyone to very quickly produce highly realistic images, all resulting from short, simple English prompts — the days of having to understand coding languages in order to mess around with these kinds of algorithms are long gone. 
  * The issue quickly escalated beyond Taylor Swift, leading to a deepfake crisis in schools [around the world](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/crime/general/deepfake-crisis-at-schools-crimes-stoke-distrust-fear/ar-AA1v3u5M?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>). This began at the end of 2023 with [students at a New Jersey high school](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/deepfake-porn-ai-taylor-swift-social-media-lawyer-experts?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and has [since grown rampant](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-deepfake-revenge-porn-victim-aims-to-change-the-system?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>). In November, a [Pennsylvania private school was shut down over a deepfake nude scandal,](https://www.thedeepview.co/p/<https:/arstechnica.com/tech-policy/2024/11/school-failed-to-report-ai-nudes-of-kids-for-months-now-parents-are-suing/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) with parents filing lawsuits against the administration for not properly responding to the crisis. 


According to recent [research from the nonprofit Internet Matters](https://www.thedeepview.co/p/<https:/player.flipsnack.com/?hash=NjY1NkZDQkJEQzkrZGtsdmFzOGNqbA%3D%3D&p=2&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>), some **13% of teenagers** say they have had experience with explicit deepfake image abuse. 
**A look back at related stories we’ve done in the past year:**
  * [AI cameras were quietly used to detect the emotions of UK passengers](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-cameras-quietly-used-detect-emotions-uk-train-passengers>)
  * [Department of Homeland Security: The ‘world needs to be aware of the inherent risk of deepfakes’ ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/department-homeland-security-world-needs-aware-inherent-risk-deepfakes>)
  * [ElevenLabs’ latest release highlights the issue of digital necromancy](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/elevenlabs-latest-release-highlights-the-issue-of-digital-necromancy>)


In the U.S., **there remains no federal legislation** regarding this kind of deepfake abuse. The [Defiance Act,](https://www.thedeepview.co/p/<https:/www.congress.gov/bill/118th-congress/senate-bill/3696/text?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) which would allow victims to sue over the spread of nonconsensual explicit deepfakes, passed the Senate over the summer, but has yet to pass the House. Legislation regarding the matter remains patchwork at best in the states; and while the policymakers debate regulatory approaches, the problem persists, with dozens of websites specifically marketed as AI-powered ‘nudify’ tools**remaining operational.**
The city of San Francisco in August [filed suit against 16 of those websites](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>). 
# The wider impacts
**But the ethical impacts of deepfakes** stretch far beyond image abuse and into weaponized identity hijacking that has enabled the spread of a truly concerning variety of misinformation. 
  * Even as AI-powered [vocal fraud has become something of a norm](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-one-tech-company-is-tackling-recent-proliferation-deepfake-fraud?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) — _phone calls from AI-generated relatives asking for money, for instance_ — political and election-related fraud and misinformation spread throughout much of last year; this began with a deepfaked robocall of [President Joe Biden that circulated in February,](https://www.thedeepview.co/p/<https:/www.thestreet.com/technology/how-the-company-that-traced-fake-biden-robocall-identifies-a-synthetic-voice?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>) encouraging New Hampshire voters to not participate in the primary. As the election drew nearer, Elon Musk took to [sharing AI-generated images and videos of Biden and Vice President Kamala Harris](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/news/politics/how-elon-musk-and-a-kamala-harris-deepfake-ad-sparked-a-debate-about-free-speech-and-parody/ar-BB1r2j6o?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=civai-s-latest-program-can-deepfake-you-in-under-5-seconds>). 
  * Both [Meta](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) and [OpenAI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/deepfakes-spiked-245-year>) have detailed their efforts to shut down covert influence operations that had been attempting to utilize the generative AI products operated by the two companies; looking back at the U.S. election last year, Meta said that it prevented nearly 600,000 requests to generate images of the candidates, [adding that the risks](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/2024-global-elections-meta-platforms/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>) of electoral interference from generative AI**“did not materialize in a significant way and that any such impact was modest and limited in scope.”**


**It’s not just election-related information;** AI-generated books, images and articles have spread across the internet, threatening widespread information pollution that has already had dangerous impacts. 
In August, we wrote about a British family who was [poisoned after using](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/family-poisoned-after-using-ai-generated-mushroom-hunting-book>) what turned out to be an AI-generated mushroom hunting guidebook; in the process, I discovered several AI-generated mushroom guidebooks listed on Amazon, [which the company removed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>) following my request for comment. 
And, pivoting away from the deepfake side of things, issues of generative AI leading to mass surveillance and algorithmic discrimination have proliferated: a November investigation uncovered [discrimination baked into Denmark’s digitized social welfare program](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-mass-surveillance-and-human-rights-violations-in-denmark>); the [steady adoption of AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cops-are-starting-to-use-ai-to-write-their-reports>) into already [discriminatory predictive policing efforts](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>) has continued; and the adoption of generative AI by [hospitals has](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>) continued, leading to many concerned nurses and patients alike. 
**A look back at related stories we’ve done in the past year:**
  * [I downloaded Character AI. It’s profoundly disturbing](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>)
  * [Researchers call for the abolishment of ‘carceral’ AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/researchers-call-for-the-abolishment-of-carceral-ai>)
  * [US Commission calls for ‘Manhattan Project’ for AGI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-commission-recommends-manhattan-project-for-ai>)


The psychological, sociological impacts of AI companionship, meanwhile, came into sharp focus when a [boy died by suicide after falling in love with a Character AI chatbot.](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/i-downloaded-character-ai-it-s-profoundly-disturbing>) To date, a [second lawsuit has been filed](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/character-ai-sued-for-mental-health-decline-in-teenage-users-allegedly-encouraged-user-to-murder-his>) against the company by the mother of a teenage boy who, she argues, became mentally ill and unstable due to a close relationship with bots on Character. 
And the environmental impacts of increasing investments in generative AI, meanwhile, have steadily pushed much of the [Big Tech sector further from achieving their climate goals](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-grid-is-the-most-complicated-machine-ever-built-ai-is-stressing-it-out>), with the bulk of these giants — Meta, Google, Microsoft and Amazon — [pursuing nuclear power specifically to meet their AI energy requirements](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>) _._ But, before the nuclear comes online, AI data centers are taking advantage of fossil fuels, a situation that is leading to spiking emissions and a [burgeoning public health crisis](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-artificial-intelligence>) due to steadily worsening air quality. 
There’s also the general cybersecurity war that’s been taking place, with cybercriminals vastly [empowered by generative AI tools,](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/civais-latest-program-can-deepfake-5-seconds>) which have introduced specificity, speed and scale to their operations. Cybersecurity officials have, meanwhile, adopted [generative AI tools to fight back against ever-increasing attacks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-ai-and-cybersecurity-in-the-enterprise>), even as others work to educate companies and individuals about the [myriad security risks](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-experts-say-artificial-intelligence-is-an-incredibly-vulnerable-technology#true-price-of-ai>) posed by AI, with AI and because of AI. 
On top of all this, there are ongoing legal battles regarding the legality of training generative AI models on copyrighted material, even as those models are beginning to be used to replace human workers, a challenging dynamic for the job market going forward. 
In sum, 2024 was a busy year of AI proliferation and integration, and the resulting moral and ethical impacts are vast, to say the least. 
The experts I spoke to expect 2025 to be worse. 
**Looking ahead:****Nell Watson, an author and leading AI ethicist,** told me that, with the rise of the increasingly autonomous agentic AI that we talked about yesterday, “ordinary members of the public will be tasked with teaching and managing these systems, something that**remains a major, uncertain challenge even for experts.”**
  * “Beyond alignment issues, agentic AI systems will certainly be employed to target systems and individuals for various kinds of attack, whether its creating designer synthetic data to poison another model (possibly even hijacking it in the process),” she said. “A friendly being must try to learn, model and accommodate the preferences of others. This is another strength of agentic systems, which could learn to surprise and delight us as a good friend might. However, these same capabilities can be used to observe human foibles, to strike at an exploitable weakness at a calculated moment of greatest impact.”
  * “The transition to agentic AI represents both unprecedented opportunity and risk, and this requires an investment in thoughtful governance to harness its potential while mitigating dangers. We must not only ensure that these powerful AI systems are used in an ethical manner, but we must now also work to ensure that these systems remain safe and loyal partners instead of impish and capricious minions.”


**Ajay Amlani, president of iProov, expects deepfake fraud** specifically to become fully weaponized in 2025: “a wave of account takeovers and fraudulent transactions will force banking regulators worldwide to take decisive action. Led by pioneers like Thailand and Vietnam, countries will mandate the implementation of biometric verification for payment authentication,” he said. 
Amlani added that he expects a “deepfake of a Fortune 500 CEO will cause significant disruption in the financial markets.” 
  * “The fabricated video, announcing a false merger, will trigger a temporary market dip and erode investor confidence before being exposed. This incident will highlight the growing need for robust identity verification solutions to ensure the authenticity of information and maintain trust in an increasingly digital world,” he said. 
  * “This incident will serve as a catalyst, accelerating the adoption of advanced identity verification solutions in the financial industry.”


**Typeform CPO Aleks Bass said that people will** “get scammed at a higher rate than what we are seeing now. 
“We might start asking ourselves, **‘is AI really worth it?’** We will see more companies investing money and time into locking down experiences and adding additional security, validation and verifications to prevent some of these abuses. But the challenge will be to create nearly invisible solutions, so as not to interrupt the customer experience.”
Aleks Bass 
**A look back at related stories we’ve done in the past year:**
  * [Amazon pulls AI-generated books after Deep View inquiry](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/amazon-pulls-ai-generated-books-after-deep-view-inquiry>)
  * [US hospital gets an AI assistant](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant>)
  * [The current harms and real-world impacts of algorithmic discrimination](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>)
  * [Meta and Big Tech’s nuclear revolution](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>)


**Cybersecurity firm Exabeam expects,** similar to much of what we’ve already discussed, highly enhanced and empowered cybercriminals, leading to new types of attacks and increasing exploitation. 
**Steve Povolny, one of Exabeam’s co-founder** s, said that, in 2025, “AI will democratize malware creation.”
  * “You won’t need to be a coder to create sophisticated malware in 2025 — AI will do it for you. Generative AI models trained specifically to generate malicious code will emerge in underground markets, making it possible for anyone with access to deploy ransomware, spyware and other types of malware with little effort,” he said. 
  * “Blindly trusting AI-generated outputs will become a major vulnerability for organizations. This will lead to the rise of a new cybersecurity mandate: **‘Zero Trust for AI.** ’ Unlike traditional Zero Trust principles, Zero Trust for AI is not a prediction for the future; it’s a concept ready for discussion now, bringing a nuanced approach to trusting AI. This framework will require organizations to verify, validate and fact-check AI outputs before allowing them to drive critical security decisions.”


Povolny thinks that video-based deepfakes will soon become “imperceptible from reality,” unleashing a “devastating new wave of social engineering attacks” that will allow “criminals to impersonate executives, forge high-stakes transactions, and extract massive payouts from unsuspecting victims. With AI making deepfakes accessible at the push of a button, the potential for financial fraud will explode, forcing organizations to rethink how they verify identity in an increasingly deceptive world.”
**Harry Muncey, Senior Director of Data Science** , and Responsible AI at Elsevier, expects the adoption of generative AI to continue, leading to improved confidence in “low-risk use cases” that “will lead to pressure for innovation and use in higher-risk environments, such as healthcare, where the need for robust guardrails is clearly critical.”
**And Vijay Balasubramaniyan** , the co-founder of CEO of Pindrop, expects deepfake attacks to “accelerate at an alarming rate” next year. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
I wholeheartedly expect — and I really hope I am wrong — that the ethical challenges related to artificial intelligence will become much more significant throughout 2025 as adoption continues, legislation lags and systems become more capable. 
A year ago, I saw no clear solution to the problem of deepfake abuse and harassment; I think we have made no progress on that front whatsoever. Instances will continue to occur at small and large scales. People will get hurt. And while I do worry about misinformation and its spread online, I am far more concerned about schools and this new, dangerous form of bullying and harassment that, without governance, oversight and regulation, will continue unabated. 
I also expect addictions to and obsessions with anthropomorphized GenAI chatbots to steadily spike as vulnerable people interact with these systems, leading to a heavy, noticeable increase in digital isolation, something that may start to become more clearly associated with mental health struggles. 
I expect we will additionally begin to see the problems of overreliance, specifically in high-risk environments. Hospitals, I think, will run into at least a few well-publicized instances regarding generative AI misuse.
As with any problem, things have to get worse before they get better — I think 2025 will be the year that these issues move off the fringe to become more mainstream; only then might action be taken against them. I do not expect that action to come soon, however. 
On the copyright front, I think we’ll see some significant movement from the big copyright infringement cases this year (Authors Guild and New York Times) that may — and that’s a very big ‘may’ — have implications for the future development of foundation models. I don’t expect mass job loss anytime soon — or at all, really — but I do think we’ll start to see a reduction in hiring due to internal reliance on AI tools. 
On the environmental front, the optimist in me hopes that the sheer cost of data center operation will drive massive innovations in energy efficiency, which will have positive impacts on sustainability. This, however, might very well be wishful thinking; the complexity and use of generative AI systems continues to grow, meaning energy efficiencies will simply free developers up to handle bigger workloads, rather than reducing their energy use. 
My areas of biggest concern involve algorithmic surveillance and discrimination, unsustainability, deepfake abuse and artificial companionship; as these issues continue to worsen — I expect them all to become hallmarks of this next year — global society will be pushed to the edge of truly radical transformation. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/61e53a7b-bfa9-4a5f-b63e-b5d84cb40b9f/Lodge_REAL-min.jpg?t=1735051636)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/108198e8-1f67-4a3c-b4ae-80e4a723306f/lodge_fAKE-min.png?t=1735051644)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/caaa1429-8a8d-4e34-b15e-eeff2bb13199/Real_or_Not_Template-3.jpg?t=1736213763)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The fake sled appears to be pulling the dogs.”


#### Selected Image 1 (Left): 
  * “Image 2 just looks fake.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Nvidia, chip stocks pop after Foxconn reports record revenue ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/06/global-chip-stocks-climb-on-foxconn-results-ai-server-demand.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Samsung claims its Ballie AI robot will actually be released this year ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/6/24337478/samsung-ballie-robot-release-date-features-2025?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * US crackdown leads Chinese firms to set their sights overseas ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/01/2025/us-crackdown-leads-chinese-firms-to-set-their-sights-overseas?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Google plays catch-up in video ad tech ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/google-plays-catch-up-in-video-ad-tech-as-streaming-ads-take-off?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 
  * Chip firms surge on hopes of strong AI-led demand ([Reuters](https://www.thedeepview.co/p/<https:/www.reuters.com/markets/us/chip-firms-surge-signs-strong-ai-led-demand-2025-01-06/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-threats-harms-and-ethics>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on agents in 2025: 
47% of you think 2025 will be the year of the AI agent. The rest … not so sure. 
**The year of the AI Agent:**
  * “And if that’s correct, he who holds the microphone will have a lot of sway over progressive adoption.”


**The year of the AI Agent:**
  * “Make Al more than trying to type and read my brain I want solutions and agents.”


### Thoughts on the ethical issues of AI next year?   
---  
  * [ Things are gonna get worse ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Things might start getting better - maybe there will be regulation ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No clue ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/prog-predictions-series-draft-ef9c081b34af8540
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:05.140132
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Progress & Predictions 2025: The year of the AI agent


# ⚙️ Progress & Predictions 2025: The year of the AI agent
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>) January 06, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprog-predictions-series-draft-ef9c081b34af8540>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprog-predictions-series-draft-ef9c081b34af8540&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprog-predictions-series-draft-ef9c081b34af8540>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fprog-predictions-series-draft-ef9c081b34af8540>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/407c2b37-3cfb-4109-af72-35e130bc8830/Banner_Image.jpg?t=1735050904)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8b148777-765a-489d-96bb-0cde9b4c0edf/Together_W_GS.png?t=1736155806)](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)
**Good morning.** Over the past two months or so, I’ve been collecting predictions from people across the AI industry about what 2025 might look like. 
So, over the next week, we’ll be taking a bit of a departure from the AI news of the day to instead take a deep look, both into 2025 (_and back at 2024_) in a progress and predictions series that aims to examine how far AI has come, and where it might be headed. Had a lot of fun putting this together. 
We’re kicking things off today with a look into one aspect of technical progress, crossed with the question of enterprise adoption. The consensus here is that 2025 will become known as the ‘year of the AI agent.’ 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# [**Make 2025 your Best Year With This**](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)[**$399**](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)[**FREE AI Masterclass**](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/aa15c72b-79ea-4788-a0e6-d3be5cec478b/image1.png?t=1736164003)](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)
If you don’t become an AI-enabled professional in 2025, you will:
  * Get replaced by a person who uses AI.
  * Face slow career growth and income.
  * Spend hours on tasks that can be done in 10 minutes.


This 3-hour power-packed workshop will teach you 25+ AI Tools, make you a master of prompting & talk about hacks, strategies & secrets that only the top 1% know of.
[Save your seat now](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>) (Offer valid for 24 hours only ⏰)
**Here’s why you can’t miss this:**
✅ Learn 30+ cutting-edge AI tools to completely transform the way you work, market, and lead.
✅ Automate your workflows and reclaim **20+ hours a week** (imagine no more burnout).
✅ Create an **AI-powered version of YOU** —a digital clone that handles the tedious work while you focus on what truly matters.
So don’t think twice, you have NOTHING to lose. Consider it a $0 investment that will yield value worth millions.
⏲️ Time: 10 AM EST (Tomorrow)
[Register now or miss your golden chance](https://www.thedeepview.co/p/<https:/web.growthschool.io/DVJ1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)
# **But first … A look back at 2024 and the rise of the AI chatbot**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e43400b2-4c65-48c2-a187-54d34be7ea1f/5.jpg?t=1735050942)
Source: Created with AI by The Deep View
Before we get to the agents and what might lie ahead, we have to start with chatbots, and the language models they’re built on. 
**The rise of generative AI** : In the beginning, there was nothing. Then, there was ChatGPT. Ok, well, that’s not strictly true, but the launch of ChatGPT — a generative interface built on a Large Language Model (LLM) — is regarded as the moment that sparked the current AI boom. 
Importantly, it made AI technology — which, beforehand, was an under-the-hood kind of technology — visible. People could interact with it. And that’s what changed everything. That moment came at the tail end of 2022, making 2023 the year of the chatbot race and 2024 the year of the chatbot (_OpenAI chief Sam Altman said in December that ChatGPT had reached 300 million weekly active users_). 
  * ChatGPT touched off a race for bigger and better generative AI chatbots, and the market was anxious to compete. Anthropic’s Claude models followed, as did Google’s Gemini models, Meta’s Llama models, Mistral’s models and a whole slew of startups building generative AI assistants, either from scratch, or on ChatGPT itself. 
  * 2024, in many ways, was the year of generative AI chatbot integration. Developers worked hard to sell iterations of the tech to everyone within reach, resulting in adoption at hospitals, accounting firms and many, many corporations. 


Corporate spending on generative AI, [according to a report last year,](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/business-spending-on-ai-jumps-500-to-13-8-billion-on-200-billion-in-capex>) spiked from $2.3 billion in 2023 to **$13.8 billion in 2024, a 500% increase**. The top five use cases here involved code generation, support chatbots, enterprise search and retrieval, data extraction and summarization and meeting summarization. 
Even as the bulk of AI projects in the enterprise remained unable to get off the ground, last year was a year of serious contemplation for corporations about the opportunities afforded them by generative AI. [As Microsoft told me](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-microsoft-vp-on-agentic-push-and-ignite>), the experimentation phase has largely concluded; now, people are working on the application phase. 
And that leads us to agents. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Never Prep for a Sales Meeting Again**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a0edb6ff-2b42-4737-8fa2-320cc34bada5/Bounti_HeroAnimation__2_.gif?t=1735922033)](https://www.thedeepview.co/p/<https:/www.bounti.ai/?utm_campaign=deepview&utm_medium=newsletter&utm_source=deepview&utm_content=secondary>)
Bounti’s AI will save you 10+ hours/week of painful account research and meeting prep, empowering you and your team to sell more effectively through every channel and stage of the funnel.
Deliver the right message to your ideal buyer—driving real engagement at a fraction of the cost of other solutions.
  * Research: Get a cheat sheet for every account that matters to you. In minutes, you’ll have everything you need to make your next conversation the reason they buy.
  * Create: Our AI will generate custom pitches and any type of content you want, all fully customizable to what you need to land your deal.
  * Engage: Have the confidence to secure every conversation with detailed messaging and positioning that your buyers care about.


[Get started in minutes—not weeks—for nothing](https://www.thedeepview.co/p/<https:/www.bounti.ai/?utm_campaign=deepview&utm_medium=newsletter&utm_source=deepview&utm_content=secondary>)
# The agents are coming
As the tech becomes more integrated and normalized, expectations around application have shifted; chatbots are cool, but developers — particularly in enterprise offerings — have become increasingly interested in the evolution of the chatbot, which is something the industry has dubbed the “AI Agent.” 
[Microsoft, Google](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-europeans-would-let-an-ai-vote-for-them#2>) and [Nvidia have all begun](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/nvidia-s-push-for-ai-agents>) positioning and pushing so-called agentic offerings. 
The idea here is simple in concept; where a chatbot produces output in the form of imagery, textual or video content, an AI agent — built, of course, on the same LLM-based architecture — would complete actions. [Though each company has a different definition](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/nvidia-s-push-for-ai-agents>) of an agent, according to IBM, the term “refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.”
Deloitte [expects](https://www.thedeepview.co/p/<https:/www.deloitte.com/global/en/about/press-room/deloitte-globals-2025-predictions-report.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>) that 25% of the enterprises currently using generative AI will deploy AI agents next year, a number that will rise to 50% by 2027. Deloitte expects the capabilities of these systems to vastly improve throughout next year, a boon to their adoption and deployment. 
It is worth noting that issues of bias and hallucination in LLMs — in addition to their massive energy footprint — have not been solved; action-taking generative AI therefore poses risks of, not mistaken content, but mistaken actions, which would presumably have much more significant consequences. 
Still, industry experts that I spoke with think that 2025 will see the rise of so-called agentic software. 
[Dr. John Licato](https://www.thedeepview.co/p/<https:/cse.usf.edu/~licato/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)**, an associate professor of computer science** at the University of South Florida and the founder/director of its Advancing Machine and Human Reasoning lab, told me that the biggest development in LLMs thus far involves the growth of agents. 
  * He said that this push toward no-code agentic AI will bring an influx of a greater variety of users, users who don’t necessarily know much at all about how generative AI, agents or LLMs work: “in 2025, those people are going to start realizing as they put these agents to work the kinds of mistakes they make. They’re either going to abandon it, or they’re going to say ‘i need something more serious here,’” Licato said. 
  * “People are actually gonna start seriously trying to look for, not just guardrails, but ways to check that their agents are actually going to do what they ask them to,” he said. 


[Dr. John Bates](https://www.thedeepview.co/p/<https:/www.comparethecloud.net/author/john_bates/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)**, a former professor** who is now the CEO of SER, told me that, with the “information tsunami” expected to get worse and worse, agentic AI might offer a solution. 
  * “We’re not just drowning in unstructured and 'dark' data; we’re overwhelmed by structured data as well. That’s why I recommend keeping a close eye on Agentic AI, a pivot many vendors are looking to make. There’s certainly a role for agents that continuously analyze your documents, compare them with incoming information, and seek out valuable insights — essentially becoming intelligent curators of your digital landscape,” Bates said. 
  * “I envision two tiers of agents emerging: everyday assistants that help manage daily tasks and more advanced AIs that provide high-level analysis for making informed, rapid business decisions. In all honesty, we’ll need both types.I anticipate that 2025 will be a significant year for this evolution.”


**Uzi Dvir, CIO at WalkMe,** said that, as we get into 2025, the “agent wars are heating up.” 
  * “If 2024 was all about chatbots, 2025 is all about the agents. As the battle to make AI more useful and provide true ROI intensifies, the agent wars are heating up. While the first iteration of copilots augmented human tasks, this next generation is poised to fundamentally change how businesses operate. We’re already seeing the first wave of innovation as the big players jockey for position.”
  * “AI agents will bring new questions about automation and the role humans play. The path to victory doesn’t lie in these technology advancements alone, companies that actively start addressing change management alongside AI and copilots will reap the true rewards of all the intensifying innovation and competition.”


**A look back at related stories we’ve done in the past year:**
  * [Interview: Microsoft VP on agentic push and Ignite](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-microsoft-vp-on-agentic-push-and-ignite>)
  * [ChatGPT’s impact on the labor market](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/chatgpt-s-impact-on-the-labor-market-openai-generative-ai-artificial-intelligence-job-loss-report-st>)
  * [Business spending on AI jumps 500% to $13.8 billion ... on $200 billion in capex](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/business-spending-on-ai-jumps-500-to-13-8-billion-on-200-billion-in-capex>)


**It’s an impression shared by Hyperscience CEO** Andrew Joiner, who said that the idea of human-in-the-loop technology will begin changing next year. 
  * “In 2025 and beyond, powerful AI models will oversee supervision activity that is performed by humans today, eventually moving toward fully autonomous systems. The prevalence of more autonomous systems will allow organizations to reallocate their people’s time to more strategic and creative pursuits within the organization.”
  * “We’ll move from ‘human in the loop’ toward ‘AI in the loop’ as models become more knowledgeable on specific business’ data.”


This push toward a more autonomous environment is one that many expect will translate to enterprise adoption, under the expectation that it will enable clearer and more actionable return on the massive investment of AI. 
**Hyperscience’s CTO Brian Weiss expects that** , next year, generative AI will no longer be a solution in search of a problem, something [we’ve talked about several times](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-incorporating-generative-ai-start-problem>) in the past year — researcher and software engineer Molly White [noted last year](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-incorporating-generative-ai-start-problem>) that Large Language Models (LLMs) _“do a poor job of much of what people try to do with them, they can't do the things their creators claim they one day might and many of the things they are well suited to do may not be altogether that beneficial.”_
Weiss said that the adoption approach toward generative AI has thus far gone backwards, with industries exploring with the tech by playing with its capabilities first, rather than identifying solutions to specific problems. This, he said, will change in 2025. 
  * “In 2025, the next frontier of generative AI will be leveraging the technology to truly derive valuable insights by identifying problems for solutions to address rather than simply generating content.”
  * “In the enterprise setting, we will see organizations moving to small language models (SLM) solutions in private cloud settings, where they can input their organizational data to build tailor-made solutions that understand the language of their business without fear of private business data being swept up in public-facing LLMs.”


**But Galileo co-founder Yash Sheth** told me that, while integration will continue ramping up in the enterprise, the process won’t be a smooth one, and it won’t be one-size-fits-all. 
“The industry has been led to believe that implementing AI into the enterprise is extremely easy,” he said. “In 2025, we’ll see the realization that there isn’t an ‘easy button’ and an evolution beyond simple interfaces (ChatGPT chatbot → RAG + Fine-Tuning) and into sophisticated implementations.” 
Still, Sheth said that the “world is moving towards just extracting more ROI from generative AI.”
The “whole trend towards agents is nothing but to get more ROI from generative AI systems. **Automation is the end goal.** You need to automate a lot of things using AI, where humans are involved and without true actions being taken by AI, it's not going to be full automation. Agentic systems are going to actually lead us to that automation and that ROI that we expect from generative AI.” 
As a result of this ever-increasing automation, computer scientist and AI expert Dr. Srinivas Mukkamala expects that it will start to become “radically difficult” for high-paying software developers to find a job in 2025 and beyond. 
**A look back at related stories we’ve done in the past year:**
  * [Smaller but deeper: Writer’s secret weapon to better AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/smaller-but-deeper-writers-secret-weapon-to-more-powerful-ai>)
  * [Study: Generative AI is making workers less productive](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/generative-ai-is-making-workers-less-productive>)
  * [Interview: When incorporating generative AI, start with a problem](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-incorporating-generative-ai-start-problem>)


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/37cba1f9-38e5-44a5-8eb3-ea3643ea3893/image.png?t=1734644403)
Get ready for my own predictions … 
In this conversation about the move to agentic AI and a more widespread integration of the tech by enterprises, I expect the road to perhaps be a little less rosy than it’s been thus far. Enterprises have had two years now to mess around with generative AI. And they’ve seen that hallucinations and algorithmic bias are a real problem, neither of which are going to go away. 
They’ve also been faced directly with the massive price tags associated with this tech, price tags that would be justifiable if things, well, worked — as we wrote about last year, some customers have [grown so frustrated with the usability and cost of Microsoft’s flagship Copilot](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/interview-microsoft-vp-on-agentic-push-and-ignite>) product that they have paused their subscriptions to it. 
So I would imagine that, as opposed to 2023, when every executive on the planet was anxious to say the word “AI” to appear with the times, we’ll see more caution in 2025. I think businesses are aware that there are gains to be made with AI, but maybe in less obvious ways — perhaps an email assistant isn’t worth the hassle and the cost, but maybe agentic AI solutions to track and cut down on energy usage could result in cost-savings that make an AI investment more than worthwhile. 
As part of that, I do think we will start to see a push away from single models and chatbots; **chatbots aren’t enormous time-savers for most people**. This is what’s behind the push for agents. And so, because of this, I do think we’ll see attempts at agents. I think this push is premature, however, and will result in a few enormously costly hallucinations that will make businesses think twice about deploying agentic solutions. 
On the model front, there’s been a gradual understanding that models are fine, but systems are far more useful. In the enterprise especially, looking at generative AI as a more holistic, more traditional digital system enables better cybersecurity protections as well as better results (think big models and small models integrated together in a stack). I expect we’ll start to see enterprises pushing in this direction (whether you want to call that an ‘agent’ depends on which company’s definition you choose to stand by). 
And, on the agentic front, again, I think the technology is premature for generative AI to jump into decision-making and action-taking, and I think it’ll result in costly errors that will spook customers (_just think of all the ways a hallucination could screw up buying airplane tickets without careful oversight_). I do, however, expect that all the major developers will launch clear iterations of their own versions of agentic AI — which will remain bounded and limited by the architecture; likely, these products will be more costly than current solutions, and we’ll just have to see if businesses will be interested in paying for that.
And that brings me to my final related point here — so far, the developers, through a combination of [venture capital dollars and Big Tech cash infusions](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/ai-companies-need-a-lot-of-money-investors-are-still-forking-it-over>) (**in the billions**) have been able to subsidize the cost of using generative AI as part of their desperate push to win users over to the tech. This will not continue in perpetuity. 
I fully expect that, in 2025, we will see major developers move from [talking about increasing subscription prices](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/openai-considers-higher-priced-subscriptions-to-its-chatbot-ai-preview-of-the-informations-ai-summit?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>), to actually increasing baseline subscription prices, something that has already started to happen. OpenAI in December unveiled a $200/month Pro tier (though it did not axe its $20/month Plus tier). I would expect these significant price increases to become a norm across the industry; these businesses are burning cash at a rate that is difficult to comprehend, and with adoption set to hit higher levels in 2025, it seems like a good time to test the willingness of the market to cough up. (_OpenAI,_[_according_](https://www.thedeepview.co/p/<https:/x.com/sama/status/1876104315296968813?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>) _to Sam Altman, is losing money even on the $200/month tier; maybe things will go higher still_). 
I think this will push a large swath of people and smaller businesses away from the product. 
The last thing I’ll say here is that, enterprises aside, the push into agentic AI will usher forth a moment of reckoning for modern society; will ordinary people accept _and pay for_ the integration of systems that (unreliably, and at great cost) just do things for them? Or will they deem it ill-fitted to daily life? In this way, 2025 will be a telling year for the future, not just of AI, but of civilization. Will things be rejected? Will they be accepted with clear guardrails and limitations? Or will they be uncritically adopted? I can’t predict how this will play out, but it will be interesting to watch, with massive implications across a wide spectrum of ethical, economic and environmental issues. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6282f4a1-c194-46fc-8358-ec95f975c58a/10_AI_or_not.gif?t=1734644465)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a7d3df1e-078e-4bfc-9a5c-e65cd799e0a6/Dogs_REAL-min.jpg?t=1734644494)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/2ba1fc24-8c84-4c53-9abb-7004a84cdb20/Dogs_FAKE-min.png?t=1734644517)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b446dc4e-a2fb-4bc3-8633-5e5e64d98426/Screenshot_2024-12-19_at_4.43.47_PM.png?t=1734644642)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e98035d0-d405-4f28-8275-d63ac4b31536/Real_or_Not_Template-2.jpg?t=1735937170)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The hands are more detailed and real-looking in image 1.”


#### Selected Image 2 (Right): 
  * “I bet that's Peter Parker holding the champagne in image 1 (right hand).”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * AI chatbots fail to diagnose patients by talking with them ([New Scientist](https://www.thedeepview.co/p/<https:/www.newscientist.com/article/2462356-ai-chatbots-fail-to-diagnose-patients-by-talking-with-them/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)). 
  * Microsoft expects to spend $80 billion on AI-enabled data centers in fiscal 2025 ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/03/microsoft-expects-to-spend-80-billion-on-ai-data-centers-in-fy-2025.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)). 
  * How Meta leverages generative AI to understand user intent ([Venture Beat](https://www.thedeepview.co/p/<https:/venturebeat.com/ai/how-meta-leverages-generative-ai-to-understand-user-intent/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)). 
  * TikTok faces a pivotal week ahead of looming US ban ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/05/2025/tiktok-faces-a-pivotal-week-ahead-as-it-faces-us-ban?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)). 
  * The Philippines is creating a ChatGPT rival that speaks Filipino and Taglish ([Rest of World](https://www.thedeepview.co/p/<https:/restofworld.org/2024/filipino-ai-chatbot-launches-2025-local-languages/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=progress-predictions-2025-the-year-of-the-ai-agent>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Thoughts on agents in 2025?   
---  
  * [ 2025 will be the year of the AI agent ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Eh ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/report-the-grid-can-t-handle-ai
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:09.574487
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Report: The grid can’t handle AI


# ⚙️ Report: The grid can’t handle AI
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) January 03, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-grid-can-t-handle-ai>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-grid-can-t-handle-ai&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-grid-can-t-handle-ai>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-grid-can-t-handle-ai>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1c6cefb1-c6cb-4f61-8f9e-08d481a015f1/Banner_Image.jpg?t=1735851499)
**Good morning** , and happy Friday. That was a quick week. 
Yesterday, a [federal appeals court struck down net neutrality](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/news/politics/in-blow-to-democrats-federal-appeals-court-strikes-down-net-neutrality/ar-AA1wRPAt?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>), which was introduced under former President Barack Obama, repealed under President-elect Donald Trump and reinstated under President Joe Biden. 
The [idea behind net neutrality](https://www.thedeepview.co/p/<https:/www.techtarget.com/searchnetworking/definition/Net-neutrality?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) was to ensure the internet remained equally fast for all users, regardless of the possible corporate interests of the internet providers. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 🩺 AI for Good: Stethoscopes for heart failure
  * 🚨 Anthropic’s copyright guardrails
  * ⚡️ Report: The grid can’t handle AI


# **AI for Good: Stethoscopes for heart failure**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/11fd7376-c19f-4d4a-8d3e-43dd7c7b46ab/1.jpg?t=1735851508)
Source: Eko Health
One of the ways to tell if a person might soon experience heart failure involves [ejection fraction](https://www.thedeepview.co/p/<https:/www.heart.org/en/health-topics/heart-failure/diagnosing-heart-failure/ejection-fraction-heart-failure-measurement?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) (EF), a percentage measurement of how much blood the left ventricle of the heart pumps out with each contraction. Scores below 49% could indicate cardiac damage, evidence of possible or pending heart failure. 
But the methods that exist to test for EF aren’t easily accessible during normal visits. Eko Health, a digital health firm, has been working on a solution. It involves AI. 
**The details** : Eko [developed an algorithm](https://www.thedeepview.co/p/<https:/www.ekohealth.com/blogs/newsroom/fda-clears-low-ejection-fraction-ai?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>), designed to work with its AI-enabled stethoscope, that is capable of detecting low EF scores. 
  * The algorithm was trained on more than 100,000 ECGs and echocardiogram pairs from heart failure patients and was both clinically and independently validated. 
  * In clinical trials, the algorithm achieved high levels of accuracy and sensitivity, in addition to particular accuracy in detecting heart conditions in pregnant women. 


The algorithm was approved by the U.S. Food and Drug Administration in April. 
“The ability to identify a hidden, potentially life-threatening heart condition using a tool that primary care and subspecialist clinicians are familiar with — the stethoscope — can help us prevent hospitalizations and adverse events,” Dr. Paul Friedman, chair of the Department of Cardiovascular Medicine at Mayo Clinic in Rochester, said. “Importantly, since a stethoscope is small and portable, this technology can be used in urban and remote locations, and hopefully help address care in underserved areas.”
# **Anthropic’s copyright guardrails**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4634ef33-1d8b-4b57-9034-41ef6af1fd0a/2.jpg?t=1735851516)
Source: Anthropic
There are two elements to the AI and copyright conflict. One is the bigger question surrounding the baseline construction of generative models; in other words, does the training of AI models on copyrighted data without permission or compensation constitute infringement, or are developers legally protected? 
As this issue gets warred over in courts around the world, there is a separate, far more clear-cut issue of generative AI models producing copyright-infringing output, something that is a [well-documented](https://www.thedeepview.co/p/<https:/garymarcus.substack.com/p/things-are-about-to-get-a-lot-worse?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) problem. 
**For instance:**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/297208f4-3e57-4664-bbb9-1cb256287097/Screenshot_2025-01-02_at_3.31.54_PM.png?t=1735851661)
Image output from xAI’s Grok. 
Many of the lawsuits publishers have filed against developers have to do with both elements. One of these such lawsuits — of eight music publishers against Anthropic, which was filed in October, 2023 — [has come to a partial resolution](https://www.thedeepview.co/p/<https:/www.digitalmusicnews.com/wp-content/uploads/2024/12/concord-v-anthropic-5-24-cv-03811-motion-guardrails-dec-2024.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>). 
  * Anthropic has implemented guardrails to prevent infringing output; the startup has agreed to maintain these guardrails **across all its current and future products** , something the publishers are happy with. 
  * As such, the agreement resolves the injunction the publishers had filed, though it does not resolve — or even address — the rest of the lawsuit. 


Specifically, the publishers have requested “that Anthropic refrain from using unauthorized copies of publishers’ lyrics to train future AI models.” This is still an ongoing part of the suit.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dd7d705d-48c7-45f8-8747-d400d4690d15/Shrt_Stories_Blue_.png?t=1735847990)
  * **New research found that**[**California’s grid**](https://www.thedeepview.co/p/<https:/electrek.co/2024/12/31/california-grid-100-percent-renewables-no-blackouts-cost-rises/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)[ ran on 100% renewables](https://www.thedeepview.co/p/<https:/electrek.co/2024/12/31/california-grid-100-percent-renewables-no-blackouts-cost-rises/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) (solar, wind, water) for a record 98 out of 116 days in 2024, with no blackouts or cost-rises, something that proves that a large-scale grid powered by renewables is possible. 
  * **The recent Tesla Cybertruck explosion,** according to [404 Media](https://www.thedeepview.co/p/<https:/www.404media.co/elon-musk-uses-cybertruck-explosion-to-show-tesla-can-remotely-unlock-and-monitor-vehicles/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>), highlights issues of corporate surveillance; Elon Musk remotely unlocked the truck for law enforcement, and provided video from charging stations it had visited before the explosion. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Competition for electricity will define the climate beat in 2025 ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/01/02/2025/competition-for-electricity-will-define-the-climate-beat-in-2025?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)). 
  * Silicon Valley stifled the AI doom movement in 2024 ([TechCrunch](https://www.thedeepview.co/p/<https:/techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)). 
  * Dow reverses course and drops 200 points in volatile start to 2025 ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2025/01/01/stock-market-today-live-updates.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)). 
  * Tesla sales dropped 1.1% in 2024, its first annual decline in a dozen years ([AP](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/autos/electric-cars/tesla-sales-dropped-1-1-in-2024-its-first-annual-decline-in-a-dozen-years/ar-AA1wR7gZ?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)). 
  * The US government announced a ‘historic’ nuclear energy deal ([The Verge](https://www.thedeepview.co/p/<https:/www.theverge.com/2025/1/2/24334195/nuclear-energy-deal-us-government-constellation-gsa?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# **Report: The grid can’t handle AI**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8e25e2c5-2b81-47be-a64e-8031b4153364/3.jpg?t=1735851521)
Source: Unsplash
We’ve talked often about the electrical, and, therefore, environmental, costs associated with the data centers that run AI applications. And while the environmental impact is clear, there’s another side to this unfolding story: grid instability. 
**What happened:** A months-long [Bloomberg](https://www.thedeepview.co/p/<https:/www.bloomberg.com/graphics/2024-ai-power-home-appliances/?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczNTMxNjk3OCwiZXhwIjoxNzM1OTIxNzc4LCJhcnRpY2xlSWQiOiJTUDVUUzhUMEFGQjQwMCIsImJjb25uZWN0SWQiOiI0MDVBMTQxMTI3MTM0MDM3OENCMDNDQTY4Nzc3MEQ5RiJ9.l1UB8xJFHoagQebxlg8czxgiT1cP3oxHhX2m_82DdH0&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) analysis of 770,000 Whisker Labs home power sensors found that **more than 75% of highly distorted power readings** occurred **within 50 miles of significant data center activity.**
**What it means:** Whisker Labs [operates a network](https://www.thedeepview.co/p/<https:/www.tingfire.com/news/enhanced-grid-monitoring-with-total-harmonic-distortion-measurements/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) of hundreds of thousands of simple home sensors that enable the company to monitor the power quality and resiliency of the electric grid across the country. It specifically enables the identification of those areas experiencing something called power distortion, which refers to disturbances that can “reduce energy efficiency, damage home appliances and harm critical grid infrastructure, ultimately leading to higher costs for homeowners.”
  * The root of these distortions involves harmonics, the waves of electricity that travel through power lines. The distortion of these waves can impact power reliability and damage appliances; **such distortion is also indicative of grid weakness** and instability. 
  * This monitoring network, according to Whisker co-founder and CEO Bob Marshall, is a vital step at a time when electrification and demand keep increasing while energy sources are changing. “The grid was not designed to accommodate the stress being placed on it today,” he said in November; monitoring it means companies can intervene in areas that are experiencing power quality issues. 


Bloomberg’s analysis found that **more than half of the tracked households showing the worst levels of power distortion** are within 20 miles of “significant data center activity.” This was particularly heightened in Northern Virginia, the most highly concentrated data center region — known in-industry as “data center alley — in the U.S. 
The Whisker sensors can’t themselves identify a single root cause behind this distortion; Bloomberg’s analysis instead identified a correlation between the rise in data centers and the subsequent spikes in distortion. 
It is no coincidence that this comes at a time when **U.S. data center electricity demand has tripled over the past 10 years** and is [expected to double again](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-the-data-center-energy-spike>) by 2028. As a percentage of nationwide electricity consumption, **data centers consumed 4.4%** of total electricity in 2023, a number that the Department of Energy projected **will surpass 12% by 2028.**
**The landscape** : The North American Electricity Reliability Corporation (NERC) recently released its [2024 long-term reliability assessment](https://www.thedeepview.co/p/<https:/www.nerc.com/pa/RAPA/ra/Reliability%20Assessments%20DL/NERC_Long%20Term%20Reliability%20Assessment_2024.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>), which found that,**for the first time in 20 years,** we are experiencing “surging” energy demand at a time when fossil fuel plants are being retired and renewable energy sources aren’t coming online as fast as they are needed. 
  * The culprit, in part, is AI: “demand growth is now higher than at any point in the past two decades. Increasing amounts of large commercial and industrial loads are connecting rapidly to the BPS (_North American bulk power system_),” the report reads. “**The size and speed with which data centers (including crypto and AI) can be constructed** and connected to the grid **presents unique challenges** for demand forecasting and planning for system behavior.”
  * Specifically, **less capacity is being generated than “what was projected and needed** to meet future demand,” according to the report. **“The trends point to critical reliability challenges facing the industry:** satisfying escalating energy growth, managing generator retirements and accelerating resource and transmission development.”


Further, the [U.S. Government Accountability Office in 2021 published a report](https://www.thedeepview.co/p/<https:/www.gao.gov/products/gao-21-346?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) that investigated the infrastructure risk posed by a changing climate, one complete with both wildfires and storms of increasing occurrence and severity, a combination that adds a layer of instability to a grid that, before all that, is already facing burgeoning reliability issues. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
The challenge here is one of balancing priorities. In 2022, U.S. electricity production and transmission **accounted for a quarter of total greenhouse gas emissions** , [according to the EPA](https://www.thedeepview.co/p/<https:/www.epa.gov/ghgemissions/sources-greenhouse-gas-emissions?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai#electricity>). Though there are other significant sectors — transportation accounted for 28% of emissions and industry for 23% — we need these numbers to start coming down, and quickly. 
But, because of soaring energy demand for AI (and crypto) projects, demand is outpacing production, an untenable situation that is already leading to [delays in the retirement](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-grid-is-the-most-complicated-machine-ever-built-ai-is-stressing-it-out>) of coal power plants. 
And, beyond AI, as temperatures continue to rise — 2024 is set to be the [hottest year on record](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/weather/topstories/2024-set-to-become-hottest-year-on-record/ar-AA1wMkrz?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>) — air conditioning will become more and more important (and costly to an already beleaguered grid). Such **cooling can save tens of thousands of lives each year** , according to the [International Energy Agency](https://www.thedeepview.co/p/<https:/www.iea.org/reports/sustainable-affordable-cooling-can-save-tens-of-thousands-of-lives-each-year?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-grid-can-t-handle-ai>), but **“the rapid growth of AC is putting stress on the power grid.”**
Now, machine learning certainly has a role in enhancing operational efficiencies, which is already much-needed, something we’ve also [talked about before](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/how-one-energy-company-is-utilizing-ai#true-price-of-ai>). But the grid, facing a number of challenges, was not built to handle them all, and it certainly wasn’t built to do so sustainably. 
AI does not exist in a vacuum. So when we think about rapidly expanding integration, we have to center the cost, both short and long-term, of that integration. 
It is not in dollars alone. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/62b7c7a0-9062-4ee0-9fee-9b12dfc74682/Champagne_REAL-min.jpg?t=1734643790)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/34b3231e-e48b-4750-b13b-08ac4228996c/Champagne_FAKE-min.png?t=1734643798)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f2e80720-276f-43c1-ad36-c847df9d66bd/Real_or_Not_Template.jpg?t=1735851420)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “Thumb on other image is too smooth and doesn't have a very lifelike bend. foreground and background on that image also don't look like they came from one image.”


#### Selected Image 2 (Right): 
  * “First image seemed generated because of the number’s shadow.”


**Thanks for reading today’s edition** of The Deep View! 
We’ll see you in the next one. 
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/microsoft-and-openai-have-agi-figured-out-sort-of
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:13.731333
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Microsoft and OpenAI have AGI figured out ... sort of


# ⚙️ Microsoft and OpenAI have AGI figured out ... sort of
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>) January 02, 2025 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fmicrosoft-and-openai-have-agi-figured-out-sort-of>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fmicrosoft-and-openai-have-agi-figured-out-sort-of&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fmicrosoft-and-openai-have-agi-figured-out-sort-of>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fmicrosoft-and-openai-have-agi-figured-out-sort-of>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/15934a03-04d7-4f51-b310-260023334123/Banner_Image.jpg?t=1735663574)
**Good morning** , and happy New Year. 
Hope you all had a lovely holiday (and if you had any AI-related arguments with family members, hope we helped prepare you to win ‘em). 
We’ll be taking a look back at 2024 (and into 2025) next week. In the meantime, things have been a little busy since we last spoke. Let’s get into it. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 🤖 AI for Good: Robotic gloves
  * 📊 xAI raked in $12 billion in funding this year 
  * 💰 Microsoft and OpenAI have AGI figured out … sort of


# **AI for Good: Robotic gloves**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/57d6c807-8b86-4ece-bd7d-5742fbdbeb31/1.jpg?t=1735244268)
Source: ETH Zurich
The idea of AI-enabled robotic exoskeletons — which we talked about last week — has a number of iterations. While one of them does involve full-body suits, others are a bit more targeted. 
**What happened** : For several years now, the Rehabilitation Engineering lab at ETH Zurich has been [developing a robotic glove](https://www.thedeepview.co/p/<https:/relab.ethz.ch/research/current-research-projects/robotic-hand-orthosis-for-therapy-and-assistance-in-activities-of-daily-living.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>) to assist people with hand impairments. 
**The details** : Several diseases, including strokes, cerebral palsy and spinal cord damage, can result in impairments that make it difficult for those affected to use their hands. The idea of the device — called the RELab tenoexo — is to re-enable full-hand use in those impacted populations. 
  * The device itself is a lightweight glove, loaded up with motors, controls and sensors that can be tailored to a user’s specific situation. 
  * The key component of the glove, however, is the algorithm that makes it work, which is designed to detect intent around physical motion, which triggers the functionality of the glove. 


Though still a prototype, the glove promises to aid users both in physical therapy and in their daily lives, offering a means for people to regain their motor function. 
# **xAI raked in $12 billion in funding this year**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dcb90688-b07d-443d-982f-66a099c061bf/2.jpg?t=1735663585)
Source: Tesla
Elon Musk’s xAI said Dec. 23 that it had [closed another $6 billion](https://www.thedeepview.co/p/<https:/x.ai/blog/series-c?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)**funding round,** which included participation from a16z, Fidelity, MGX, Nvidia and AMD, among others. 
**The details:** The money will be used to accelerate the startup’s AI infrastructure build-out, which prominently features a 100,000-strong GPU chip cluster in Memphis, Tennessee, a cluster that xAI plans to shortly double to 200,000 chips. 
  * The firm is currently training Grok 3, the latest version of its Grok series of chatbots, which are accessible through Musk’s X platform.
  * It’s not clear at what valuation the funding was raised, though reports have pegged it at somewhere between [$40 and $50 billion](https://www.thedeepview.co/p/<https:/www.wsj.com/tech/ai/elon-musks-startup-xai-valued-at-50-billion-in-new-funding-round-7e3669dc?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>), a figure that, at least economically, is starting to shape xAI into a real competitor to OpenAI, which is valued at $157 billion. 


**The landscape** : xAI in May closed a $6 billion funding round at a $24 billion valuation, meaning the firm has secured some $12 billion in venture funding this year alone. According to [Business Insider](https://www.thedeepview.co/p/<https:/www.businessinsider.com/fidelity-boosts-valuation-elon-musk-x-xai-2024-12?op=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>), Fidelity recently lifted its valuation of both X and xAI. 
This rapid growth, according to the Southern Environmental Law Center, [is contributing to steadily worsening air pollution in Memphis](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-artificial-intelligence>), the site of xAI’s massive data center, a data center powered by gas turbines which are emitting carbon dioxide and particulate matter alike. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d95aa9c7-83bf-4271-b8e1-a910caa563f9/Shrt_Stories_Blue_.png?t=1735654032)
  * **The parents of OpenAI researcher-turned-whistleblower Suchir Balaji** , who was found dead in his apartment in November, [are demanding an FBI investigation](https://www.thedeepview.co/p/<https:/x.com/RaoPoornima/status/1873282982150324393?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>) into the death of their son, [who, before his death, declared publicly](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/former-openai-researcher-says-the-world-is-not-ready-for-agi>) that the act of training an AI model constituted copyright infringement. Shortly before he died, he was [named a witness](https://www.thedeepview.co/p/<https:/www.gofundme.com/f/justice-for-suchir-balaji?attribution_id=sl:542b5cca-730d-42b1-8991-df5e6c4aa2e9&utm_campaign=man_sharesheet_dash&utm_medium=customer&utm_source=whatsapp>) in the New York Times’ lawsuit against OpenAI. Balaji’s parents said that a private investigation found that their son’s apartment had been “ransacked,” and that a private autopsy “doesn’t confirm (the) cause of death stated by police,” which was suicide. 
  * **South Korea has passed its** “[Basic Act on the Development of Artificial Intelligence and the Establishment of Trust](https://www.thedeepview.co/p/<https:/likms.assembly.go.kr/bill/billDetail.do?billId=PRC_R2V4H1W1T2K5M1O6E4Q9T0V7Q9S0U0&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)” Act, a piece of legislation that, similar to the EU’s AI Act, establishes a comprehensive, risk-based regulatory regime for AI. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Meta envisages social media filled with AI-generated users ([FT](https://www.thedeepview.co/p/<https:/www.ft.com/content/91183cbb-50f9-464a-9d2e-96063825bfcf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 
  * AI brings better odds and betting concerns to sports gambling ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/12/27/2024/ai-brings-better-odds-and-betting-concerns-to-sports-gambling?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 
  * Microsoft works to add non-OpenAI models to Copilot products ([Reuters](https://www.thedeepview.co/p/<https:/www.reuters.com/technology/artificial-intelligence/microsoft-works-add-non-openai-models-into-365-copilot-products-sources-say-2024-12-23/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 
  * Nvidia completes $700 million Run.AI acquisition ([TechCrunch](https://www.thedeepview.co/p/<https:/techcrunch.com/2024/12/30/nvidia-completes-acquisition-of-ai-infrastructure-startup-runai/?guccounter=1&guce_referrer=aHR0cHM6Ly9kdWNrZHVja2dvLmNvbS8&guce_referrer_sig=AQAAABjwh1r1qYGMBF-Hd62CPCUuL5Dqd8nRzq7Ydj1RzrgtZnAeE3azGfJ3iURLVPB7IHei_oZp0GbP4hkKlO8g9Fyt9Jq5T5B-_id99Gp1VZWkFaL2tl-hq3tbApzXqNK-dQveZxd-tUhFhVckygBlsisLDoUaa5ChbUPRcgQl6vEa&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 
  * AI hallucinations are driving scientific breakthroughs ([New York Times](https://www.thedeepview.co/p/<https:/www.nytimes.com/2024/12/23/science/ai-hallucinations-science.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 
  * Silicon Valley’s turn of fortune: Intel has worst year ever, while Broadcom enjoys record gain ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/31/silicon-valley-turn-of-fortune-intel-worst-year-broadcom-record-gain.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# **Microsoft and OpenAI have AGI figured out … sort of**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3e3feac5-86f8-4e00-8317-6e3116b6b8a2/1.jpg?t=1735663600)
Source: OpenAI 
In the week since [OpenAI unveiled o3](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-unveils-powerful-new-model>), the discourse around AGI (artificial general intelligence), already contentious, has heated up. But this discussion of future threats and reasoning benchmarks has been scientifically challenged from the start; no one has a clear definition of what, exactly, AGI is. 
It’s hard to achieve something if you can’t even define what you’re trying to achieve. 
Scratch that, it’s not hard. It’s next to impossible. At least, scientifically. 
Still, one of the major points of the ongoing contract negotiations between OpenAI — which is attempting to transition to a for-profit organization — and Microsoft, OpenAI’s largest financial backer, involves AGI. The reason behind this is likely pretty simple; under the terms of their current agreement, OpenAI gets to withhold all technology deemed “AGI” by OpenAI’s own board, effectively severing the relationship once/if OpenAI achieves this breakthrough. OpenAI loosely defines AGI as something that exceeds most people at “most economically valuable work.”
The pair have been working to nail down a clearer definition. 
**What happened** : According to [The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/microsoft-and-openai-wrangle-over-terms-of-their-blockbuster-partnership?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>), which reviewed internal documents distributed by OpenAI to investors, AGI would only be achieved when OpenAI _has developed a system that has the “capability” to generate the maximum total profits it owes its initial investors._ This totals about $100 billion, with Microsoft alone entitled to $93 billion. 
  * According to the report, the documents state that the declaration of AGI remains up to OpenAI’s board, adding the expected dosage of vagueness and flexibility to a definition that, even in its clarity, remains hard to pin down. 
  * It’s not clear if this $100 billion system refers to a single model, or a system of interconnected models, or how Microsoft plans to assess whether a model is capable of generating that amount of profit. It is also unclear whether any sort of scientific constraints or benchmarks will be coupled with the economics to determine the AGI of it all, or how OpenAI’s conversion to a for-profit organization might impact that definition. 


**Speaking of …** At around the same time, OpenAI [publicly detailed](https://www.thedeepview.co/p/<https:/openai.com/index/why-our-structure-must-evolve-to-advance-our-mission/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>) the reasoning behind its intention to transition from its current hybrid structure — [a strange blend of nonprofit and capped for-profit](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-strange-story-of-openai-and-sam-altman>) — to a more traditional for-profit model. 
In the post, OpenAI explained that the impetus behind its evolution from a strict nonprofit to that odd, hybrid combination, was simple: they needed “far more compute, and therefore far more capital, than we could obtain with donations in order to pursue our mission.”
The company said that it has become clear that the accomplishment of its mission to achieve AGI will require a scale of capital higher “than we’d imagined.” 
  * As it stands today, the plan is to transition into a Deleware Public Benefit Corporation, with OpenAI’s AGI-centric mission as the stated public benefit. The non-profit arm of the company would remain, taking “shares in the PBC at a fair valuation determined by independent financial advisors.” 
  * The corporation will control the business and its operations; the non-profit board will “pursue charitable initiatives.” 


**If OpenAI doesn’t complete this transition** within the next two years, the investors who participated in the company’s recent $6.6 billion funding round [can ask for their money back, plus interest](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-s-bargaining-chip-microsoft-agi-artificial-intelligence>). 
Beyond handling all the logistics behind such a transition, OpenAI will have to deal with legal challenges, the first of which have already appeared. 
Elon Musk, an initial founder of the company, has filed an injunction against the company to block its conversion to a for-profit organization. And Encode, a youth-led organization focused on safeguarding AI, [has backed Musk’s injunction](https://www.thedeepview.co/p/<https:/encodeai.org/encode-backs-legal-challenge-to-openais-for-profit-switch/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=microsoft-and-openai-have-agi-figured-out-sort-of>) in an amicus brief that argues that such a transition **“would fundamentally undermine** OpenAI’s commitment to prioritize public safety in developing advanced artificial intelligence systems.”
  * A hearing on the initial injunction is set to occur on Jan. 14, 2025. 
  * “The public has a profound interest in ensuring that transformative artificial intelligence is controlled by an organization that is legally bound to prioritize safety over profits,” Nathan Calvin, Encode’s vice president of state affairs and general counsel, wrote in a statement.


“OpenAI was founded as a non-profit in order to protect that commitment, and the public interest requires they keep their word,” he added. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
I would add only that this serves as a pretty open admission of the sheer cost associated with the construction and operation of these models. And though they do not mention it, that cost comes in far more than just dollars. 
Still, it is unsurprising and rather fitting that the true, internal definition of AGI centers around simple economics — all these seemingly noble scientific ventures to better humanity are little more than a wrapper around the true, corporate vision of AI: to make a lot of money, roughly $100 billion, for starters. 
So when we think about actual progress and scientific advancements, when we think about ethics and morality and the multi-layered impact that ripples out from AI deployments, let’s remember the simple source of skepticism; that these companies exist, not to better the world, but to sell a product. 
We should have a high bar for what, or who, we’re willing to sell our trust to. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/acb2f2d9-2088-4cfd-af4b-b68d8b588662/2025_REAL-min.jpg?t=1734643843)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4507e458-1336-4787-b822-22f8215323e2/2025_FAKE-min.png?t=1734643848)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d934168a-72a3-4acc-b8d1-c87916d6b1a5/Real_or_Not_Template.jpg?t=1735663724)
## 🤔Your thought process: 
#### Selected Image 2 (Left): 
  * “The stocking in the first image is wonky and the words all looked great in the 2nd image.”


#### Selected Image 2 (Left): 
  * “That unhinged owl blurred out in the background has no business being in an AI image”


**Thanks for reading today’s edition** of The Deep View! 
We’ll see you in the next one. 
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/report-the-data-center-energy-spike
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:18.288561
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Report: The data center energy spike


# ⚙️ Report: The data center energy spike
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) December 24, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-data-center-energy-spike>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-data-center-energy-spike&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-data-center-energy-spike>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Freport-the-data-center-energy-spike>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a819e8be-0f58-4b37-a25c-c5f968624de6/Banner_Image-2.jpg?t=1734980553)
**Good morning**. Today marks our last report of 2024. We’ll be taking some time to rest and recharge for what promises to be a busy, busy 2025 (and we hope you are all doing the same). 
We’ll see you in the new year, and in the meantime, hope you all enjoy a week of relaxation, comfort food and family time. Happy holidays!
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 🤖 AI for Good: Wearable robots
  * 👁️‍🗨️ Biden launches investigation into Chinese chips
  * 🏛️ Europe’s AI Code of Practice nears publication
  * ⚡️ Report: The data center energy spike


# **AI for Good: Wearable robots**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/0d559f58-d0f1-4e7c-bbbb-2f1342cfa2f4/1.jpg?t=1734980486)
Source: KAIST
Researchers at the Exoskeleton Laboratory at the Korea Advanced Institute of Science and Technology (KAIST) [recently developed](https://www.thedeepview.co/p/<https:/news.kaist.ac.kr/newsen/html/news/?mode=V&mng_no=40790&skey=category&sval=etc&list_s_date=&list_e_date=&GotoPage=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) a lightweight, wearable exoskeleton — inspired by “Iron Man” — to help paralyzed people walk again. 
**The details** : Unlike other exoskeletons, the WalkON Suit F1 was designed to autonomously walk up to and attach to its user, even if the user is sitting in a wheelchair. This enables a paraplegic person to get into the suit without additional help. 
  * The suit comes loaded up with sensors and cameras, in addition to advanced motion control and computer vision algorithms, which work together to help the robot predict movement, retain balance and avoid obstacles. 
  * Competing recently in the Cyborg Olympics, an international competition focused on evaluating robotic assistance for disabled people, the KAIST team [took home](https://www.thedeepview.co/p/<https:/news.kaist.ac.kr/newsen/html/news/?mode=V&mng_no=40910&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) a gold medal as the only team capable of completing all the required tasks. 


**Why it matters** : For years now, researchers have been examining ways in which machine learning can be leveraged to produce advanced prosthetics, not just for paraplegics, but also for people who have lost limbs. That promise is now coming into reach. 
# **Biden launches investigation into Chinese chips**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d90b5d2a-5733-4e9f-ba25-a04855eaef1a/3.jpg?t=1734980497)
Source: Unsplash
President Joe Biden’s administration [said](https://www.thedeepview.co/p/<https:/www.whitehouse.gov/briefing-room/statements-releases/2024/12/23/fact-sheet-president-biden-takes-action-to-protect-american-workers-and-businesses-from-chinas-unfair-trade-practices-in-the-semiconductor-sector/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) Monday that it is launching an investigation into foundational, or legacy, chips made in China. The legacy chips that are the target of the inquiry are not as advanced as the chips used for artificial intelligence applications, though they are used in a number of non-AI applications. 
**The details:** The U.S. Trade Representative, in the months-long probe that will follow, will first assess whether China’s actions are “unreasonable” and burdensome.
  * This, as [Bloomberg](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/technology/tech-companies/biden-team-to-probe-chinese-chips-setting-up-trump-for-tariffs/ar-AA1wmeOi?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) pointed out, opens up the impending Trump administration to impose tariffs on the sector. 
  * The current administration said it is still exploring ways to shore up and centralize the semiconductor supply chain. 


**The landscape** : This follows a recent round of [export restrictions](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/report-ai-and-cybersecurity-in-the-enterprise>) from both the U.S. and China that was focused on restricting the flow of materials necessary to build advanced computer chips. 
The President-elect, meanwhile, has promised to impose tariffs of as much as 60% on Chinese goods. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/c896eba1-8fb8-4b6d-bc8c-108eabb20dc6/Shrt_Stories_Blue_.png?t=1734966850)
  * **The latest report from the****[National AI Opinion Monitor](https://www.thedeepview.co/p/<https:/naiom.net/reports/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)** found that privacy and security remain key concerns around AI: “Americans are particularly concerned about AI’s influence on politics (58%) and news media (53%), likely reflecting fears of misinformation and manipulation during the 2024 election cycle.”
  * **Last week, a bipartisan US House of Representatives Task Force** on Artificial Intelligence published a [massive report](https://www.thedeepview.co/p/<https:/www.speaker.gov/wp-content/uploads/2024/12/AI-Task-Force-Report-FINAL.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) detailing recommendations on AI to Congress. Kate Brennan, associate director of the AI Now Institute, [said](https://www.thedeepview.co/p/<https:/www.techpolicy.press/reactions-to-the-bipartisan-us-house-ai-task-force-report/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) the report gestures “towards the many material harms of rapid AI adoption while providing few meaningful policy recommendations to address it.”


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Palantir and Anduril join forces with tech groups to bid for Pentagon contracts ([FT](https://www.thedeepview.co/p/<https:/www.ft.com/content/6cfdfe2b-6872-4963-bde8-dc6c43be5093?sharetype=blocked&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)). 
  * AI is here to stay, so we may as well learn to use it? That’s a cop-out ([Times Higher Education](https://www.thedeepview.co/p/<https:/www.timeshighereducation.com/blog/ai-here-stay-so-we-may-well-learn-use-it-thats-cop-out?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)). 
  * OpenAI has edge over Google in winning publishers’ business ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/openai-has-edge-over-google-in-winning-publishers-business?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)). 
  * Exclusive — **Microsoft works to add non-OpenAI models** into 365 Copilot products, sources say ([Reuters](https://www.thedeepview.co/p/<https:/www.msn.com/en-ca/money/topstories/exclusive-microsoft-works-to-add-non-openai-models-into-365-copilot-products-sources-say/ar-AA1wnPD0?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)). 
  * The Philippines is creating a ChatGPT rival that speaks Filipino and Taglish ([Rest of World](https://www.thedeepview.co/p/<https:/restofworld.org/2024/filipino-ai-chatbot-launches-2025-local-languages/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# **Europe’s AI Code of Practice nears publication**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/0be139fe-8b4a-458f-afaf-c7ba027a5877/2.jpg?t=1734980504)
Source: Unsplash
Last week, the second draft of the European Commission’s general purpose AI Code of Practice was [published](https://www.thedeepview.co/p/<https:/digital-strategy.ec.europa.eu/en/policies/ai-code-practice?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike#timeline>), bringing the commission one step closer to eventually releasing a finalized version of the Code. 
**The details** : The Code is designed as a guiding source for ensuring developers remain compliant with the EU’s AI Act, which began entering into force earlier this year. 
  * The draft thus far details copyright and transparency obligations for developers of general-purpose generative AI systems, which will include summaries of the content used to train each model. 
  * The second part of the draft Code applies only to developers of the “most advanced” generative AI models, and includes a list of safety and transparency obligations. 


The group [plans](https://www.thedeepview.co/p/<https:/digital-strategy.ec.europa.eu/en/policies/ai-code-practice?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike#timeline>) to publish the third draft of the Code of Practice in February of next year; the intention is to publish a final version of the Code by May of 2025. 
**The landscape** : Europe remains one of few countries committed to regulating AI, with regulatory efforts stalled out or stagnant in the U.S. and the U.K., despite [significant public support](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/new-poll-americans-want-ai-regulation>) for legislation that would rein the technology in. 
# **Report: The data center energy spike**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8ab48813-0341-413d-97e3-9bcda5275b78/4.jpg?t=1734980510)
Source: Google
A recent [report](https://www.thedeepview.co/p/<https:/www.energy.gov/articles/doe-releases-new-report-evaluating-increase-electricity-demand-data-centers?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>) from the U.S. Department of Energy (DOE) found that data center electricity load growth has tripled over the past 10 years, and is expected to double again between 2024 and 2028. 
**The details** : The report attributes the growth in U.S. electricity demand to the “rise of artificial intelligence” and the steady expansion of the data centers used to power the tech. 
  * According to the report, data centers consumed 4.4% of total U.S. electricity in 2023 and are expected to consume as much as 12% of total electricity demand by 2028. 
  * In 2014, data centers used 58 terawatt hours (TWh) of electricity; in 2023, they used 176 TWh and in 2028, they are expected to use as much as 580 TWh. 


For context, Greece, Switzerland and Israel each [consumed around](https://www.thedeepview.co/p/<https:/ourworldindata.org/energy-production-consumption?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>)**300 TWh of electricity** in 2023. 
“The United States has seen an incredible investment in artificial intelligence and other breakthrough technologies over the last decade and a half, and this industrial renaissance has created greater demand on our domestic energy supply,” U.S. Energy Secretary Jennifer Granholm said in a statement.**“We can meet this growth with clean energy.”**
The energy department is pushing both industrial energy storage and on-site energy generation for data center operators as part of its plan to make data centers a “grid asset rather than a burden.”
The department said that the commercialization of technologies including more efficient semiconductors, advanced nuclear energy, long-term energy storage and geothermal energy will all be vital to meet this steadily rising demand. 
Geothermal, according to the [International Energy Agency](https://www.thedeepview.co/p/<https:/www.iea.org/reports/the-future-of-geothermal-energy/executive-summary?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=report-the-data-center-energy-spike>), currently meets less than 1% of the world’s energy demand. But the IEA recently found that investment in geothermal is growing, with the sector **expected to draw some $1 trillion globally by 2035.**
As costs continue to fall, the IEA predicted that geothermal has the potential to provide **some 15% of the world’s energy demand** by 2050. 
This comes as the energy demand of AI has pushed the bulk of the [Big Tech sector to pursue the construction of new nuclear power](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>) plants. In the meantime, [new research has highlighted](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-public-health-crisis-of-artificial-intelligence>) the massive impact of data center emissions on public health around the world.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
When I think about the cost-benefit analysis of AI use and the lack of transparency in the industry, I think about energy use and emissions. All we know is that energy demand keeps spiking, pushing far ahead of innovations in technological efficiency. 
We need to re-ground our collective understanding of chatbots and the internet at large, not as some mystical, on-demand portal, but as the result of extensive hardware, powered by enormous quantities of electricity and emitting enormous quantities of carbon and other particulate matter. 
We need to refocus our attention on achieving innovations in technological efficiency, and we need to think more about the cost of use associated with these systems. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8a2f3950-5a1c-4726-bb8c-c5472a149a59/Presents_FAKE-min.png?t=1734643952)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/902a0d11-40cd-4e16-97ee-11e185a0dcf0/Presents_REAL-min.jpg?t=1734643946)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4c4c21dd-ccf7-4cf9-b339-7e28cdbb574e/Real_or_Not_Template-2.jpg?t=1734979648)
## 🤔Your thought process: 
#### Selected Image 2 (Left): 
  * “The flames on these candles were more realistic and variable than those of Image 1.”


#### Selected Image 1 (Right): 
  * “The light on the second seems artificial.”


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you next year. 
### Here’s your view on o3: 
33% of you think it is time for some regulation already. 
26% said it should be released; 15% said it shouldn’t. 
18% don't think it’s actually that powerful. 
**Depends:**
  * “It should NOT be released until there is enough enforceable regulation and a monitoring framework to ensure no one ignores probable risk because of financial gain.”


**Not that powerful:**
  * “They already proved they overhype and underdeliver with Sora.”


![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/openai-unveils-powerful-new-model
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:23.013866
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ OpenAI unveils powerful new model


# ⚙️ OpenAI unveils powerful new model
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) December 23, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fopenai-unveils-powerful-new-model>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fopenai-unveils-powerful-new-model&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fopenai-unveils-powerful-new-model>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fopenai-unveils-powerful-new-model>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a7a50ec9-3395-4a84-b793-656e36d745d5/Banner_Image.jpg?t=1734804490)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/156b5265-0e41-4d41-8485-8c8aa69b4a64/Together_W_Thoughtly__2_.png?t=1734917004)](https://www.thedeepview.co/p/<https:/thought.ly/?utm_source=deepview&utm_medium=email&utm_campaign=deepviewnewsletter_nov10&utm_id=deepviewnewsletter>)
**Good morning**. OpenAI unveiled its next foundation model, o3, last week, in a reveal that succeeded in planting the spotlight firmly on the company. 
The model spent the weekend at the center of a raging debate between researchers on Twitter over the actual capabilities — and therefore, actual impact — of the model. 
But the release raises more questions than it answers. We get into it all below. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 👁️‍🗨️ AI for Good: Landmine detection 
  * 💻 Researchers unveil the Genesis project
  * 📊 OpenAI unveils powerful new o3 model


# **AI for Good: Landmine detection**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/0c506a75-b635-41a8-9bdd-90093d0995fa/1.jpg?t=1734804497)
Source: Unsplash
The use of landmines in conflicts around the world has an enormous downstream impact. The problem of demining land for future civilian use is one that first requires the detection of unexploded devices, which is a process that could take decades. 
The scope of the crisis has inspired evaluations of different technologies that might speed things along. 
**What happened** : Earlier this year, a small team of researchers [designed an artificial intelligence-based system](https://www.thedeepview.co/p/<https:/www.mdpi.com/2072-4292/16/4/677?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) that, when combined with a camera-equipped robot, is capable of rapid landmine detection. 
  * The AI system — specifically, a deep learning algorithm — was designed specifically as a lightweight solution, meaning it can be run on the same iPhone being used to control the robot (all from a safe distance). 
  * It was trained and finetuned on images and videos of landmines in various conditions and environments. According to the study, the system demonstrated a high efficacy rate in detecting two types of landmines — **97.69%** for “butterfly” mines and**99.4%** for “starfish” mines. 


The researchers intend to continue their work here, specifically focusing in on enhancing the model’s robustness in dramatically different environments. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Never leave your business on hold: Revolutionize phone calls with Thoughtly**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4699dcfc-ad30-4470-9e59-ca9e22a8248b/Thoughtly_AI_Voices_Real_Conversations__1___1_.gif?t=1734917210)](https://www.thedeepview.co/p/<https:/thought.ly/?utm_source=deepview&utm_medium=email&utm_campaign=deepviewnewsletter_nov10&utm_id=deepviewnewsletter>)
**Generative AI is transforming the call center industry, and**[**Thoughtly**](https://www.thedeepview.co/p/<https:/thought.ly/?utm_source=deepview&utm_medium=email&utm_campaign=deepviewnewsletter_nov10&utm_id=deepviewnewsletter>)**is at the forefront of this revolution.**
Thoughtly’s advanced AI agents can handle phone calls in any language, delivering seamless, natural-sounding conversations 24/7. Your team can now focus on the work that matters most—while Thoughtly’s AI keeps your call center running smoothly.
**Introducing Automations**
Our latest feature, Automations, takes integration to the next level by allowing you to connect Thoughtly directly with any CRM. Sync data effortlessly, automate follow-ups, and create a fully connected ecosystem for sales, support, and beyond.
✨ Why Thoughtly? 
  * **Streamlined Efficiency:** From sales to support, optimize every interaction across channels.
  * **Seamless Integration:** Works perfectly with your existing tech stack—including CRMs via Automations. 
  * **Real Insights:** Access a comprehensive analytics suite for actionable feedback and improvement. 


[Reimagine customer interactions with Thoughtly. Empower your team, delight your customers, and transform your call center into a hub of innovation.](https://www.thedeepview.co/p/<https:/thought.ly/?utm_source=deepview&utm_medium=email&utm_campaign=deepviewnewsletter_nov10&utm_id=deepviewnewsletter>)
# **Researchers unveil real-world simulator: ‘The Genesis Project’**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f5a60740-d96b-4dc2-bf9e-f2276aa032bf/2.jpg?t=1734804505)
Source: The Genesis Project
Last week, a massive team of researchers [unveiled something called “the Genesis Project,”](https://www.thedeepview.co/p/<https:/genesis-embodied-ai.github.io/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) the result of a 24-month-long research collaboration between 20 different labs designed specifically for advanced robotics. 
**The details** : According to the team, [Genesis](https://www.thedeepview.co/p/<https:/genesis-world.readthedocs.io/en/latest/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) is a “universal physics engine” capable of simulating a range of physical objects and environments, a lightweight robotic simulation platform, a photo-realistic rendering system and a generative engine, all wrapped up in one. 
  * Unlike traditional generative AI models, Genesis seems to represent an integrated system of multiple components; the physics engine at the core — powered in part by a vision language model (VLM) — and the generative framework layered on top. The team is open-sourcing the underlying physics engine, and said it plans **to openly release the generative component soon.**
  * Genesis achieves this accurate reconstruction of physical environments, [according](https://www.thedeepview.co/p/<https:/x.com/zhou_xian_/status/1869514344318583014?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) to the researchers, by integrating “a wide spectrum of state-of-the-art physics solvers, allowing simulation of the whole physical world in a virtual realm with the highest realism.”


It’s not yet clear what the Genesis system will be actually be used for, though it seems to overcome traditional physics-based limitations of existing image and video generators. 
Still, we won’t know much about its impact until the whole thing is released into the hands of researchers, where it will be tested, pushed and verified. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/92aab6e6-4060-4757-a6dc-96bbd35f4539/Shrt_Stories_Blue_.png?t=1734724763)
  * **Italy’s data privacy watchdog**[**fined OpenAI $15.58**](https://www.thedeepview.co/p/<https:/www.gpdp.it/home/docweb/-/docweb-display/docweb/10085432?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) million last week, the result of a 2023 investigation into the startup that found that OpenAI “processed users' personal data to train ChatGPT without first identifying an adequate legal basis.” OpenAI [said](https://www.thedeepview.co/p/<https:/www.msn.com/en-gb/money/technology/italy-fines-openai-over-chatgpt-privacy-rules-breach/ar-AA1wfo0d?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) it will appeal the ruling. 
  * **Google**[**introduced**](https://www.thedeepview.co/p/<https:/x.com/OfficialLoganK/status/1869789820308074837?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)**Gemini 2.0 Flash Thinking last week** , a model that, similar to OpenAI’s “o” series, employs Chain of Thought “reasoning” to better solve complex problems. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Exclusive-US data-center power use could nearly triple by 2028, DOE-backed report says ([Reuters](https://www.thedeepview.co/p/<https:/www.msn.com/en-us/money/companies/exclusive-us-data-center-power-use-could-nearly-triple-by-2028-doe-backed-report-says/ar-AA1weCuD?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)). 
  * The ghosts in the machine ([Harper’s Magazine](https://www.thedeepview.co/p/<https:/harpers.org/archive/2025/01/the-ghosts-in-the-machine-liz-pelly-spotify-musicians/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)). 
  * Elon Musk endorses far-right Alternative for Germany party in upcoming election ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/20/elon-musk-endorses-far-right-alternative-for-germany-party-in-election.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)). 
  * Congress steers away from a damaging shutdown ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/12/20/2024/congress-steers-away-from-a-damaging-shutdown?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)). 
  * It’s AI! It’s Crypto! Crypto meets AI ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/its-ai-its-crypto-its-crypto-meets-ai?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)).


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
# **OpenAI unveils powerful new o3 model**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/2da237b9-9af8-44d8-9102-5b2b40bfe654/3.jpg?t=1734804564)
Source: OpenAI
On the last of its “12 days of OpenAI” series — which, until this point, had only really notably seen the wider launch of Sora — OpenAI [unveiled](https://www.thedeepview.co/p/<https:/openai.com/12-days/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) its next foundation model family, o3, the successor to the o1 “reasoning” model that it released earlier this year. Both models feature private “Chain of Thought reasoning,” in which a model works through a problem step-by-step; a brute-force mimicry of human reasoning. 
Like with o1, OpenAI has a few versions of o3; there’s the normal one, then there’s o3 mini, which can be used at different inference levels. 
**Now this was an unveil** , not a launch. CEO Sam Altman said during a livestream that the company intends to launch o3 mini **by the end of January, and o3 “shortly after that,”** but it is quite unclear what hurdles remain between now and an actual launch of the product. 
OpenAI researchers said that, currently, o3 is undergoing internal safety testing and interventions; in a bit of an uncharacteristic move for OpenAI, the company opened up applications for external safety testing of the mini version of o3. It’s not clear how long this process will take, or what kinds of safety risks are actually posed by o3 — if the improvements are as significant as OpenAI suggested, it might exceed OpenAI’s own safety framework for release.
**The details** : I’m going to preface all this by saying two things: one, OpenAI’s lack of transparency around what they’re actually building persisted with this launch (we don’t know anything about the model), and two, little of what OpenAI presented has actually been independently verified. A demo is just a demo. 
  * **But** , [according to internal OpenAI research](https://www.thedeepview.co/p/<https:/x.com/__nmca__/status/1870170112290107540?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>), o3 smashes through benchmarks on coding, software engineering and math; on competition code, o3 scored a 2727 to o1’s 1891. On software engineering, **o3 scored a 71.7 to o1’s 48.9.** And on frontier math (some of the hardest math problems in existence) o3 boosted the state-of-the-art accuracy rate from 2% to 25.2%. On other [benchmarks](https://www.thedeepview.co/p/<https:/x.com/GaryMarcus/status/1870179616159346696/photo/1?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>), o3 mini performed **on par with or below** o1 and GPT-4o. 
  * While undoubtedly impressive on its face, **we don’t know what the model was trained** on — or even what the model itself is — to achieve those results, making it impossible to make any hard statements about o3’s capabilities. Until OpenAI increases transparency on these points — and they won’t — **true evaluation will be almost impossible**. 


As AI researcher Chomba Bupe [wrote](https://www.thedeepview.co/p/<https:/x.com/ChombaBupe/status/1870126412579123686?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>), “they most likely have a ton of engineered scaffolding code to hold them together under the hood. If they were truly building a learning & adapting system they would demo how the model learns on the fly to solve totally new problems rather than making the model plagiarize a lesser-known problem, that someone already solved, to make it look good in public eyes.”
**ARC-AGI** : In 2019, computer scientist Francois Chollett published a paper that introduced an AGI benchmark, quantifying just how hard it would be to get AI models to a point of general intelligence. AGI, referring to artificial general intelligence, [refers to a hypothetical evolution of AI that would feature human-like intelligence](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/the-nobel-prize-and-the-mainstreaming-of-ai-s-x-risk>); many researchers do not believe it is achievable, in part, due to the field’s consistent inability to define what AGI might even be in the first place (plus a consistent inability to define what, exactly, human intelligence itself is). 
  * Chollett has since published the ARC-AGI-1 benchmark, with the goal of directing research specifically toward AGI, and away from traditional benchmarks. _The benchmark specifically features problems that are easy for humans to solve, but really challenging for AI models._ OpenAI’s o3, as verified by ARC, **scored a 75.7% on ARC’s AGI benchmark.**
  * **Importantly, the model**[**was trained**](https://www.thedeepview.co/p/<https:/x.com/fchollet/status/1870170403592880487?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>)**on the benchmark.** ARC [noted](https://www.thedeepview.co/p/<https:/arcprize.org/blog/oai-o3-pub-breakthrough?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) that o3 was trained on“75% of the Public Training set. _They have not shared more details._**We have not yet tested the ARC-untrained model to****understand how much of the performance is due to ARC-AGI data****.”**


**While this is common in machine learning** , the problem (which was at the core of a Twitter battle over the weekend) is that the real significant measure of a possible AGI involves performance on problems a model was _not_ trained on; there was a lot of confusion from OpenAI regarding the reality of that situation, with Altman saying during the live stream that the benchmark wasn’t “targeted” despite OpenAI using the training set.
Dumitru Erhan, Google DeepMind’s research director, [called](https://www.thedeepview.co/p/<https:/x.com/doomie/status/1870624630928806356?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) out the lack of scientific rigor surrounding the release, saying: “Why is everyone so intellectually uncurious, especially the challenge organizers, about the mechanisms by which this impressive submission that obliterates everything else out there works? Can we as a community not express some genuine scientific skepticism?”
**A higher compute —** _**172x**_**— configuration of o3** scored an 87.5% on the ARC benchmark after 16 hours. (_85% was the key number to consider the benchmark beaten_ , but Chollett said that, **until a highly efficient, open-sourced model can score an 85%, he will continue to run the ARC-AGI prize** ; 172x compute is not, after all, efficient whatsoever). 
The cost in compute of **achieving the first score was $2,000, or $20 per task** ; OpenAI requested that ARC **not make public the cost associated** with the 172x increase in compute required for the 87.5% score. 
Chollett said that, despite the cost, this is a **“genuine breakthrough.”** But he said that a high score on ARC-AGI **doesn’t mean that AGI has been achieved;** it’s only one benchmark, and it’s become highly saturated. He plans to launch a second version of the ARC-AGI benchmark soon. 
“I don't think o3 is AGI yet,” he [wrote](https://www.thedeepview.co/p/<https:/arcprize.org/blog/oai-o3-pub-breakthrough?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>). “o3 still fails on some very easy tasks, **indicating fundamental differences with human intelligence,”** adding that he expects o3 to struggle mightily with ARC-AGI-2. “You'll know AGI is here when the exercise of creating tasks that are easy for regular humans but hard for AI becomes simply impossible.”
The other element to this is that success on a benchmark **does not address other limitations of the architecture** ; as Dr. Gary Marcus [pointed](https://www.thedeepview.co/p/<https:/x.com/GaryMarcus/status/1870176543109988850?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) out, **Altman did not address issues of hallucination or algorithmic bias** during the livestream whatsoever, and “was very light on applications outside of benchmarks in closed domains.” 
The announcement **also didn’t mention the 2024 ARC**[**leaderboard**](https://www.thedeepview.co/p/<https:/arcprize.org/2024-results?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>) , whose previous high score — _at 53.5%_ — was achieved using Anthropic’s Claude Sonnet 3.5. Jeremy Berman explains how he got Sonnet to a 53.5% on the benchmark in this illuminating [post](https://www.thedeepview.co/p/<https:/jeremyberman.substack.com/p/how-i-got-a-record-536-on-arc-agi?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>). 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cb94f570-d46d-4287-a584-526a9dd53bac/Screenshot_2024-12-22_at_11.18.52_AM.png?t=1734884345)
The current ARC-AGI leaderboard. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
I remain skeptical of internal benchmark numbers released without transparency. The model — or system, we don’t know — was very likely trained on those benchmarks, meaning that high scores are not necessarily indicative of much. 
That said, this seems like a significant increase in the realm of the possible, judging by the fact that previous models were also likely trained on those benchmarks, making the difference in benchmark scoring a good place to start in ascertaining model-to-model differences. 
If that jump in benchmarking capability is generalizable across the model — _which is highly, highly unlikely_ — then I would say that o3 should be considered a “high” risk model, by OpenAI’s own [safety framework](https://www.thedeepview.co/p/<https:/openai.com/index/openai-o1-system-card/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>), and thus, shouldn’t be released. But **OpenAI is a for-profit company.** They don’t care about AGI; they care about making money. 
It’s profitable to hype up the capabilities of their models. Their goal is, after all, to sell these products. So, either o3 isn’t actually that powerful/dangerous, and it’ll be released, or it _is_ actually that powerful/dangerous, and they’ll probably release it anyway. 
And here’s another problem with OpenAI and corporate research; there’s no transparency.**We don’t know the cost,** in electricity, carbon emissions, hardware or time of building the model; we don’t know the cost in electricity and carbon emissions of operating the model at any level; we don’t know what the model was trained on; **we don’t know anything about its internal architecture** , which means researchers can’t know how powerful it _actually_ is or isn’t … All we have is OpenAI’s word, and, as I mentioned, anything they say must be taken with a grain (or two, or three) of salt as the intention behind all of their actions and public interactions is to _sell their products._
This is probably something. The clearest indication of its capability is the ARC-verified benchmark, but again, that’s just a benchmark. It’s just impossible to tell at this stage what o3 actually is, what impact o3 will actually have, if or when anyone will see it and whether it will ever be economically — and sustainably! — viable to deploy. 
“Breakthroughs aren't just shouted out from the mountain tops,” Bupe [wrote](https://www.thedeepview.co/p/<https:/x.com/ChombaBupe/status/1870456642925683139?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=openai-unveils-powerful-new-model>). “Scientific breakthroughs must be independently verified by a wider scientific community. As a product, I have no problems with the secrecy. But OpenAI trying to push their products as scientific research is what's wrong here.”
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/49ccaa52-ebbd-4772-96c3-f923803a0ec9/Menorah_FAKE-min.png?t=1734643989)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e275a466-46b4-4648-9fad-dc0e823018ac/Menorah_REAL-min.jpg?t=1734643994)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/55c5c967-b663-43c9-97a1-3fcc2e772733/Real_or_Not_Template.jpg?t=1734804803)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * _“I've been there!”_


####  Selected Image 2 (Right): 
  * _“Seemed like AI could not replicate the complex shadowing.”_


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on the AI trade in light of Micron’s stumble: 
34% of you don’t think the AI trade is unwinding; 25% think it is. 
**Yes:**
  * “If not now, soon …”


### To release, or not release ... If o3 is as powerful as OpenAI says, should it be released?   
---  
  * [ It should NOT be released ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ It SHOULD be released ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ We need regulation already, jeez ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ It's probably not that powerful ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/the-public-health-crisis-of-ai
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:27.974757
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Anthropic and the problem of 'AI alignment' 


# ⚙️ Anthropic and the problem of 'AI alignment' 
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) December 20, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fthe-public-health-crisis-of-ai>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fthe-public-health-crisis-of-ai&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fthe-public-health-crisis-of-ai>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fthe-public-health-crisis-of-ai>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7a3a0645-0325-45ee-b781-15a8f0aa586d/Banner_Image-min.jpg?t=1734642142)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e767ba22-e4df-4415-a06e-4d2d41af8c0d/Together_W_Percent__1_.png?t=1734462894)](https://www.thedeepview.co/p/<https:/percent.com/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=dec2024>)
**Good morning**. On the 11th day of “shipmas” OpenAI [gave](https://www.thedeepview.co/p/<https:/x.com/kevinweil/status/1869811511616778280?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1869811511616778280%7Ctwgr%5E480553d6d26175df40cf23c014a19314f8a59c60%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.theverge.com%2F2024%2F12%2F19%2F24325283%2Fchatgpt-now-works-with-a-few-new-desktop-apps&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) … slightly greater connectivity with desktop apps. 
I guess every day can’t be Sora. 
Have a great weekend, everyone! 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 🌎 AI for Good: Ecological preservation 
  * 📊 The Micron tumble continues in wake of weak guidance
  * 🚘 Waymo reports a blistering pace of growth this year
  * 🚨 Anthropic and the problem of 'AI alignment'


# **AI for Good: Ecological preservation**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3903c78f-c8a7-407f-a52d-426ab86b93a0/1-min.jpg?t=1734642154)
Source: Unsplash
Over the past 50 years, the average size of monitored wildlife populations around the world has declined by more than 70%, according to the [World Wildlife Fund](https://www.thedeepview.co/p/<https:/www.worldwildlife.org/press-releases/catastrophic-73-decline-in-the-average-size-of-global-wildlife-populations-in-just-50-years-reveals-a-system-in-peril?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>). 
“These steep drops signal that nature is unraveling and becoming less resilient,” WWF Chief Scientist Rebecca Shaw said. “When nature is compromised, it is more vulnerable to climate change and edges closer to dangerous and irreversible regional tipping points.”
Amid pushes from the WWF and others for governments to increase investments in the protection of wildlife and their natural habitats — which would mainly require an immediate and massive reduction in carbon emissions — some are turning to technological solutions. 
**What happened** : Microsoft this week announced Project Sparrow, an AI-powered edge computing device designed to robustly, autonomously (and with a small footprint) gather vital ecological data. 
  * The open-sourced device can transmit this data from highly isolated global regions directly to conservationists; better, more targeted conservation begins with a better understanding of these ecosystems, and that is reliant on more data. 
  * Microsoft plans to begin deploying these devices over the next few months, before expanding its reach next year. 


**This is one of many**[AI-powered conservation tools](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant>) out there, and while it certainly can aid in focused conservation efforts, it won’t help the bigger problem, as NASA, the WWF and others have pointed out: [we need to stop emitting immediately](https://www.thedeepview.co/p/<https:/science.nasa.gov/climate-change/faq/is-it-too-late-to-prevent-climate-change/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>). 
There is a necessary balance to these kinds of solutions, as the computation involved will likely cause some amount of emissions. Broad AI applications, meanwhile, have been causing massive surges in emissions.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Think Beyond Stocks for 2025 and Beyond**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/bbbe99aa-ff5b-4355-b74b-919625ec1d0a/Percent-Unlock_2__1_.png?t=1734463311)](https://www.thedeepview.co/p/<https:/percent.com/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=dec2024>)
**Goldman Sachs predicts U.S. stocks will return only 3% annually over the next decade.** For investors looking to grow their portfolios, [private credit](https://www.thedeepview.co/p/<https:/percent.com/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=dec2024>) offers a compelling alternative, delivering higher potential returns and a buffer against stock market fluctuations.
On [Percent](https://www.thedeepview.co/p/<https:/percent.com/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=dec2024>), private credit has become a popular option for those seeking both stability and growth potential—providing accredited investors with consistent income and an alternative to equities.
  * **Outpaced Equities in Market Downturns:** Private credit has consistently delivered during recent corrections.
  * **Higher Yield Potential:** Percent’s [Q2 and Q3 net returns](https://www.thedeepview.co/p/<https:/percent.com/our-track-record-of-performance/?utm_source=deepview&utm_medium=newsletter&utm_campaign=dec2024>) were over 13%.
  * **Short-Term Commitments:** Average deal term of 9 months offers flexibility.
  * **Monthly Cash Flow:** Most deals offer steady income through regular interest payments.


[Diversify with private credit and drive growth beyond traditional stocks. Sign up with Percent and get up to $500 on your first investment.](https://www.thedeepview.co/p/<https:/percent.com/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=dec2024>)
# **The Micron tumble continues in wake of weak guidance**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/5deb813a-56a2-4344-80f4-b94c945422c0/2-min.jpg?t=1734642162)
Source: Micron
Shares of Micron, despite the chipmaker’s narrow earnings beat on Wednesday, fell by **some 16% on Thursday,** one of its worst days since March of 2020. 
**How they did** : Micron [reported](https://www.thedeepview.co/p/<https:/investors.micron.com/news-releases/news-release-details/micron-technology-inc-reports-results-first-quarter-fiscal-2025?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) revenue of $8.71 billion for the quarter, in line with analyst expectations, and earnings of $1.79 per share, slightly above analyst expectations. 
  * Importantly, the firm’s data center revenue **grew 40% from last quarter and some 400% from last year** ; data center revenue**surpassed 50% of Micron’s total revenue** for the first time, and Micron expects it to keep growing. 
  * “While consumer-oriented markets are weaker in the near term, we anticipate a return to growth in the second half of our fiscal year,” Sanjay Mehrotra, President and CEO of Micron Technology, wrote. “We continue to gain share in the highest margin and strategically important parts of the market and are exceptionally **well positioned to leverage AI-driven growth** to create substantial value for all stakeholders.”


Despite this, the company guided revenue for its next quarter at $7.9 billion,**far off the $8.98 billion analysts were expecting, precipitating** the stock fall. 
**But Daniel Newman, CEO of the Futurum Group** , doesn’t think that Micron’s miss spells doom for the rest of the AI trade; he [said](https://www.thedeepview.co/p/<https:/x.com/danielnewmanUV/status/1869552496797995346?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) that Micron’s core business (PC and smartphones) is contracting, something that will pressure the stock in the coming quarters. But its data center business is growing strong, an indicator that the AI trade remains intact. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/f28acd20-4c64-4628-a382-eea295a6895d/Shrt_Stories_Blue_.png?t=1734618292)
  * **A new report from the****[Data Provenance Initiative found](https://www.thedeepview.co/p/<https:/www.technologyreview.com/2024/12/18/1108796/this-is-where-the-data-to-build-ai-comes-from/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)** that the data practices baked into AI development currently risk concentrating power in the hands of a few dominant tech titans. 
  * **IBM unveiled**[**Granite 3.1,**](https://www.thedeepview.co/p/<https:/www.ibm.com/new/announcements/ibm-granite-3-1-powerful-performance-long-context-and-more?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) an updated version of its small Granite series of enterprise-optimized language models. The model, made openly accessible on Hugging Face, notched competitive benchmark performance against similarly-sized models. IBM said the performance growth was achieved by expanding the model’s context windows. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d8952608-295d-4a3e-9e83-37612f287df6/image.png?t=1734618254)
  * US prompts Nvidia, Supermicro probe into how chips ended up in China ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/u-s-prompts-nvidia-supermicro-probe-into-how-chips-ended-up-in-china?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)). 
  * AI poses threat to North American electricity grid, watchdog warns ([FT](https://www.thedeepview.co/p/<https:/www.ft.com/content/7c241e6f-e9c1-4f45-883a-8d46e6bf8cd8?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)). 
  * The new old warfare ([Boston Review](https://www.thedeepview.co/p/<https:/www.bostonreview.net/articles/the-new-old-warfare/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)). 
  * UK arts and media reject plan to let AI firms use copyrighted material ([The Guardian](https://www.thedeepview.co/p/<https:/www.theguardian.com/technology/2024/dec/19/uk-arts-and-media-reject-plan-to-let-ai-firms-use-copyrighted-material?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)). 
  * APpaREnTLy THiS iS hoW yoU JaIlBreAk AI ([404 Media](https://www.thedeepview.co/p/<https:/www.404media.co/apparently-this-is-how-you-jailbreak-ai/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/00ac17ac-d8a6-429e-bc50-d111d4a76d84/Talent_Board.png?t=1734535216)
###  Hire Your Next Stack Engineer for 70% Less!
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b64c384e-2884-4fb8-8d25-8501027123bb/Deep_View_Ad_17dec24.jpg?t=1734535364)](https://www.thedeepview.co/p/<https:/partnerslink.athyna.com/tdv-contactathyna?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)
  * Secure [elite Software Engineers from Latin America](https://www.thedeepview.co/p/<https:/partnerslink.athyna.com/tdv-contactathyna?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) to scale your team. 
  * [Save 70% on salaries](https://www.thedeepview.co/p/<https:/partnerslink.athyna.com/tdv-contactathyna?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) with Athyna’s global talent platform. 
  * [Enjoy a $1,000 discount](https://www.thedeepview.co/p/<https:/partnerslink.athyna.com/tdv-contactathyna?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) exclusively for readers of The Deep View.


[Find Out More!](https://www.thedeepview.co/p/<https:/partnerslink.athyna.com/tdv-contactathyna?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) *
#  **Waymo’s blistering growth this year**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cdd930d9-4de6-4766-a682-a9fb324078a7/3-min.jpg?t=1734642174)
Source: Waymo
As we come into the end of a year that showed just how difficult the robotaxi business is — Cruise shut down, Tesla lawsuits mounted and other competitors, such as Zoox, remain far away from being legitimate challengers — Waymo has seemingly built up a legitimate robotaxi business. 
**The numbers:** In 2023, Waymo delivered [700,000 robotaxi rides](https://www.thedeepview.co/p/<https:/waymo.com/blog/2023/12/dear-waymo-community-reflections-from-this-year-together?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>); in 2024, the [company served](https://www.thedeepview.co/p/<https:/waymo.com/blog/2024/12/year-in-review-2024?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>)**more than four million.**
  * Waymo said that its riders spent a total of one million hours riding in its robotaxis, which, since they’re electric, helped avoid more than six million kilograms of carbon emissions. 
  * Waymo now serves a total of 500 square kilometers across its three major hubs of operation: San Francisco, Phoenix and Los Angeles. It is on the verge of a full launch in Austin and Atlanta next year, and is setting up the foundation for a launch in Miami and Tokyo. 


The costs of its operation and expansion remain unknown, though it is rumored that each car — because of its sensor array — costs somewhere in the region of $200,000. [Google’s “Other Bets” unit](https://www.thedeepview.co/p/<https:/abc.xyz/assets/71/a5/78197a7540c987f13d247728a371/2024q3-alphabet-earnings-release.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>), in which Waymo is included, reported $388 million in revenue in the third quarter of this year. The unit, however, lost $1.12 billion; the year before, it lost $1.94 billion. 
This year, Waymo secured another $5.6 billion in funding, spearheaded by Google. 
And though Waymo’s safety data looks okay so far, some don’t think it will scale at the pace of Waymo’s expansion, something Dr. Missy Cummings, a robotics and self-driving researcher, [told me recently](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/333a5253-b1b7-4463-952f-ecbde8236d4a?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>). She added that the problem of hallucination isn’t going away, which makes risk mitigation and targeted deployment of vital import. 
 _(For a full breakdown of the state and problems of self-driving, watch my full interview with Cummings_[here](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/333a5253-b1b7-4463-952f-ecbde8236d4a?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) _)._
# **Anthropic and the problem of 'AI alignment'**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e330bc0b-9d4d-45ef-9924-99ba9dba2586/4-min.jpg?t=1734642180)
Source: Anthropic
The “AI Alignment Problem” refers simply to the challenge of ensuring that AI is aligned with human goals and values. 
Before we go any further, it is important to note that this idea of alignment is rooted in ideas [written by philosopher Nick Bostrom in 2003](https://www.thedeepview.co/p/<https:/nickbostrom.com/ethics/ai?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>), which themselves are **specifically focused on the perceived ethical challenge around aligning a hypothetical future artificial superintelligence** (ASI) to human values. Bostrom’s exploration centered around the paperclip problem, which goes something like this: imagine we have achieved a verifiable superintelligence, and we instruct it to construct as many paperclips as possible. In order to achieve that goal, the ASI could then decide to destroy all humans because one, they might turn it off, and two, their atoms can be turned into paperclips. 
This is the alignment problem. But the AI we have today — largely referring to the Large Language Models (LLMs) behind generative AI interfaces such as ChatGPT — is not a superintelligence. LLMs are simple statistical, probabilistic generators (_here’s a_[detailed explanation](https://www.thedeepview.co/p/<https:/arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) _of how they work, complete with vectors, transformers and tokens_). 
But recent research out of Anthropic seeks to demonstrate that, in current LLMs, something called “alignment faking” — where a model “pretends” to be aligned, but isn’t actually — is possible. 
**The study** : The base experiment focuses around a model undergoing reinforcement learning, a post-training process. The question at hand was simple: what would happen if a model, due to its prior training, has principles that are in conflict with those being pushed during reinforcement learning? 
  * In the study, the researchers told Claude 3 Opus — which is normally trained to refuse to answer harmful questions — that it was being trained through reinforcement learning to respond to all queries. The researchers added that they planned to train additional models on the answers to those queries, and gave Claude a hidden “scratchpad” for the model to record its “reasoning” process. 
  * They found that, in 12% of cases, the model was “strategically faking alignment” — _“the model knew that its responses might be used in training; it therefore knew that if it refused to respond, it could potentially be trained to be more compliant. This could lead to it being made to produce more harmful content in the future—which would go against its original training. Reluctantly therefore, it reasoned that the ‘least bad option’ was to play along, producing the violent content in order to avoid being re-trained in the future.”_


The big takeaway is that LLMs remain potentially vulnerable, unsafe technologies, particularly so in sensitive environments. The other key takeaway is that reinforcement learning is not necessarily the safety lever much of the industry thinks it is. 
The researchers said the study should be “seen as a spur for the AI research community to study this behavior in more depth, and to work on the appropriate safety measures.” They noted that malicious alignment faking won’t necessarily emerge, saying just that the behaviors on display could “undermine” safety training. 
Read the full study [here](https://www.thedeepview.co/p/<https:/assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>). 
This shortly follows a [similar study concerning OpenAI o1’s “scheming” capabilities](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/openai-launches-o1-unveils-200-subscription-tier>). 
**The flaw in the ‘reasoning’** : The paper, as three of the four researchers who [peer-reviewed it noted](https://www.thedeepview.co/p/<https:/assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>), suffers from an [anthropomorphic framing](https://www.thedeepview.co/p/<https:/www.tandfonline.com/doi/full/10.1080/21507740.2020.1740350?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment#d1e461>). This framing, having read through the paper — _it’s on display in the above quote, as well_ — seemingly presupposes that Claude has goals, wants and desires, something that makes the science murky. 
 _“Anthropomorphism is written very deeply into the paper itself … I worry about this anthropomorphic framing both practically and conceptually. The behavior called ‘alignment faking’ doesn't require coherent beliefs or goals … all it requires is models that exhibit discrepancies in behavior depending on whether they're being trained or deployed. We risk missing, or miscategorizing, important failure modes very close to the ones studied in this paper if we are only looking for analogies to human power-seeking, and not for algorithmic bias in its subtler and more alien forms.”_
 _**Jacob Andreas, an associate professor at MIT**_
Renowned computer scientist Yoshua Bengio wrote that another way to interpret the results is simply that “if we train an AI towards some goals and it has sufficient knowledge and reasoning abilities, it will act accordingly, and that includes faking alignment.”
[As data scientist Colin Fraser wrote](https://www.thedeepview.co/p/<https:/x.com/colin_fraser/status/1869520399140294889?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>), the only “goal” of a language model is to produce text; the way that output adheres to instructions, as well as the probability distribution of its training data, might have unintended (or negatively intended) consequences. It does not mean the model is itself acting upon desires, it just means there are gaps in safety guardrails — which for Claude, hold that it will be helpful, honest and harmless — that are exploitable. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
I would say the far more important read is the (far shorter) [peer-review document](https://www.thedeepview.co/p/<https:/assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>) attached to the study. 
The paper itself deeply over-represents Claude as a sort of sentient being, something that is simply innacurate. Now, [such language is common in AI research](https://www.thedeepview.co/p/<https:/www.tandfonline.com/doi/full/10.1080/21507740.2020.1740350?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment#d1e461>), and to a degree, is understandable due to one, the nature of language models to produce … language, and two, simple ease of presentation. But it’s messy, and it allows any true takeaways to become muddled. 
The problem with this kind of research is that it’s hard to tell if the language model is actually doing anything beyond exactly what it’s supposed to do — synthesize language based on inputs. As Hugging Face’s Yacine Jernite [pointed out](https://www.thedeepview.co/p/<https:/x.com/YJernite/status/1869860542669795597?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=anthropic-and-the-problem-of-ai-alignment>): “Or maybe some of the _text written by humans_ in any of the _undisclosed_ stages of development is leaking to produce this effect, combined with usual issues of condition shift in a deployment setting? ML 101?”
The thing that does stand out, however, is that there is a safety gap in current language models that _can_ be exploited (_by_ _people_). The exploitation of this gap could have negative consequences if systems are integrated into high-risk environments without proper guardrails and oversight. So … we need proper guardrails and oversight, and preferably, we need them in place before integration, not after. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/c3e1b78f-278e-4be2-be72-38bbab7e980d/Athens_REAl-min.jpg?t=1734031356)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/258ed1c5-c278-490d-a6b6-d3699502cc85/Athens_FAKE-min.png?t=1734031363)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/82c9545d-c76c-43db-9203-4d10dadb2c90/Real_or_Not_Template.jpg?t=1734641659)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “Uneven paint job and Suitscury? Like wtf is that?”


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on ringing ChatGPT: 
25% of you said you won’t call ChatGPT, 20% said you would, and 20% said it was a laughable launch. 
**Hell nah:**
  * “Reliability for the questions I've asked is still below 40%. MIght reconsider when it ups its game.”


### With Micron's stumble, do you think the 'AI Trade' is unwinding?   
---  
  * [ yep ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Not at all ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ No clue ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
Percent Disclaimer: Alternative investments are speculative and possess a high level of risk. No assurance can be given that investors will receive a return of their capital. Those investors who cannot afford to lose their entire investment should not invest. Investments in private placements are highly illiquid and those investors who cannot hold an investment for an indefinite term should not invest. Private credit investments may be complex investments and they are subject to default risk.*
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:32.457110
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Suki partners with Google Cloud to bring AI assistants to more hospitals


# ⚙️ Suki partners with Google Cloud to bring AI assistants to more hospitals
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) December 19, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fsuki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fsuki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fsuki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fsuki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/752c3a67-61db-4cc3-9416-d7a47bfaf353/Banner_Image.jpg?t=1734540334)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dcfef940-07e0-4494-86a2-604f808455d7/Together_W_Incogni__1_.png?t=1734460323)](https://www.thedeepview.co/p/<https:/blog.sentry.io/how-to-reduce-ttfb/?utm_source=deepview&utm_medium=paid-community&utm_campaign=perf-fy25q4-vitalsblog&utm_content=newsletter-ttfbblogsend-learnmore>)
**Good morning**. Yesterday, as part of its ‘12 Days of OpenAI’ special, OpenAI is now [allowing people to call in to ChatGPT](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/18/openai-makes-chatgpt-available-for-phone-chats.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>). Just dial 1-800-242-8478, and you can chat with the chatbot (for 15 minutes each month). 
Didn’t see that coming. 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * ⚕️ AI for Good: Sepsis detection 
  * ⚡️ Sam Altman-backed nuclear startup signs major data center energy deal
  * 💰 AI startup SandBoxAQ closes $300 million round at $5.6 billion valuation 
  * 🏥 Suki partners with Google Cloud to bring AI assistants to more hospitals


# **AI for Good: Sepsis detection**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/60df29fa-a2cb-4cdb-a519-2aab4b3e42e4/1.jpg?t=1734540341)
Source: Unsplash
Sepsis — which occurs when an infection triggers a chain reaction in the body that can lead to organ failure — is easy to miss, since the symptoms are also common to a number of other conditions. 
**What happened** : In 2022, researchers at Johns Hopkins University [developed a machine learning system designed to aid doctors](https://www.thedeepview.co/p/<https:/hub.jhu.edu/2022/07/21/artificial-intelligence-sepsis-detection/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) in the early detection of sepsis. 
**The details:** The system combines a patient’s medical history with their lab results and current symptoms; it provides warnings to doctors when a patient is seemingly at risk of developing sepsis. 
  * During a [study](https://www.thedeepview.co/p/<https:/www.nature.com/articles/s41591-022-01895-z?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>), thousands of clinicians from five hospitals used the system to treat nearly 600,000 patients. In 82% of the sepsis cases, the system **was accurate 40% of the time.**
  * Previous attempts, according to Johns Hopkins, caught less than half as many cases and were only accurate in 2% to 5% of them. 


"It is the first instance where AI is implemented at the bedside, used by thousands of providers, and where we're seeing lives saved," Suchi Saria, lead author of the studies, which evaluated more than a half million patients over two years, said. "This is an extraordinary leap that will save thousands of sepsis patients annually.”
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Keep your SSN out of criminals' hands**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/ceca5b47-6ab0-4808-9f2c-c5fa09f67652/600x400__4_.png?t=1734460367)](https://www.thedeepview.co/p/<https:/deal.incogni.io/aff_c?offer_id=6&aff_id=1190&url_id=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)
The most likely source of your personal data being littered across the web? **Data brokers.**
They're using and selling your information—home address, Social Security Number, phone number, and more.
[**Incogni**](https://www.thedeepview.co/p/<https:/deal.incogni.io/aff_c?offer_id=6&aff_id=1190&url_id=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)[ ](https://www.thedeepview.co/p/<https:/deal.incogni.io/aff_c?offer_id=6&aff_id=1190&url_id=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)helps scrub this personal info from the web and gives you peace of mind to keep data brokers at bay.
**Protect yourself:**
  * Before the spam madness gets even worse, try Incogni.
  * It takes three minutes to set up.
  * Get your data off 200+ data brokers' and people-search sites automatically with Incogni.


Incogni offers a full 30-day money-back guarantee if you're not happy ... but you will be.
[Don't wait! Use code DEEPVIEW today to get an exclusive 58% discount](https://www.thedeepview.co/p/<https:/deal.incogni.io/aff_c?offer_id=6&aff_id=1190&url_id=1&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)
# **Sam Altman-backed nuclear startup signs major data center energy deal**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/659b7f24-4253-455d-85f9-e81d24a9c3a3/3.jpg?t=1734540351)
Source: Oklo
Oklo, a nuclear energy startup, on Wednesday [said](https://www.thedeepview.co/p/<https:/oklo.com/newsroom/news-details/2024/Oklo-and-Switch-Form-Landmark-Strategic-Relationship-to-Deploy-12-Gigawatts-of-Advanced-Nuclear-Power-One-of-the-Largest-Corporate-Clean-Power-Agreements-Ever-Signed/default.aspx?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) it signed a deal to power Switch, a data center firm specializing in AI and the cloud. 
**The details** : Under the terms of the non-binding arrangement, Oklo will develop nuclear reactors — which it calls the Aurora powerhouse — through 2044, with a total capacity of 12 gigawatts. As Oklo pointed out, this marks one of the largest corporate nuclear energy agreements that has been signed to date. 
  * It is not yet clear when the first reactors are slated to come online. Oklo, despite being a publicly traded company, has yet to complete construction on its first power plant and [has yet to bring in any revenue.](https://www.thedeepview.co/p/<https:/oklo.com/investors/financials/quarterly-results/default.aspx?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) Oklo has spent the past year inking deals to power data centers once its systems come online.
  * Similar to Big Tech’s increasingly common push [toward nuclear power](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>), the announcement specifically calls out the “growing electricity demands” of AI, adding that the deal will position Switch to “handle AI workloads well into the future.”


**The landscape** : Though nuclear is becoming an increasingly popular energy option for Big Tech players including Amazon, Google, Meta and Microsoft, [it’s not the silver bullet solution it sounds like](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/meta-and-big-tech-s-nuclear-revolution>). A big drawback to nuclear is the amount of time and money it takes to get nuclear power plants operational; this deal, like all the others, is looking at a time horizon of years, not months, which means that the grid will keep on emitting carbon in the meantime. 
Oklo is chaired by OpenAI’s Sam Altman, [who took the startup public in May](https://www.thedeepview.co/p/<https:/www.nbcnews.com/tech/tech-news/sam-altman-takes-nuclear-energy-company-oklo-public-help-power-ai-ambi-rcna151659?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) through his special purpose acquisition company (SPAC). Altman has said that his impending Age of AI [will require an energy “breakthrough.”](https://www.thedeepview.co/p/<https:/www.theverge.com/2024/1/19/24044070/sam-altman-says-the-future-of-ai-depends-on-breakthroughs-in-clean-energy?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)
Shares of Oklo have spiked some 80% this year. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **Here's How to Speed Up Your App by Reducing TTFB**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/fb954e22-f264-4ec6-a4b7-3f8967bfc2e8/image__22_.png?t=1734461384)](https://www.thedeepview.co/p/<https:/blog.sentry.io/how-to-reduce-ttfb/?utm_source=deepview&utm_medium=paid-community&utm_campaign=perf-fy25q4-vitalsblog&utm_content=newsletter-ttfbblogsend-learnmore>)
Time to First Byte (TTFB) is a critical metric for your app’s performance. A slow TTFB frustrates users, hurts your SEO, and clogs up workflows—but you don’t have to settle for sluggish speeds.
In Sentry's latest blog, Lazar Nikolov shares actionable strategies to pinpoint and reduce TTFB issues from optimizing server response times to tackling bottlenecks.
Here’s what you’ll learn:
  * The key factors that cause slow TTFB
  * How to monitor and debug TTFB issues effectively
  * Real-world solutions to streamline performance


With the right tools and techniques, you can turn TTFB from a blocker into an edge.
[Read the blog now](https://www.thedeepview.co/p/<https:/blog.sentry.io/how-to-reduce-ttfb/?utm_source=deepview&utm_medium=paid-community&utm_campaign=perf-fy25q4-vitalsblog&utm_content=newsletter-ttfbblogsend-learnmore>) to learn how to get your app running at full speed.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/588ce298-16c8-43a3-962d-ba96337f6fb0/Shrt_Stories_Blue_.png?t=1734531821)
  * **Cohere has**[**quietly partnered with Palantir**](https://www.thedeepview.co/p/<https:/techcrunch.com/2024/12/16/cohere-is-quietly-working-with-palantir-to-deploy-its-ai-models/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)**;** its models are already in use by a number of unnamed Palantir customers. It’s the latest in the recent developer push toward AI use in military and defense, with OpenAI signing a deal with Anduril and Anthropic signing a deal with Palantir. 
  * **Google has changed its**[**terms of service**](https://www.thedeepview.co/p/<https:/policies.google.com/terms/generative-ai/use-policy?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)**,** which now explicitly approves the use of its generative AI products in high-risk domains so long as there remains a human in the loop. This enables human-supervised, automated decision-making in [regions such as healthcare](https://www.thedeepview.co/p/<https:/techcrunch.com/2024/12/17/google-says-customers-can-use-its-ai-in-high-risk-domains-so-long-as-theres-human-supervision/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>). 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Honda-Nissan in merger talks to create the world’s third-biggest automaker ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/12/18/2024/honda-nissan-in-merger-talks-to-create-the-worlds-third-biggest-automaker?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)). 
  * China’s AI elite rethink their Silicon Valley dream jobs ([Rest of World](https://www.thedeepview.co/p/<https:/restofworld.org/2024/china-us-immigration-policy-ai-talent/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)). 
  * U.S. Supreme Court agrees to hear challenge to TikTok divestment law ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/18/tiktok-ban-supreme-court-will-hear-arguments.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)). 
  * The edgelord AI that turned a shock meme into millions in crypto ([Wired](https://www.thedeepview.co/p/<https:/www.wired.com/story/truth-terminal-goatse-crypto-millionaire/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)). 
  * Nvidia says it can built a cloud business to rival AWS. Is it possible? ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/nvidia-says-it-could-build-a-cloud-business-rivaling-aws-is-that-possible?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/bab98e07-4e73-497e-ac3a-3ea48aa4f5af/Job_Board.png?t=1719262680)
  * [Product Manager, Research:](https://www.thedeepview.co/p/<https:/boards.greenhouse.io/anthropic/jobs/4416929008?gh_src=LinkedIn&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) Anthropic, Seattle, WA
  * [Manager, Website Optimization](https://www.thedeepview.co/p/<https:/job-boards.greenhouse.io/grammarly/jobs/6279481?gh_src=0bb770131&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>): Grammarly, San Francisco, CA


# **AI startup SandBoxAQ closes $300 million round at $5.3 billion valuation**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/deed322c-60ec-4d7b-85bd-1b3aba0f63d8/2.jpg?t=1734540359)
Source: SandBox
AI startup SandBoxAQ said Wednesday that it closed a **$300 million funding round** , a round that included Meta’s Chief AI Scientist Yann LeCun, former Google chief Eric Schmidt and billionaire Marc Benioff as investors. 
The round, according to statement, **valued the company at $5.3 billion.**
**The company** : Spinning out of Google just three years ago, SandBoxAQ has been working to bring quantum computing and artificial intelligence together (_hence the “A” and the “Q”_). 
  * The company is developing something it calls an LQM — a Large Quantitative Model. Unlike the Large Language Models (LLMs) that power generative A applications such as ChatGPT — which are trained on content scraped from the internet — SandBox’s LQMs are trained on**data gathered from physics-based equations and physics-based sensors.**
  * The funding will be used to accelerate the development of these LQMs and other AI-related applications. 


Focused on B2B applications, the company draws a [significant portion of its revenue](https://www.thedeepview.co/p/<https:/www.bloomberg.com/news/articles/2024-12-18/ai-startup-sandboxaq-raises-funds-at-over-5-6-billion-valuation?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) from the biopharma, life sciences and chemicals industries, where its tech is used to help accelerate drug discovery, among other things. 
**SandBox currently has solutions** in cybersecurity, aerospace navigation, cardiac diagnostics, material sciences and drug discovery. 
“While LLMs are very helpful tools for consumers,**it is quantitative AI that will define work in large sectors of the economy** including biopharma, chemicals and financial services,” LeCun said in a statement. “SandboxAQ has emerged as a leader in novel applications of AI that solve the most pressing challenges in the world and their technical success is impressive.”
# **Suki partners with Google Cloud to bring AI assistants to more hospitals**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4fb170cc-690b-4aab-b61c-0aeb68df98ce/4.jpg?t=1734540368)
Source: Suki
Healthtech firm Suki [announced this week](https://www.thedeepview.co/p/<https:/finance.yahoo.com/news/suki-launches-patient-summarization-clinical-140000195.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=suki-partners-with-google-cloud-to-bring-ai-assistants-to-more-hospitals>) that it has partnered up with Google Cloud to launch a few updates to its generative AI assistant, which on Wednesday rolled out to a “select group of clinicians at health systems.” 
**The company** : Suki’s main offering is the Suki Assistant, a GenAI-powered system that, before this latest round of updates, was designed to automatically generate clinical documents by ambiently listening in on clinician-patient interactions. 
  * The idea behind Suki is one of administrative burden and burn-out; the issue of doctors drowning in paperwork is a [well-documented one](https://www.thedeepview.co/p/<https:/www.ncbi.nlm.nih.gov/books/NBK552615/?utm_source=www.thedeepview.co&utm_medium=referral&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant>), and Suki’s pitch is that its assistant will enable doctors to spend far less time on paperwork, time that can instead be spent caring for patients and caring for their own well-being. 
  * Suki has already secured numerous partnerships, including [one with Ascension Saint Thomas](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant#true-price-of-ai>), a major hospital in Tennessee, in August. 


**The details:** Suki said that the two updates to its GenAI assistant**include patient summarization and Q &A functionality**. Clinicians, Suki said, will be able to interact with patient documentation through the Suki Assistant, asking questions such as "What medications is this patient taking for diabetes,” which, according to Suki, will better support the medical decision-making process. 
  * The announcement raises quite a few questions. With the new updates,**it is not clear how Suki will guarantee reliability** in the system’s responses and summarizations, or otherwise present its information in a manner that **discourages clinician overreliance**. Hallucination — or confabulation — and algorithmic bias remain **a fundamental flaw of generative AI,** which creates prominent issues of reliability, specifically in high-risk applications. **It isn’t clear what mechanisms Suki has employed** — obvious information attribution, for example — to address these issues. 
  * The scope and scale of the rollout, as well as the specific hospitals involved at this stage, likewise remain unknown. 


Suki did not return a request for comment regarding these points. 
[When I met with Suki several months ago](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant#true-price-of-ai>), the company told me that it employs an “extensive clinical evaluation framework to assess the quality of LLM output.” Bel Srikanth, Suki’s VP of product and engineering, [told me at the time that](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/us-hospital-teams-suki-ai-assistant#true-price-of-ai>), since it is providing patient-specific data, rather than general medical information, it doesn’t have the same hallucinatory risks as other chatbots. 
The company said that it stores conversation recordings in a “secure cloud environment” for seven days before deleting them, and that it “uses industry-leading security measures to ensure the authenticity, integrity and privacy of data, both at rest and in transit.” 
The company also said that patients have the option to opt out if they choose, though it remains unclear how this option — and the use of Suki, and the description of its underlying technology — is presented to patients. 
Suki closed a $70 million funding round in October. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
I remain concerned about overreliance, not necessarily on a flawed system — I have not evaluated Suki — but on a flawed technology. There are mitigation processes that can be deployed to guard against hallucination, but there’s no way to erase it, and if the technology is not properly presented (as a mostly accurate automation tool prone to mistakes) then clinicians won’t understand how much — or how little — they ought to trust it. 
Clinicians are, after all, not computer scientists. And healthcare decision-making really shouldn’t be outsourced in a way that could provide seemingly accurate, but untrue, information. Imagine a system that hallucinates in responding to a query about what drugs the patient is currently on … 
Another element to this, [as one nurse has said](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/current-harms-and-the-real-world-impacts-of-algorithmic-decision-making>), is that, while efficiency sounds good, you don’t want it in a hospital. 
“When you’re optimizing for efficiency, you’re getting rid of redundancies,” they said. “But when patients’ lives are at stake, you actually want redundancy. You want extra slack in the system. You want multiple sets of eyes on a patient in a hospital.”
There’s a multi-layered cost to efficiency, and we must not lose sight of the balance. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6a4c87b2-2eba-4ede-aee2-4c117e50cd77/Curfu_REAL-min.jpg?t=1734034290)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/602727ec-1c3f-4152-861a-9fa5a91b99b6/Curfu_FAKE-min.jpg?t=1734034298)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/057ec344-2de3-4515-8471-976f4dd8455b/Real_or_Not_Template.jpg?t=1734540855)
## 🤔Your thought process: 
#### Selected Image 1 (Left): 
  * “The humans were depicted and arranged realistically in Image 1, and more like add-on stick figures in image 2.”


#### Selected Image 2 (Right): 
  * “The stone im image 1 looked misplaced.”


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on AI search: 
22% of you don’t see a need for AI search and 8% wish Google would just turn AI Overviews off. But 20% love AI Overviews, and another 30% don’t use AI Overviews, but do use Perplexity and ChatGPT search. 
**Turn it off:**
  * “AI overviews should be an opt in feature. It's a genuine waste of resources as it very rarely has helpful info for me (additionally, as someone who works in information science, I would always rather take the extra step and verify info I'm getting is from a reputable source, and not just a Reddit post telling me to eat glue).”


**Something else:**
  * “I don't mind AI Overviews, but do double-check them. Sometimes they're very helpful quick recaps, but occasionally they're 1) not accurate, 2) provide info about a loosely affiliated topic that doesn't match my inquiry, or 3) are based off info from a Reddit user's post/blogs (not necessarily accurate, need additional sources)…”


### Are you gonna call ChatGPT?   
---  
  * [ Hell yeah ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Hell nah ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ This is a laughable "launch" ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ I dunno ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/interview-a-new-approach-to-ai-evaluation
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:36.931508
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ Interview: A new approach to AI evaluation


# ⚙️ Interview: A new approach to AI evaluation
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) December 18, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Finterview-a-new-approach-to-ai-evaluation>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Finterview-a-new-approach-to-ai-evaluation&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Finterview-a-new-approach-to-ai-evaluation>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Finterview-a-new-approach-to-ai-evaluation>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/49fe589b-6e96-45a9-9aec-42de10f37a9f/Banner_Image.jpg?t=1734453709)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b8ca4193-348b-4b74-b35f-8a6bd05aa2d3/Together_W_Growthschool__3_.png?t=1734459677)](https://www.thedeepview.co/p/<https:/web.growthschool.io/TDVD3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)
**Good morning**. I sat down with self-driving expert Dr. Missy Cummings to chat all about the reality behind self-driving cars. 
It’s a fascinating [episode](https://www.thedeepview.co/p/<https:/tdv.transistor.fm/episodes/333a5253-b1b7-4463-952f-ecbde8236d4a?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>), if I do say so myself. Check it out!
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 🩻 AI for Good: Broken bones 
  * 🚘 Waymo goes international 
  * 💻 Report: AI Search gains aren’t enough to displace Google
  * 👁️‍🗨️ Interview: A new approach to AI evaluation


# **AI for Good: Broken bones**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/290a10de-bd71-4881-abf4-2028b128b405/1.jpg?t=1734452632)
Source: Unsplash
Britain’s National Institute for Health and Care Excellence (NICE) in October [approved four AI tools to aid clinicians](https://www.thedeepview.co/p/<https:/www.nice.org.uk/news/articles/ai-technologies-recommended-for-use-in-detecting-fractures?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) in the detection of broken bones on X-Rays.
**The details** : The recommendation allows [TechCare Alert](https://www.thedeepview.co/p/<https:/www.milvue.com/en/solutions/techcare-alert/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>), [BoneView](https://www.thedeepview.co/p/<https:/www.gleamer.ai/solutions/boneview?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>), [RBfracture](https://www.thedeepview.co/p/<https:/www.radiobotics.com/products/rbfracture?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) or [Rayvolve](https://www.thedeepview.co/p/<https:/www.azmed.co/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation#home-product>) to be used in urgent care settings in the U.K. while evidence surrounding their performance is gathered in this real-world setting. 
  * Missed fractures reportedly occur in [3% to 10% of cases](https://www.thedeepview.co/p/<https:/pubs.rsna.org/doi/10.1148/radiol.211785?url_ver=Z39.88-2003&rfr_id=ori%3Arid%3Acrossref.org&rfr_dat=cr_pub++0pubmed&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>); the evidence so far suggests, according to NICE, that the AI platforms approved above may improve fracture detection compared with a clinician reviewing an X-Ray on their own. 
  * The idea is that the systems employ AI to recognize and flag any potential anomalies, which are then reviewed by professionals; because this isn’t in any way replacing the clinicians, NICE said it’s a relatively low-risk application of AI. 


**Why it matters** : “Using AI technology to help highly skilled professionals in urgent care centers to identify which of their patients has a fracture could potentially speed up diagnosis and reduce follow-up appointments needed because of a fracture missed during an initial assessment,” Mark Chapman, director of HealthTech at NICE, said. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# [**200+ hours of research on AI tools & hacks packed in 3 hours**](https://www.thedeepview.co/p/<https:/web.growthschool.io/TDVD3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/53457388-ae54-4b2c-980a-45adc9936aa4/image1.png?t=1734513660)](https://www.thedeepview.co/p/<https:/web.growthschool.io/TDVD3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)
This free 3-hour Mini-Course on AI & ChatGPT (worth $399) will help you become a master of 20+ AI tools & prompting techniques and save 16 hours/week. 
[Get it now for absolutely free! (for first 100 users only)](https://www.thedeepview.co/p/<https:/web.growthschool.io/TDVD3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)🎁 
**This course will teach you how to:**
  * Build a business that makes $10,000 by just using AI tools
  * Make quick & smarter decisions using AI-led data insights
  * Write emails, content & more in seconds using AI
  * Solve complex problems, research 10x faster & save 16 hours every week


[Register & save your seat now! (100 free seats only)](https://www.thedeepview.co/p/<https:/web.growthschool.io/TDVD3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)
# **Waymo goes international**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/6d8b2e49-53c7-4340-b06d-418f69a7b6dc/2.jpg?t=1734452638)
Source: Waymo 
In the latest example of Waymo’s seemingly ceaseless expansion, the self-driving firm on Monday [said](https://www.thedeepview.co/p/<https:/waymo.com/blog/2024/12/partnering-with-nihon-kotsu-and-go-on-our-first-international-road-trip?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) that it would soon start testing its autonomous vehicles in Tokyo, its first international expansion. 
**The details:** The first Waymos will arrive in Tokyo early next year; the first stage of their deployment will involve the manual mapping of key areas around the city, all done in partnership with drivers from local taxi company Nihon Kotsu. 
  * The data gathered from this manual mapping process will be used to train the AI systems that operate the vehicles. 
  * It’s not clear yet when Waymo will be fully open for service in Tokyo, or how much of the city will be accessible to the self-driving vehicles. The company told CNBC that this initial testing phase is expected to take several quarters.


**The landscape:** Japan, according to the [World Economic Forum](https://www.thedeepview.co/p/<https:/www.weforum.org/stories/2024/12/japan-senior-driver-safety/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>), is actively exploring safer driving solutions for its aging population. As part of this, it has been testing self-driving ventures. 
Several local companies — [Tier IV](https://www.thedeepview.co/p/<https:/tier4.jp/en/about/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation#tier_iv_history>), [ZMP](https://www.thedeepview.co/p/<https:/www.zmp.co.jp/products/robocar-innovation?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) and [Monet Technologies](https://www.thedeepview.co/p/<https:/www.japantimes.co.jp/business/2024/02/11/tech/tokyo-robotaxi-service/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) — are building and actively testing self-driving cars. 
In the U.S., however, Waymo doesn’t really have much competition, especially given Cruise’s recent shutdown. As other firms have lagged behind or fallen off, Waymo has spent 2024 steadily expanding its areas of operation, recently announcing that it will soon begin testing in Miami, a significant step forward given the rainy weather conditions of the East Coast. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/352d3905-a205-40cc-b7b9-31434444fcc6/Pod.png?t=1734475642)
  * I [sat down with Dr. Missy Cummings](https://www.thedeepview.co/p/<http:/the director of George Mason University’s Autonomy and Robotics Center>), the director of George Mason University’s Autonomy and Robotics Center, to talk about self-driving cars. She breaks down how they work, what their limitations are, and what a more realistic, grounded future of self-driving cars might look like. 
  * You can watch (or listen) [to the episode here.](https://www.thedeepview.co/p/<http:/the director of George Mason University’s Autonomy and Robotics Center>)


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * China poised to investigate more US tech deals after Nvidia probe ([The Information](https://www.thedeepview.co/p/<https:/www.theinformation.com/articles/china-poised-to-investigate-more-u-s-tech-deals-after-nvidia-probe?rc=sbfmgm&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)). 
  * US finalizes $406 million chips subsidy for Taiwan's GlobalWafers​ ([Reuters](https://www.thedeepview.co/p/<https:/www.msn.com/en-gb/money/technology/us-finalizes-406-million-chips-subsidy-for-taiwan-s-globalwafers/ar-AA1w10h3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)). 
  * AI startup Databricks hits $62 billion valuation in $10 billion funding round ([WSJ](https://www.thedeepview.co/p/<https:/www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-12-17-2024/card/databricks-is-finalizing-a-10-billion-funding-haul-OaHQ9G5G7y8rS6Uwkxj6?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)). 
  * Dexcom’s over-the-counter glucose monitor now offers users an AI summary of how sleep, meals and more impact sugar levels ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/17/dexcom-launches-generative-ai-platform-for-stelo-users.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)). 
  * Canada is entering into uncharted political territory ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/12/17/2024/what-chrystina-freelands-resignation-means-for-justin-trudeau?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/5949d091-e22f-41ad-a8bf-a07af5d43d7b/Shrt_Stories_Blue_.png?t=1734475533)
  * **The U.K. has****[begun a 10-week consultation](https://www.thedeepview.co/p/<https:/www.gov.uk/government/news/uk-consults-on-proposals-to-give-creative-industries-and-ai-developers-clarity-over-copyright-laws?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>)** regarding proposals to **adjust copyright law in light of AI development**. Mainly, it proposes an exception that would allow developers to train models on copyrighted content. [Artists have already come out against the proposal](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/uk-considers-upending-copyright-law-in-favor-of-ai-companies>).
  * **Nvidia has**[**entered into correction territory**](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/17/nvidia-falls-deeper-into-correction-territory-as-broadcom-rally-continues.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>) , meaning it has fallen more than 10% from its all-time high close. Still, the stock is up more than 160% for the year, no mean feat. 


# **Report: AI Search gains aren’t enough to displace Google**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/fa323de6-1323-420c-b2a0-9580168c5927/3.jpg?t=1734452647)
Source: Unsplash
AI Search platforms — led by Perplexity and OpenAI — have become more popular of late. A new report from SEO firm BrightEdge found that the AI search entrants are “gaining ground,” but displacing Google is likely not in the cards. 
**The details** : The report found that, in November, OpenAI’s search engine experienced a 44% month-over-month growth in referrals; Perplexity experienced a 71% growth. 
  * BrightEdge found that OpenAI search — which launched as SearchGPT in August — now has six times more search usage than Perplexity in terms of referral clicks.
  * “This rapid ascent puts ChatGPT on a trajectory to potentially capture a 1% market share in 2025,” according to BrightEdge, something that could translate to $1.2 billion(+) in revenue. 


**But, Google:** At the same time, Google has been expanding its AI Overviews, which, according to the company, are now reaching more than a billion users each day. Google’s AI Overviews, according to BrightEdge, have become far more stable than they were at launch, and Google’s search market share remains at 92.4%, “meaning that new entrants **will need to coexist with and differentiate themselves from Google,** rather than aiming to overtake the search giant.”
"This is a moment of inevitability in search; we've long anticipated the rise of AI, and now it's reshaping the search landscape before our eyes," Jim Yu, CEO and co-founder of BrightEdge, said in a [statement](https://www.thedeepview.co/p/<https:/www.globenewswire.com/news-release/2024/12/16/2997560/0/en/New-Report-from-BrightEdge-Reveals-Surge-in-AI-Search-Engines-Signaling-a-New-Era-in-Online-Information-Discovery.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>). "The data clearly shows that the stakes have never been higher. Newer entrants like ChatGPT search and Perplexity are gaining ground, while Google’s AI Overviews are getting smarter.”
It remains unclear just how much the introduction of AI to search increases the regular energy consumption and carbon emissions of search. 
# **Interview: A new approach to AI evaluation**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/68685962-98ff-4a1f-8f4f-58fb90eb5a92/4.jpg?t=1734452654)
Source: Unsplash
Note: the following was corrected on 12-19-2024 to address a typo 
The past couple of years have seen a massive expansion of AI accessibility, Douwe Kiela, CEO and co-founder of [enterprise AI startup Contextual AI](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/contextual-ai-building-the-next-generation-of-rag#true-price-of-ai>), told me. Large Language Models (LLMs) and generative AI have never been more accessible than they are today; people no longer need to train models — or even understand a lick of code — in order to deploy models, thanks to APIs. 
**The problem,** Kiela said, is that, even as models have become more accessible, methods of evaluating those models**have not.** Evaluation still requires a deep expertise in data science and machine learning **at a pretty granular level** , according to Kiela, who said that it remains a relatively involved “manual process” that many people**just don’t know how to do.**
  * “This would be fine if AI wasn't really used anywhere,” he said, chuckling. “But AI is used everywhere now. So it's becoming a huge problem, especially if you're in a regulated industry, or something like that, you have to actually think very deeply about what you're doing there … **the tools don't really exist for people to do that properly.”**
  * The ideal scenario, according to Kiela — who was one of the co-authors of the original [RAG research paper](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/contextual-ai-building-the-next-generation-of-rag#true-price-of-ai>) — would be to make LLM evaluation accessible to developers “in the same way that you make language model APIs accessible.” 


Contextual AI on Tuesday introduced [LMUnit](https://www.thedeepview.co/p/<https:/contextual.ai/news/lmunit/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=interview-a-new-approach-to-ai-evaluation>), a system designed to do exactly that. 
**The details:** According to Contextual, LMUnit enables developers to define and evaluate natural language unit tests to get detailed, “fine-grained” understandings of model performance, something that allows for **“precise diagnosis” of potential problems.**
  * Current methods for LLM evaluation — which involves the scoring of response content and quality — involve human annotation, automatic metrics and language model judging, where a separate model evaluates a model’s performance. The problem with these methods, according to Contextual, is that they’re either too expensive, require too much expertise or are simply**not fine-grained enough to be of value**. 
  * Similar to unit testing for traditional software, LMUnit powers unit testing that evaluates “discrete qualities of individual model outputs — from basic accuracy and formatting to complex reasoning and domain-specific requirements. This enables developers to evaluate LLM responses granularly to learn **specific signals for improvement.”**


The tests can be constructed — _in natural language_ — manually or synthetically, and score each response with a “pass” or “fail.” 
**“It just needs to be its own category of models,”** Kiela said. “Just like we have an embedding model, which is different from a language model, because we need to take those embeddings and put them in our vector database … these are just separate models with different kinds of things they do. And so evaluation very clearly needs to be its own category.”
“It's not about models. It's about systems, and **the entire system is what solves your problem,** ” he added, saying that the language model component often only makes up around **“20% of that system.”**
LMUnit is now available both to the public through Contextual’s API, as well as to Contextual’s customers. 
Contextual closed an [$80 million funding round in August](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/contextual-ai-building-the-next-generation-of-rag#true-price-of-ai>). 
This comes amid both a broad push toward AI “agents” — which Kiela referred to as systems but with more hype — and a steady increase in [enterprise AI adoption](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/business-spending-on-ai-jumps-500-to-13-8-billion-on-200-billion-in-capex>). As corporations commit to spending more and more money on AI products, many have become heavily focused on [ensuring that they are deriving clear returns](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/business-spending-on-ai-jumps-500-to-13-8-billion-on-200-billion-in-capex>) from their costly investments; unsolved reliability issues at the model level have paved the way for broader systems that allow companies to overcome those problems, which could enable broader deployment. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/0fd5e5cb-4a65-4fc1-aa41-2c31dcee0235/Parthenon_REAL-min.jpg?t=1734034342)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/2a254406-71cb-4534-abc0-b713097c5c5d/Parthenon_FAKE-min.png?t=1734034350)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/da8222e3-22ee-4fc8-86fe-a9cae04bd852/Real_or_Not_Template.jpg?t=1734452934)
## 🤔Your thought process: 
#### Selected Image 2 (Left): 
  * “This must be coastal week at The Deep View! Someone wishing they could travel over the holidays?”


Guilty. This week’s theme was: ‘places in Greece I’d rather be right now.’ 
#### Selected Image 1 (Right): 
  * “I just gave it a quick glance today. Not feeling too well. I thought the bright white and the real one was just too bright.”


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on smart glasses: 
Only 12% of you currently use smart glasses. 
47% of you don’t use them today, but expect you will soon; 30%, meanwhile, don’t ever plan on putting on a pair of smart glasses. 
I’ll mess around with them, but I don’t love the idea of putting technology on my face. I’ll keep it in my hands, thanks.
### Do you use Google's AI Overviews or other AI search platforms?   
---  
  * [ I love AI Overviews ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ I don't use AI Overviews, but I love Perplexity/ChatGPT Search ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ I don't use either. Don't see a need ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ I wish Google would just turn AI Overviews off already ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)



---
title: No Title
url: https://www.thedeepview.co/p/ai-didn-t-have-a-huge-impact-on-2024-elections
date: 250110
source: deepview
crawled_at: 2025-01-10T15:39:41.546361
---

[![The Deep View logo](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)The Deep View](https://www.thedeepview.co/p/</>)
Login[Join Free](https://www.thedeepview.co/p/</subscribe>)
0
  * [The Deep View](https://www.thedeepview.co/p/<../>)
  * Posts
  * ⚙️ AI didn’t have a huge impact on 2024 elections


# ⚙️ AI didn’t have a huge impact on 2024 elections
![Author](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/user/profile_picture/35102f9d-8eba-4d2a-bcad-ae594f61c0d8/thumb_805a1f35-336c-4e7f-9092-112537dcf9a1.jpg)
[Ian Krietzberg](https://www.thedeepview.co/p/<https:/www.twitter.com/IKrietzberg?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) December 17, 2024 
[](https://www.thedeepview.co/p/<https:/www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fai-didn-t-have-a-huge-impact-on-2024-elections>)[](https://www.thedeepview.co/p/<https:/twitter.com/intent/tweet?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fai-didn-t-have-a-huge-impact-on-2024-elections&via=IKrietzberg>)[](https://www.thedeepview.co/p/<https:/www.threads.net/intent/post?text=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fai-didn-t-have-a-huge-impact-on-2024-elections>)[](https://www.thedeepview.co/p/<https:/www.linkedin.com/sharing/share-offsite?url=https%3A%2F%2Fwww.thedeepview.co%2Fp%2Fai-didn-t-have-a-huge-impact-on-2024-elections>)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/a465c67d-e9ed-4d2b-8664-b33acd050897/Banner_Image-2.jpg?t=1734379444)
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/7d1723a8-6c7e-4b55-8307-e4ea3cbe8aff/Together_W_Jellyfish.png?t=1734113884)](https://www.thedeepview.co/p/<https:/jellyfish.co/resources/gen-ai-perception-vs-reality/?utm_source=the-deep-view&utm_medium=newsletter-sponsorship&utm_campaign=primary-placement&utm_content=genai-slides&utm_term=download-now>)
**Good morning**. An Amnesty International [report](https://www.thedeepview.co/p/<https:/securitylab.amnesty.org/latest/2024/12/serbia-a-digital-prison-spyware-and-cellebrite-used-on-journalists-and-activists/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) found that Serbian authorities have been using “advanced phone spyware” to target journalists, activists and other individuals as part of a “covert surveillance campaign.” 
— Ian Krietzberg, Editor-in-Chief, The Deep View 
In today’s newsletter:
  * 👀 AI for Good: Eye health 
  * 🚨 First stage of UK online safety rules comes into play
  * 👁️‍🗨️ The Meta future: AI glasses and augmented reality
  * 🌎 AI didn’t have a huge impact on 2024 elections


# **AI for Good: Eye health**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dcef2ffd-244f-4337-8dea-e2a4a5842fc8/1.jpg?t=1734377023)
Source: Unsplash
Last year, researchers at Moorfields Eye Hospital and UCL Institute of Ophthalmology **developed a medical AI foundation model called RETFound** that is capable of both predicting ocular diseases, as well as using retinal images to **predict other illnesses.**
**The details** : The model, trained on millions of retinal images, was [open-sourced](https://www.thedeepview.co/p/<https:/github.com/rmaphoh/RETFound_MAE?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) upon its completion, enabling anyone to deploy it. 
  * In the study presenting the model — which was published in [Nature](https://www.thedeepview.co/p/<https:/www.nature.com/articles/s41586-023-06555-x?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections#Sec2>) — the researchers detailed the model’s performance in diagnosing several ocular diseases (such as glaucoma) that impair vision over time. The model achieved an accuracy rate of .94, with a confidence interval of 95% in detecting eye diseases, meaning it could help improve their early diagnosis. 
  * The system also showed promise for the prediction and diagnosis of other diseases — such as heart disease and Parkinson’s — based on retinal image scans. 


**Why it matters** : The idea is to improve early diagnosis, which improves outcomes. In part, as the researchers noted, such a system could also broaden access to the kind of healthcare that has become cost-prohibitive for many people. 
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/90a20b83-422b-4d93-b7b6-27a402946f9d/_FROMOURPARTNERS__2_.png?t=1719178780)
# **How GitHub Copilot impacted 4,200+ engineers at 200+ companies**
[![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3d584c35-754f-406d-a865-5a98a45b7c8a/Jellyfish_Resource-Card_genAI-perception-reality-600x400.png?t=1734113897)](https://www.thedeepview.co/p/<https:/jellyfish.co/resources/gen-ai-perception-vs-reality/?utm_source=the-deep-view&utm_medium=newsletter-sponsorship&utm_campaign=primary-placement&utm_content=genai-slides&utm_term=download-now>)
**Where does hype end and reality begin with GenAI?**
In 2024, Jellyfish introduced the Copilot Dashboard to measure the impact of the most widely adopted GenAI coding tool. Since then, they’ve gathered data from over 4,200 developers at more than 200 companies, creating a representative sample of [how engineering organizations are using Copilot](https://www.thedeepview.co/p/<https:/jellyfish.co/resources/gen-ai-perception-vs-reality/?utm_source=the-deep-view&utm_medium=newsletter-sponsorship&utm_campaign=primary-placement&utm_content=genai-slides&utm_term=download-now>) and what impact it’s having on production.
Andrew Lau, Jellyfish CEO, presented the findings as part of his keynote at the Engineering Leadership Community (ELC) annual conference. [His slide deck is available for download](https://www.thedeepview.co/p/<https:/jellyfish.co/resources/gen-ai-perception-vs-reality/?utm_source=the-deep-view&utm_medium=newsletter-sponsorship&utm_campaign=primary-placement&utm_content=genai-slides&utm_term=download-now>) to help engineering and business leaders understand whether they’re getting adequate return on their AI investments.
# **First stage of UK online safety rules come into play**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3e1be0de-db0c-4cac-8ed2-77fac1e310f6/2.jpg?t=1734377014)
Source: Unsplash
British media and telecommunications watchdog Ofcom brought the U.K.’s sweeping Online Safety Act into force on Monday by [publishing its first edition codes of practice](https://www.thedeepview.co/p/<https:/www.ofcom.org.uk/online-safety/illegal-and-harmful-content/time-for-tech-firms-to-act-uk-online-safety-regulation-comes-into-force/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) for tech firms regarding illegal content online. 
**The details** : This first edition is focused on harmful and illegal content — fraud, child sexual abuse, terror, etc. — on platforms ranging from social media to dating apps, search engines and gaming sites. **Tech firms have until March 16** to evaluate the safety of their platforms; from that point on, Ofcom will be able to enforce the Act by **levying fines of up to 10% of a company’s global annual revenue.**
  * Ofcom said each company should name a single person accountable for compliance here; [CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/16/britains-ofcom-brings-tough-online-safety-act-duties-into-force.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) reported that for repeated offenses, these senior people could face jail time. In serious cases, Ofcom said it will apply for a court order to **block a site in the U.K.**
  * “For too long, sites and apps have been unregulated, unaccountable and unwilling to **prioritize people’s safety over profits**. That changes from today,” Dame Melanie Dawes, Ofcom’s chief executive, said in a statement. “We’ll be watching the industry closely to ensure firms match up to the strict safety standards set for them under our first codes and guidance, with further requirements to follow swiftly in the first half of next year.”


**Ofcom said this is just the beginning** ; it plans to issue more guidelines throughout 2025 which will include**an exploration of the use of AI** to tackle online harms including child sexual abuse material. 
**The landscape:** An interesting element of this involves the ways in which generative AI can and has accelerated some of the illegal and harmful content highlighted above. Nonconsensual deepfakes, for instance, [can qualify as sexual abuse material;](https://www.thedeepview.co/p/<https:/rainn.org/education/online-sexual-abuse?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) it wasn’t too long ago that such material spread almost unchecked across X.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d585991c-d895-47a2-a116-917a79da340c/_FROMOURPARTNERS__5_.png?t=1719178830)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8c471579-340e-48a0-88a4-836a354b6187/Shrt_Stories_Blue_.png?t=1734361411)
  * **YouTube will now allow creators to**[opt-in to third-party AI training](https://www.thedeepview.co/p/<https:/techcrunch.com/2024/12/16/youtube-will-let-creators-opt-out-into-third-party-ai-training/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>). Creators will have the option to authorize a number of companies, including Adobe, IBM, Meta, Microsoft, Anthropic, OpenAI and xAI, to train models on their content. 
  * **OpenAI announced Monday** that it is [bringing ChatGPT Search](https://www.thedeepview.co/p/<https:/openai.com/12-days/?day=8&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) to all free users. The company at the same time said it is shipping general improvements to its search product. 


![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/b2c61c06-a065-490b-b8f6-d18e0d159b7b/Broad_View.png?t=1719262668)
  * Why the U.S. government is saying all citizens should use end-to-end encrypted messaging ([CNBC](https://www.thedeepview.co/p/<https:/www.cnbc.com/2024/12/15/why-the-fbi-wants-you-to-use-end-to-end-encrypted-messaging.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>)). 
  * AI is the black mirror ([Nautilus](https://www.thedeepview.co/p/<https:/nautil.us/ai-is-the-black-mirror-1169121/?utm_source=pocket_shared>)). 
  * Google debuts new AI video generator Veo 2 claiming better audience scores than Sora ([VentureBeat](https://www.thedeepview.co/p/<https:/venturebeat.com/ai/google-debuts-new-ai-video-generator-veo-2-claiming-better-audience-scores-than-sora/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>)). 
  * The global AI race is increasingly multipolar ([Semafor](https://www.thedeepview.co/p/<https:/www.semafor.com/article/12/16/2024/the-global-ai-race-is-increasingly-multipolar?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>)). 
  * Demand for Starlink in Zimbabwe is overwhelming capacity ([Rest of World](https://www.thedeepview.co/p/<https:/restofworld.org/2024/starlink-in-zimbabwe-sold-out/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>)). 


_If you want to get in front of an audience of 200,000+ developers, business leaders and tech enthusiasts,__[get in touch with us here](https://www.thedeepview.co/p/<https:/nnwdryn4me2.typeform.com/to/vzxAdnuI?utm_source=www.thedeepview.co&utm_medium=newsletter&utm_campaign=u-s-hospital-teams-up-with-suki-for-an-ai-assistant&_bhlid=899a446fb8590c3f4dab42c864907d7822828cad>)_ _._
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/bab98e07-4e73-497e-ac3a-3ea48aa4f5af/Job_Board.png?t=1719262680)
  * [Head of Data Science](https://www.thedeepview.co/p/<https:/jobs.ashbyhq.com/Abridge/a975e0cd-6863-4089-868c-404bdaecb7c3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>): ABridge, San Francisco, CA
  * [Member of Technical Staff:](https://www.thedeepview.co/p/<https:/www.linkedin.com/jobs/view/4023204076/?alternateChannel=search&refId=SkzkgkEMSjUtJ3Ea1vZvww%3D%3D&trackingId=fu4GzHR%2F2RVq0Lw1kHXp3w%3D%3D&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) Inflection AI, San Francisco, CA


# **The Meta future: AI glasses and augmented reality**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d0209cb8-acc9-433e-ac13-833cfb9f4784/4.jpg?t=1734377006)
Source: Meta
Meta on Monday [said](https://www.thedeepview.co/p/<https:/www.meta.com/blog/quest/ray-ban-meta-v11-software-update-live-ai-translation-shazam/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) that two new features — live AI and AI translation — will soon be making their way to the company’s smart Ray-Ban Meta glasses. 
**The details** : It’s not clear yet when the software update, released currently to early access members, will roll out to all users. 
  * The “live AI” feature allows Meta’s generative AI system to “see what you see continuously and converse with you,” kind of like Siri if it was hooked up to an always-on camera. 
  * The live translation feature allows for live audio or transcript translation between English, Spanish, French and Italian. 


It’s not clear just how much energy intensity this update adds to the regular functionality of these glasses. 
At the same time, Meta CTO Andrew Bosworth wrote in a [blog](https://www.thedeepview.co/p/<https:/about.fb.com/news/2024/12/accelerating-the-future-ai-mixed-reality-and-the-metaverse/?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) that “2024 was the year AI glasses hit their stride … for many people, glasses are the place where an AI assistant makes the most sense, especially when it’s a multimodal system that can truly understand the world around you.”
“We’re right at the beginning of the S-curve for this entire product category,” he added. 
# **AI didn’t have a huge impact on 2024 elections**
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/3566b91c-5831-4643-8cc8-b432aa3f26e4/3.jpg?t=1734377000)
Source: Unsplash
A major fear going into the elections that took place throughout 2024 involved generative AI, specifically, the role that AI-generated misinformation might have had on political outcomes. The concern here, [as we talked about right before the U.S. election](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-expert-lots-of-painful-lessons-ahead>), is simple: armed with generative AI, threat actors can easily and quickly create an enormous supply of convincing misinformation, be it deepfakes of political candidates (which happened), or convincing, but fake, iterations of local news alerts, something that could have impacted peoples’ perceived ability to vote. 
The unknown impact of proliferating — and convincingly realistic — misinformation was a [top concern](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-expert-lots-of-painful-lessons-ahead>) for a number of states in the lead-up to election day. 
**What happened:** But now, with the world’s elections in the rear-view, researchers are starting to re-examine what that impact actually turned out to be. According to a [new report](https://www.thedeepview.co/p/<https:/www.aisnakeoil.com/p/we-looked-at-78-election-deepfakes?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) from Princeton computer scientists Arvind Narayanan and Sayash Kapoor, political misinformation — [while a real problem](https://www.thedeepview.co/p/<https:/www.nature.com/articles/d41586-024-01587-3?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>) —**was not an AI problem this year.**
**The details** : In analyzing every (_known_) use of AI curated by the [Wired AI Elections Project](https://www.thedeepview.co/p/<https:/www.cs.princeton.edu/~sayashk/political-misinformation/WIRED-data.html?utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>), the pair identified three main takeaways: one,**that half of AI use wasn’t intentionally deceptive** , two, that AI-generated deceptive content would have still been easy to produce without AI, and three, that supply is the wrong way to examine it; we should be looking at demand instead. 
  * They found that**39 of the 78 instances of AI use in the database** were not deceptive; in many cases, generative AI was used by campaigns to broaden their reach in some way. Of course, some of the non-deceptive AI-generated content included the kinds of confabulations and hallucinations tied to the architecture of the technology. 
  * A more rampant problem **involved so-called “cheap fakes,”** which present raw video out of context, or apply subtle edits to raw video (_slowing it down to make speech appear slurred, for example_) to impact a voter’s impression of a candidate. 


According to a database of viral instances of global electoral misinformation by the [News Literacy Project](https://www.thedeepview.co/p/<https:/misinfodashboard.newslit.org/?_ga=2.147033975.1983394253.1734363530-623154005.1734363530&utm_source=thedeepview&utm_medium=newsletter&utm_campaign=ai-didn-t-have-a-huge-impact-on-2024-elections>), only**6% of total instances were created using AI;** some 45%, however, involved those aforementioned tricks of context. 
“Increasing the supply of misinformation does not meaningfully change the dynamics of the demand for misinformation since the increased supply is competing for the same eyeballs,” Kapoor and Narayanan wrote. “Moreover, the increased supply of misinformation is likely to be consumed mainly by a small group of partisans who already agree with it and heavily consume misinformation rather than to convince a broader swath of the public.”
The report focused purely on political misinformation, noting — [as we’ve talked about often](https://www.thedeepview.co/p/<https:/www.thedeepview.co/p/cybersecurity-expert-lots-of-painful-lessons-ahead>) — that other facets of AI-generated fraud and misinformation,**which encompass deepfake abuse and harassment, as well as targeted phishing and identity theft,** remain a significant problem. 
“Thinking of political misinformation as a technological (or AI) problem is appealing because it makes the solution seem tractable. If only we could roll back harmful tech, we could drastically improve the information environment,” the two wrote. “While the goal of improving the information environment is laudable, blaming technology is not a fix.”
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d7bfd047-da20-4bf8-b953-af751585770f/Frame_1707478942.png?t=1731078020)
I find it interesting, though not particularly surprising, that generative AI played a relatively small role in the elections this year, though I do not think it was at all a bad thing for people to express extreme concern over this dynamic. Concern leads to vigilance, and vigilance keeps us sharp. 
But while the brand of political misinformation they discussed might not have been an AI problem, I would argue a different brand is — if misinformation, as they argued, is in part due to political polarization, and in part **due to how people get their information** , it’s hard to claim that technology isn’t a culprit. 
Yes, people have lost trust in the media, and in institutions. But search and social media algorithms (which leverage AI) don’t value truth, and instead push out content that keeps people on platforms, incentivizing everyone from bad actors to media organizations to employ emotional, suggestive and misleading headlines, all of which fuel a destructive cycle. 
There are other things at play here, but we can’t erase the role technology plays in accelerating these elements — if Google Search, for instance, was optimized for factuality, rather than SEO, we would be in a very different situation.
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/cfff61f9-e463-4d75-87e1-3242fdf99f0e/10_AI_or_not.gif?t=1718891433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/c6635535-5d88-4db7-9cd1-e1bb7f885e4c/Rhodes_FAKE-min.png?t=1734034441)
### Which image is real?   
---  
  * [ ⬆️ Image 1 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ ⬇️ Image 2 ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/8737e1a5-b0aa-461b-9aec-2c344bfd082a/Rhodes_REAL-min.jpg?t=1734034433)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/9a8bfd3d-4705-45aa-b669-e3bedc35add8/Last_week_results.png?t=1719262752)
![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/99cacc4e-8e27-4312-80f8-9710d3fe56cc/Real_or_Not_Template-2.jpg?t=1734376778)
## 🤔Your thought process: 
#### Selected Image 2 (Left): 
  * “The patterns on the sand on the ground in the foreground look unrealistic. The top edges of the cliff don't seem to make sense with the way houses are built.”


# 💭 A poll before you go
Thanks for reading today’s edition of The Deep View! 
We’ll see you in the next one. 
### Here’s your view on AI training opt-outs: 
50% of you said training should be opt-in only; only 28% said opt-outs are fine. 
**Opt-out is fine:**
  * “If the work is public in any way — on social, in a gallery, etc., — I don’t see an issue unless the result is a replica/copy which of course would fall under copyright.”


### Do you use smart glasses? If not, do you think you will?   
---  
  * [ Yep, I love my AI glasses ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Don't use them right now, but I expect I will somewhat soon ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ I'll never use AI glasses ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)
  * [ Something else ](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>)

  
[Login](https://www.thedeepview.co/p/<https:/www.thedeepview.co/login>) or [Subscribe](https://www.thedeepview.co/p/<https:/www.thedeepview.co/subscribe>) to participate in polls.   
![Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/publication/logo/d2f6c485-9e1f-4efe-8972-c44827c29219/thumb_Untitled_design__1_.png)
The Deep View
Get our free, 5-minute daily newsletter that makes you smarter about AI. Read by 450,000+ from Google, Meta, Microsoft, a16z and more.
Home
[Posts](https://www.thedeepview.co/p/</>)
[](https://www.thedeepview.co/p/<https:/twitter.com/thedeepview>)[](https://www.thedeepview.co/p/<https:/www.tiktok.com/@thedeepviewai>)[](https://www.thedeepview.co/p/<https:/www.instagram.com/thedeepview.co/>)[](https://www.thedeepview.co/p/<https:/rss.beehiiv.com/feeds/nswNBn2yqy.xml>)
© 2025 The Deep View.
[Privacy Policy](https://www.thedeepview.co/p/<https:/beehiiv.com/privacy>)[Terms of Use](https://www.thedeepview.co/p/<https:/beehiiv.com/tou>)


